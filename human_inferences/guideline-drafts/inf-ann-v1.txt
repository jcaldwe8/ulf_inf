; Len's comments in brackets.

[Multi-stage]:
1. Have all annotators generate inferences for sentences
2. Have annotators vote on correctness/appropriateness of other annotators' annotations (take if majority says it's correct?) -- seeing one annotation at a time
3. Show all annotations for a single sentence, ask annotators to group duplicates (semantically equivalent)


The purpose of these guidelines is to have people generate inferences at
surface form level but with restricted/guidance to only consider specific types
of inference.  By providing examples of inference rules we can expect to limit
superfluous syntactic variations.  These variations can be handled in
principle, but just adds to the rules that need to be written.  e.g. "What is
the official animal of Canada?" -> "Something is the official animal of
Canada."; "Canada has an official animal".  These inferences are effectively
the same information, so we'd like the humans to choose one canonically to
simplify what we need to get our system to accomplish for this experiment.

The general structure is to provide some information regarding the types of
inferences we're interested in for the given sentence.  Then asking the
annotator to provide some classification of the provided inference to make sure
they clearly distinguish the different available inferences.  We allow open
class annotation, where the annotator doesn't think it falls into any given
classes.  This we can do preliminarily a couple iterations to make sure the
classes cover most expected cases.

1) Implicatives
  a. use word lookup to highlight the word identified
     [Oh, the annotator will be provided with this]
     {GK: Yes.  And I'm still deciding whether to give the annotator just a
     single case to deal with for a given sentence or highlight all possible
     cases.}
  b. provide all inference rule descriptions and examples for this for reference
     [You don't mean separate examples for every implicative? Or do you? (c) seems
     to imply yes]
     {GK: Probably not an example for the exact implicative, but probably a few
     examples for each implicative type (grouped by semantic structure and
     available inferences) so that for all (or at least most) implicatives
     there are some concrete examples of the sorts of inferences we're
     interested in.  For example for the implicatives 'rejoice', 'reveal',
     'understand', and others all have (+,+) polarity inference and have the
     inference structure 'x <verb> (that y) -> y' so they would all be provided
     the first set of examples for 'regret' shown below.  It should be clear to the
     annotators then that "John understands that he treated Mary without
     respect" has some of the same inferences available to it as "John regrets
     that he treated Mary without respect"}
      Ex. regret
      "John regrets that he treated Mary without respect"
      x regret (that y) -> y
      x not regret (that y) -> y
      "John regrets having treated Mary without respect"
      x regret (ka y) -> (x y)       [maybe x regret y-ing -> (x y-ed)  {GK: Yes, because we can't say *"John regrets to run"}
      x not regret (ka y) -> (x y)   [ likewise ]
         [Provide other-tense examples too -- "did not regret", "has not regretted",
          "will not regret" (which has a weaker implication)]
         {GK: Yes. I've been going through the implicative inference lists from
         Stratos to handle various tenses and determining exactly what the
         inferences are.  Right now I'm working with almost fully explicit ULF
            e.g. ((w_wff),(t_tense),(x)) : (x ((t regret.v) (that w))) -> w
         but I'll also need to think about what the nicest presentation will be
         for the annotators.}
  c. ask the annotator to write sentences that reflect the consequent of these
     rules applied to the provided sentence, as appropriate -- mark which rule
     is being represented.
  d. ask for any other inferences of this type, but not included in the rules
     in a different entry (to check if our rules seem to cover all the inferences
     that our subjects can think of).
  e. record annotations in including: original sentence, rule-result-annotator triples

2) Counterfactuals
  [See other doc in this folder 'cf-guidelines-v1.txt' for details]

3) Requests
  a. Enumerate inference types
    * implicit request as a directly conversion of original question
        can you ...
          -> I expect/want you to ...
    * inferred request not directly mapped from question
        "Is x here?"
          -> "I expect you to get x if they are nearby"
          [risky? but interesting to try]
          {GK: I agree}
    * indirect intention inference
        "Is x here?"
          -> "I probably want to speak to x"
        [likewise]
    * situational inference
        "Is x here?"
          -> "The speaker is probably on the phone or at an entrance"
        "Could I get the check?"/"Could you get me the check?"
          -> "The speaker is probably a patron at a sit-down restaurant"
          -> "The speaker thinks the hearer works at the restaurant")
    * Negative requests (request is negative to the surface question)
        "Can't you be friendly?"
          -> "I want you to be friendly"
          -> "I don't see a reason for you to not be friendly"
        [Depends of "friendly to WHOM" -- it it's the addresee, the 
        implication is also "You are not being friendly"; if it's future
        directed, then this need not be implied; "When I meet the mayor,
        I'm going to be very business-like." Reply: "Can't you be friendly?"]

  b. Use grep patterns to reduce displayed information.
  c. For the sentence ask the annotator to select the inference classification
     and provide resulting sentence/ULF.  Allow them to mark that there is no
     appropriate category, or multiple if ambiguous.


4) Questions
  [See separate doc 'question-guidelines-v1.txt' for details]

GK(3/29/2018): Should run the sampled sentences first with the annotators.
Then they should be pretty comfortable with identifying the sorts of inferences
we care about even without prompting.  We then have them annotate some
sentences that were not sampled to verify that there are not many inferences we
care about in the ignored sentences.

