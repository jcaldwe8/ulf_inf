[
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1812, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/46", 
    "implicative_pattern": "accepted", 
    "in-dataset_implicative_shuffle_num": 379, 
    "in-dataset_question_shuffle_num": 0, 
    "inf_sentences_id": 689108, 
    "line": "What , then , is the point of talking to Vorontsov , whose country already has accepted the principle of a broad-based Afghan government to supplant the one headed by its old protegy , President Najib ?", 
    "linenum": 11, 
    "matchl": "What , then , is the point of talking to Vorontsov , whose country already has accepted the principle of a broad-based Afghan government to supplant the one headed by its old protegy , President Najib ?", 
    "out-dataset_implicative_shuffle_num": 1516, 
    "out-dataset_question_shuffle_num": 0, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 916688
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 14676, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_question_shuffle_num": 0, 
    "inf_sentences_id": 705124, 
    "line": "Who was the 1st U.S. President ?", 
    "linenum": 4676, 
    "matchl": "Who was the 1st U.S. President ?", 
    "out-dataset_question_shuffle_num": 1, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 932704
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 554887, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 0, 
    "inf_sentences_id": 554908, 
    "line": "What do people expect ?", 
    "linenum": 554887, 
    "matchl": "What do people expect ?", 
    "out-dataset_question_shuffle_num": 2, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 782165
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 55763, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/135-0.txt", 
    "implicative_pattern": "recognize", 
    "in-dataset_implicative_shuffle_num": 108294, 
    "in-dataset_question_shuffle_num": 0, 
    "inf_sentences_id": 761663, 
    "line": "What ! these men do not recognize me !", 
    "linenum": 7336, 
    "matchl": "What ! these men do not recognize me !", 
    "out-dataset_implicative_shuffle_num": 222289, 
    "out-dataset_question_shuffle_num": 3, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 989243
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 84, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/100", 
    "implicative_pattern": "fails", 
    "in-dataset_implicative_shuffle_num": 587, 
    "in-dataset_question_shuffle_num": 1, 
    "inf_sentences_id": 687380, 
    "line": "When both engines on a plane go out , investigators normally would look at the performance of the pilot , particularly actions taken after one engine fails , along with the engines themselves , the fuel and electrical systems , and the possibility of sabotage or maintenance failure , among other possible causes .", 
    "linenum": 12, 
    "matchl": "When both engines on a plane go out , investigators normally would look at the performance of the pilot , particularly actions taken after one engine fails , along with the engines themselves , the fuel and electrical systems , and the possibility of sabotage or maintenance failure , among other possible causes .", 
    "out-dataset_implicative_shuffle_num": 2348, 
    "out-dataset_question_shuffle_num": 4, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 914960
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 9933, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "come", 
    "in-dataset_implicative_shuffle_num": 1965, 
    "in-dataset_question_shuffle_num": 1, 
    "inf_sentences_id": 700381, 
    "line": "How come a doughnut has a hole in it ?", 
    "linenum": 3933, 
    "matchl": "How come a doughnut has a hole in it ?", 
    "out-dataset_implicative_shuffle_num": 7861, 
    "out-dataset_question_shuffle_num": 5, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 927961
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 495911, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "want", 
    "in-dataset_implicative_shuffle_num": 273764, 
    "in-dataset_question_shuffle_num": 1, 
    "inf_sentences_id": 495931, 
    "line": "Do you really want that ?", 
    "linenum": 495911, 
    "matchl": "Do you really want that ?", 
    "out-dataset_implicative_shuffle_num": 540110, 
    "out-dataset_question_shuffle_num": 6, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 723189
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 241380, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2600-0.txt", 
    "in-dataset_question_shuffle_num": 1, 
    "inf_sentences_id": 947282, 
    "line": "\" You 're not asleep ? \"", 
    "linenum": 12259, 
    "matchl": "\" You 're not asleep ? \"", 
    "out-dataset_question_shuffle_num": 7, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 1174862
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1452, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/3", 
    "in-dataset_question_shuffle_num": 2, 
    "inf_sentences_id": 688748, 
    "line": "What does the future hold ?", 
    "linenum": 26, 
    "matchl": "What does the future hold ?", 
    "out-dataset_question_shuffle_num": 8, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 916328
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 7926, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "in-dataset_question_shuffle_num": 2, 
    "inf_sentences_id": 698374, 
    "line": "The major league baseball team in Pittsburgh is called what ?", 
    "linenum": 1926, 
    "matchl": "The major league baseball team in Pittsburgh is called what ?", 
    "out-dataset_question_shuffle_num": 9, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 925954
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 174189, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 2, 
    "inf_sentences_id": 174206, 
    "line": "Aren\u2019t they on the sea during the night ?", 
    "linenum": 174189, 
    "matchl": "Aren\u2019t they on the sea during the night ?", 
    "out-dataset_question_shuffle_num": 10, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 401467
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 264591, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2701-0.txt", 
    "implicative_pattern": "think", 
    "in-dataset_implicative_shuffle_num": 29515, 
    "in-dataset_question_shuffle_num": 2, 
    "inf_sentences_id": 970493, 
    "line": "Dost not think of murdering the officers when thou gettest to sea ? \"", 
    "linenum": 1578, 
    "matchl": "Dost not think of murdering the officers when thou gettest to sea ? \"", 
    "out-dataset_implicative_shuffle_num": 64731, 
    "out-dataset_question_shuffle_num": 11, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1198073
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1071, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/14", 
    "in-dataset_question_shuffle_num": 3, 
    "inf_sentences_id": 688367, 
    "line": "When the guerrillas kill civilians , they usually announce it on their clandestine Radio Venceremos .", 
    "linenum": 44, 
    "matchl": "When the guerrillas kill civilians , they usually announce it on their clandestine Radio Venceremos .", 
    "out-dataset_question_shuffle_num": 12, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 915947
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 8611, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "in-dataset_question_shuffle_num": 3, 
    "inf_sentences_id": 699059, 
    "line": "What `` marvelous '' major-league baseball player is now a spokesman for a beer company ?", 
    "linenum": 2611, 
    "matchl": "What `` marvelous '' major-league baseball player is now a spokesman for a beer company ?", 
    "out-dataset_question_shuffle_num": 13, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 926639
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 497173, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "proceed", 
    "in-dataset_implicative_shuffle_num": 235455, 
    "in-dataset_question_shuffle_num": 3, 
    "inf_sentences_id": 497193, 
    "line": "Are you ready to proceed ?", 
    "linenum": 497173, 
    "matchl": "Are you ready to proceed ?", 
    "out-dataset_implicative_shuffle_num": 476610, 
    "out-dataset_question_shuffle_num": 14, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 724451
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 298479, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2814-0.txt", 
    "implicative_pattern": "remember", 
    "in-dataset_implicative_shuffle_num": 16422, 
    "in-dataset_question_shuffle_num": 3, 
    "inf_sentences_id": 1004381, 
    "line": "Do you remember that thing he wrote ...? \"", 
    "linenum": 2495, 
    "matchl": "Do you remember that thing he wrote ...? \"", 
    "out-dataset_implicative_shuffle_num": 38545, 
    "out-dataset_question_shuffle_num": 15, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1231961
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1024, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/135", 
    "implicative_pattern": "get", 
    "in-dataset_implicative_shuffle_num": 1761, 
    "in-dataset_question_shuffle_num": 4, 
    "inf_sentences_id": 688320, 
    "line": "Would Mr. Antori ever get back in ?", 
    "linenum": 46, 
    "matchl": "Would Mr. Antori ever get back in ?", 
    "out-dataset_implicative_shuffle_num": 7044, 
    "out-dataset_question_shuffle_num": 16, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 915900
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 14967, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_question_shuffle_num": 4, 
    "inf_sentences_id": 705415, 
    "line": "Who wrote The Collector ?", 
    "linenum": 4967, 
    "matchl": "Who wrote The Collector ?", 
    "out-dataset_question_shuffle_num": 17, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 932995
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 492839, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 4, 
    "inf_sentences_id": 492859, 
    "line": "Are we really in 2015 ?", 
    "linenum": 492839, 
    "matchl": "Are we really in 2015 ?", 
    "out-dataset_question_shuffle_num": 18, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 720117
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 276265, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/28054-0.txt", 
    "in-dataset_question_shuffle_num": 4, 
    "inf_sentences_id": 982167, 
    "line": "Shall we go over and have a look at it , eh ?", 
    "linenum": 3840, 
    "matchl": "Shall we go over and have a look at it , eh ?", 
    "out-dataset_question_shuffle_num": 19, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 1209747
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1036, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/14", 
    "in-dataset_question_shuffle_num": 5, 
    "inf_sentences_id": 688332, 
    "line": "When the uniformed men had finished killing Cecilio , they went back to his house to demand food and his weapon .", 
    "linenum": 9, 
    "matchl": "When the uniformed men had finished killing Cecilio , they went back to his house to demand food and his weapon .", 
    "out-dataset_question_shuffle_num": 20, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 915912
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 812, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_1000.raw", 
    "in-dataset_question_shuffle_num": 5, 
    "inf_sentences_id": 691260, 
    "line": "What is Spumante ?", 
    "linenum": 812, 
    "matchl": "What is Spumante ?", 
    "out-dataset_question_shuffle_num": 21, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 918840
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 401441, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 5, 
    "inf_sentences_id": 401461, 
    "line": "Tom does have a certain charm , does n't he ?", 
    "linenum": 401441, 
    "matchl": "Tom does have a certain charm , does n't he ?", 
    "out-dataset_question_shuffle_num": 22, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 628719
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 273748, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/28054-0.txt", 
    "implicative_pattern": "presume", 
    "in-dataset_implicative_shuffle_num": 178677, 
    "in-dataset_question_shuffle_num": 5, 
    "in-dataset_request_shuffle_num": 2060, 
    "inf_sentences_id": 979650, 
    "line": "\" How can you presume to do such deeds ? \" the monk asked suddenly , pointing solemnly and significantly at Lise .", 
    "linenum": 1323, 
    "matchl": "\" How can you presume to do such deeds ? \" the monk asked suddenly , pointing solemnly and significantly at Lise .", 
    "out-dataset_implicative_shuffle_num": 363055, 
    "out-dataset_question_shuffle_num": 23, 
    "out-dataset_request_shuffle_num": 4508, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1207230
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 230, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/106", 
    "in-dataset_question_shuffle_num": 6, 
    "inf_sentences_id": 687526, 
    "line": "`` It seems we 're a patsy for somebody , does n't it ?", 
    "linenum": 14, 
    "matchl": "`` It seems we 're a patsy for somebody , does n't it ?", 
    "out-dataset_question_shuffle_num": 24, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 915106
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 14479, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_question_shuffle_num": 6, 
    "inf_sentences_id": 704927, 
    "line": "What two countries is Andorra nestled between ?", 
    "linenum": 4479, 
    "matchl": "What two countries is Andorra nestled between ?", 
    "out-dataset_question_shuffle_num": 25, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 932507
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 512524, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "stop", 
    "in-dataset_implicative_shuffle_num": 211182, 
    "in-dataset_question_shuffle_num": 6, 
    "in-dataset_request_shuffle_num": 3014, 
    "inf_sentences_id": 512545, 
    "line": "How can I stop him ?", 
    "linenum": 512524, 
    "matchl": "How can I stop him ?", 
    "out-dataset_implicative_shuffle_num": 428064, 
    "out-dataset_question_shuffle_num": 26, 
    "out-dataset_request_shuffle_num": 6355, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 739802
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 213563, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2554-0.txt", 
    "in-dataset_question_shuffle_num": 6, 
    "inf_sentences_id": 919465, 
    "line": "Have I ? \"", 
    "linenum": 3129, 
    "matchl": "Have I ? \"", 
    "out-dataset_question_shuffle_num": 27, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 1147045
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1900, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/5", 
    "implicative_pattern": "like", 
    "in-dataset_implicative_shuffle_num": 1888, 
    "in-dataset_question_shuffle_num": 7, 
    "inf_sentences_id": 689196, 
    "line": "When it 's time for their biannual powwow , the nation 's manufacturing titans typically jet off to the sunny confines of resort towns like Boca Raton and Hot Springs .", 
    "linenum": 0, 
    "matchl": "When it 's time for their biannual powwow , the nation 's manufacturing titans typically jet off to the sunny confines of resort towns like Boca Raton and Hot Springs .", 
    "out-dataset_implicative_shuffle_num": 7552, 
    "out-dataset_question_shuffle_num": 28, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 916776
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 12186, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "love", 
    "in-dataset_implicative_shuffle_num": 490, 
    "in-dataset_question_shuffle_num": 7, 
    "inf_sentences_id": 702634, 
    "line": "What sign is the best love match for a horoscope sign ?", 
    "linenum": 2186, 
    "matchl": "What sign is the best love match for a horoscope sign ?", 
    "out-dataset_implicative_shuffle_num": 1961, 
    "out-dataset_question_shuffle_num": 29, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 930214
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 441332, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "understood", 
    "in-dataset_implicative_shuffle_num": 186268, 
    "in-dataset_question_shuffle_num": 7, 
    "inf_sentences_id": 441352, 
    "line": "Understood why I am opposed to women on the tatami ?", 
    "linenum": 441332, 
    "matchl": "Understood why I am opposed to women on the tatami ?", 
    "out-dataset_implicative_shuffle_num": 378236, 
    "out-dataset_question_shuffle_num": 30, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 668610
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 147315, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1661.txt.utf-8", 
    "in-dataset_question_shuffle_num": 7, 
    "inf_sentences_id": 853216, 
    "line": "Do you feel equal to it ? \"", 
    "linenum": 4535, 
    "matchl": "Do you feel equal to it ? \"", 
    "out-dataset_question_shuffle_num": 31, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 1080796
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 553, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/115", 
    "in-dataset_question_shuffle_num": 8, 
    "inf_sentences_id": 687849, 
    "line": "`` Who 'd pay any attention to a 20-year-old kid ? ''", 
    "linenum": 30, 
    "matchl": "`` Who 'd pay any attention to a 20-year-old kid ? ''", 
    "out-dataset_question_shuffle_num": 32, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 915429
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 10114, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_question_shuffle_num": 8, 
    "inf_sentences_id": 700562, 
    "line": "What is the largest snake in the world ?", 
    "linenum": 114, 
    "matchl": "What is the largest snake in the world ?", 
    "out-dataset_question_shuffle_num": 33, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 928142
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 498366, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 8, 
    "inf_sentences_id": 498386, 
    "line": "Why are you fighting me ?", 
    "linenum": 498366, 
    "matchl": "Why are you fighting me ?", 
    "out-dataset_question_shuffle_num": 34, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 725644
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 64697, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/135-0.txt", 
    "in-dataset_question_shuffle_num": 8, 
    "inf_sentences_id": 770597, 
    "line": "Shall we go into ecstasies over Russia ?", 
    "linenum": 16270, 
    "matchl": "Shall we go into ecstasies over Russia ?", 
    "out-dataset_question_shuffle_num": 35, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 998177
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 283, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/107", 
    "implicative_pattern": "forgotten", 
    "in-dataset_implicative_shuffle_num": 369, 
    "in-dataset_question_shuffle_num": 9, 
    "inf_sentences_id": 687579, 
    "line": "`` Have we forgotten our children were killed , too ? ''", 
    "linenum": 19, 
    "matchl": "`` Have we forgotten our children were killed , too ? ''", 
    "out-dataset_implicative_shuffle_num": 1476, 
    "out-dataset_question_shuffle_num": 36, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 915159
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 12560, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_question_shuffle_num": 9, 
    "inf_sentences_id": 703008, 
    "line": "What English word has the most letters ?", 
    "linenum": 2560, 
    "matchl": "What English word has the most letters ?", 
    "out-dataset_question_shuffle_num": 37, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 930588
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 51880, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 9, 
    "inf_sentences_id": 51896, 
    "line": "What did you do with your camera ?", 
    "linenum": 51880, 
    "matchl": "What did you do with your camera ?", 
    "out-dataset_question_shuffle_num": 38, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 279158
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 168446, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/20228.txt.utf-8", 
    "in-dataset_question_shuffle_num": 9, 
    "inf_sentences_id": 874347, 
    "line": "--?Nang m~ga insic ? ? Nasisira ba ang isip ninyo?--ang sabi ni Fr .", 
    "linenum": 226, 
    "matchl": "--?Nang m~ga insic ? ? Nasisira ba ang isip ninyo?--ang sabi ni Fr .", 
    "out-dataset_question_shuffle_num": 39, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 1101927
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1224, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/20", 
    "in-dataset_question_shuffle_num": 10, 
    "inf_sentences_id": 688520, 
    "line": "What triggered the latest clash was a skirmish over the timing of a New Zealand government bond issue .", 
    "linenum": 4, 
    "matchl": "What triggered the latest clash was a skirmish over the timing of a New Zealand government bond issue .", 
    "out-dataset_question_shuffle_num": 40, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 916100
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 15157, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_question_shuffle_num": 10, 
    "inf_sentences_id": 705605, 
    "line": "What country has the highest per capita consumption of cheese ?", 
    "linenum": 5157, 
    "matchl": "What country has the highest per capita consumption of cheese ?", 
    "out-dataset_question_shuffle_num": 41, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 933185
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 512575, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "show", 
    "in-dataset_implicative_shuffle_num": 185275, 
    "in-dataset_question_shuffle_num": 10, 
    "inf_sentences_id": 512596, 
    "line": "Did you show her your pictures ?", 
    "linenum": 512575, 
    "matchl": "Did you show her your pictures ?", 
    "out-dataset_implicative_shuffle_num": 376250, 
    "out-dataset_question_shuffle_num": 42, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 739853
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 93304, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1400-0.txt", 
    "implicative_pattern": "known", 
    "in-dataset_implicative_shuffle_num": 24132, 
    "in-dataset_question_shuffle_num": 10, 
    "inf_sentences_id": 799204, 
    "line": "\" You have an apprentice , \" pursued the stranger , \" commonly known as Pip ?", 
    "linenum": 2654, 
    "matchl": "\" You have an apprentice , \" pursued the stranger , \" commonly known as Pip ?", 
    "out-dataset_implicative_shuffle_num": 53965, 
    "out-dataset_question_shuffle_num": 43, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1026784
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 313, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/108", 
    "in-dataset_question_shuffle_num": 11, 
    "inf_sentences_id": 687609, 
    "line": "Rather , he asked a question: `` Are we doing a good enough job teaching our children what America is and what she represents in the long history of the world ? ''", 
    "linenum": 10, 
    "matchl": "Rather , he asked a question: `` Are we doing a good enough job teaching our children what America is and what she represents in the long history of the world ? ''", 
    "out-dataset_question_shuffle_num": 44, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 915189
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 8955, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "in-dataset_question_shuffle_num": 11, 
    "inf_sentences_id": 699403, 
    "line": "What is AFS ?", 
    "linenum": 2955, 
    "matchl": "What is AFS ?", 
    "out-dataset_question_shuffle_num": 45, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 926983
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 494247, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 11, 
    "inf_sentences_id": 494267, 
    "line": "Have you done something wrong ?", 
    "linenum": 494247, 
    "matchl": "Have you done something wrong ?", 
    "out-dataset_question_shuffle_num": 46, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 721525
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 480616, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/844.txt.utf-8", 
    "implicative_pattern": "mean", 
    "in-dataset_implicative_shuffle_num": 184690, 
    "in-dataset_question_shuffle_num": 11, 
    "inf_sentences_id": 1186520, 
    "line": "What on earth do you mean ?", 
    "linenum": 316, 
    "matchl": "What on earth do you mean ?", 
    "out-dataset_implicative_shuffle_num": 375081, 
    "out-dataset_question_shuffle_num": 47, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1414100
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 571, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/116", 
    "in-dataset_question_shuffle_num": 12, 
    "inf_sentences_id": 687867, 
    "line": "`` Is there something rotten in the kingdom of museums ? ''", 
    "linenum": 17, 
    "matchl": "`` Is there something rotten in the kingdom of museums ? ''", 
    "out-dataset_question_shuffle_num": 48, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 915447
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 3417, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "live", 
    "in-dataset_implicative_shuffle_num": 3052, 
    "in-dataset_question_shuffle_num": 12, 
    "inf_sentences_id": 693865, 
    "line": "What movie tour of the Roman empire features the admonition : `` Row well and live '' ?", 
    "linenum": 417, 
    "matchl": "What movie tour of the Roman empire features the admonition : `` Row well and live '' ?", 
    "out-dataset_implicative_shuffle_num": 11145, 
    "out-dataset_question_shuffle_num": 49, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 921445
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 322909, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "begin", 
    "in-dataset_implicative_shuffle_num": 121253, 
    "in-dataset_question_shuffle_num": 12, 
    "inf_sentences_id": 322928, 
    "line": "When did you begin studying French ?", 
    "linenum": 322909, 
    "matchl": "When did you begin studying French ?", 
    "out-dataset_implicative_shuffle_num": 248206, 
    "out-dataset_question_shuffle_num": 50, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 550187
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 363675, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/3600-0.txt", 
    "implicative_pattern": "work", 
    "in-dataset_implicative_shuffle_num": 95331, 
    "in-dataset_question_shuffle_num": 12, 
    "inf_sentences_id": 1069578, 
    "line": "Are we not brutes to call that work brutish which begets us ?", 
    "linenum": 11476, 
    "matchl": "Are we not brutes to call that work brutish which begets us ?", 
    "out-dataset_implicative_shuffle_num": 196363, 
    "out-dataset_question_shuffle_num": 51, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1297158
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1009, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/135", 
    "implicative_pattern": "frightened", 
    "in-dataset_implicative_shuffle_num": 130, 
    "in-dataset_question_shuffle_num": 13, 
    "inf_sentences_id": 688305, 
    "line": "When the little guy gets frightened , the big guys hurt badly .", 
    "linenum": 31, 
    "matchl": "When the little guy gets frightened , the big guys hurt badly .", 
    "out-dataset_implicative_shuffle_num": 520, 
    "out-dataset_question_shuffle_num": 52, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 915885
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 7804, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "in-dataset_question_shuffle_num": 13, 
    "inf_sentences_id": 698252, 
    "line": "What is the second highest mountain peak in the world ?", 
    "linenum": 1804, 
    "matchl": "What is the second highest mountain peak in the world ?", 
    "out-dataset_question_shuffle_num": 53, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 925832
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 318786, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 13, 
    "inf_sentences_id": 318805, 
    "line": "Why did you volunteer to do this ?", 
    "linenum": 318786, 
    "matchl": "Why did you volunteer to do this ?", 
    "out-dataset_question_shuffle_num": 54, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 546064
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 287388, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/28054-0.txt", 
    "in-dataset_question_shuffle_num": 13, 
    "inf_sentences_id": 993290, 
    "line": "\" Last night ?", 
    "linenum": 14963, 
    "matchl": "\" Last night ?", 
    "out-dataset_question_shuffle_num": 55, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 1220870
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1823, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/46", 
    "implicative_pattern": "happen", 
    "in-dataset_implicative_shuffle_num": 1349, 
    "in-dataset_question_shuffle_num": 14, 
    "inf_sentences_id": 689119, 
    "line": "`` What is going to happen ?", 
    "linenum": 22, 
    "matchl": "`` What is going to happen ?", 
    "out-dataset_implicative_shuffle_num": 5396, 
    "out-dataset_question_shuffle_num": 56, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 916699
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 1288, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "in-dataset_question_shuffle_num": 14, 
    "inf_sentences_id": 691736, 
    "line": "What European country is home to the beer-producing city of Budweis ?", 
    "linenum": 288, 
    "matchl": "What European country is home to the beer-producing city of Budweis ?", 
    "out-dataset_question_shuffle_num": 57, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 919316
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 179095, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 14, 
    "inf_sentences_id": 179112, 
    "line": "What 's your favorite thing about Hawaii ?", 
    "linenum": 179095, 
    "matchl": "What 's your favorite thing about Hawaii ?", 
    "out-dataset_question_shuffle_num": 58, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 406373
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 380265, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/4300-0.txt", 
    "in-dataset_question_shuffle_num": 14, 
    "inf_sentences_id": 1086168, 
    "line": "Must be Ruby pride of the on the floor naked .", 
    "linenum": 2494, 
    "matchl": "Must be Ruby pride of the on the floor naked .", 
    "out-dataset_question_shuffle_num": 59, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 1313748
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2158, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/61", 
    "in-dataset_question_shuffle_num": 15, 
    "inf_sentences_id": 689454, 
    "line": "When he first was diagnosed as retarded , he was 9 . ''", 
    "linenum": 22, 
    "matchl": "When he first was diagnosed as retarded , he was 9 . ''", 
    "out-dataset_question_shuffle_num": 60, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 917034
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 7832, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "in-dataset_question_shuffle_num": 15, 
    "inf_sentences_id": 698280, 
    "line": "What culture developed the idea of potlatch ?", 
    "linenum": 1832, 
    "matchl": "What culture developed the idea of potlatch ?", 
    "out-dataset_question_shuffle_num": 61, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 925860
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 283322, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 15, 
    "inf_sentences_id": 283340, 
    "line": "Why do n't you give me a break ?", 
    "linenum": 283322, 
    "matchl": "Why do n't you give me a break ?", 
    "out-dataset_question_shuffle_num": 62, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 510600
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 253940, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2600-0.txt", 
    "implicative_pattern": "reflecting", 
    "in-dataset_implicative_shuffle_num": 185716, 
    "in-dataset_question_shuffle_num": 15, 
    "inf_sentences_id": 959842, 
    "line": "When he had finished that business it was already too late to go anywhere but still too early to go to bed , and for a long time he paced up and down the room , reflecting on his life , a thing he rarely did .", 
    "linenum": 24819, 
    "matchl": "When he had finished that business it was already too late to go anywhere but still too early to go to bed , and for a long time he paced up and down the room , reflecting on his life , a thing he rarely did .", 
    "out-dataset_implicative_shuffle_num": 377133, 
    "out-dataset_question_shuffle_num": 63, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1187422
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2791, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/84", 
    "implicative_pattern": "attack", 
    "in-dataset_implicative_shuffle_num": 1893, 
    "in-dataset_question_shuffle_num": 16, 
    "inf_sentences_id": 690087, 
    "line": "When the FBI received $15 million more as a result of the 1986 drug bill , `` I indicated that I felt that we could attack anywhere between 5 and 10 percent more that a current one-third to 40 percent of approximately 450 major drug trafficking organizations , '' Sessions said at a Justice Department news conference .", 
    "linenum": 13, 
    "matchl": "When the FBI received $15 million more as a result of the 1986 drug bill , `` I indicated that I felt that we could attack anywhere between 5 and 10 percent more that a current one-third to 40 percent of approximately 450 major drug trafficking organizations , '' Sessions said at a Justice Department news conference .", 
    "out-dataset_implicative_shuffle_num": 7572, 
    "out-dataset_question_shuffle_num": 64, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 917667
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 14673, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_question_shuffle_num": 16, 
    "inf_sentences_id": 705121, 
    "line": "What is ` Last Chance for Animals ' ?", 
    "linenum": 4673, 
    "matchl": "What is ` Last Chance for Animals ' ?", 
    "out-dataset_question_shuffle_num": 65, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 932701
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 342546, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "want", 
    "in-dataset_implicative_shuffle_num": 71444, 
    "in-dataset_question_shuffle_num": 16, 
    "inf_sentences_id": 342565, 
    "line": "Do you want to drink a perfect cocktail ?", 
    "linenum": 342546, 
    "matchl": "Do you want to drink a perfect cocktail ?", 
    "out-dataset_implicative_shuffle_num": 148588, 
    "out-dataset_question_shuffle_num": 66, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 569824
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 428729, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/521-0.txt", 
    "in-dataset_question_shuffle_num": 16, 
    "inf_sentences_id": 1134633, 
    "line": "He asked me again , \" Why you angry mad with Friday?--what me done ? \"", 
    "linenum": 1801, 
    "matchl": "He asked me again , \" Why you angry mad with Friday?--what me done ? \"", 
    "out-dataset_question_shuffle_num": 67, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 1362213
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 885, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/129", 
    "implicative_pattern": "tell", 
    "in-dataset_implicative_shuffle_num": 1820, 
    "in-dataset_question_shuffle_num": 17, 
    "inf_sentences_id": 688181, 
    "line": "For example , what exactly did the CIA tell Major Giroldi and his fellow coup plotters about U.S. laws and executive orders on assassinations ?", 
    "linenum": 12, 
    "matchl": "For example , what exactly did the CIA tell Major Giroldi and his fellow coup plotters about U.S. laws and executive orders on assassinations ?", 
    "out-dataset_implicative_shuffle_num": 7280, 
    "out-dataset_question_shuffle_num": 68, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 915761
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 14365, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_question_shuffle_num": 17, 
    "inf_sentences_id": 704813, 
    "line": "What famous communist leader died in Mexico City ?", 
    "linenum": 4365, 
    "matchl": "What famous communist leader died in Mexico City ?", 
    "out-dataset_question_shuffle_num": 69, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 932393
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 22940, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 17, 
    "inf_sentences_id": 22956, 
    "line": "What is that building whose door is painted white ?", 
    "linenum": 22940, 
    "matchl": "What is that building whose door is painted white ?", 
    "out-dataset_question_shuffle_num": 70, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 250218
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 49165, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/135-0.txt", 
    "implicative_pattern": "thinking", 
    "in-dataset_implicative_shuffle_num": 245014, 
    "in-dataset_question_shuffle_num": 17, 
    "inf_sentences_id": 755065, 
    "line": "What are you thinking about ? \"", 
    "linenum": 738, 
    "matchl": "What are you thinking about ? \"", 
    "out-dataset_implicative_shuffle_num": 495729, 
    "out-dataset_question_shuffle_num": 71, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 982645
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 882, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/129", 
    "in-dataset_question_shuffle_num": 18, 
    "inf_sentences_id": 688178, 
    "line": "When they did , his commanders did n't have the initiative to do more than block a couple of roads .", 
    "linenum": 9, 
    "matchl": "When they did , his commanders did n't have the initiative to do more than block a couple of roads .", 
    "out-dataset_question_shuffle_num": 72, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 915758
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 2100, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "in-dataset_question_shuffle_num": 18, 
    "inf_sentences_id": 692548, 
    "line": "What is the executor in a will ?", 
    "linenum": 1100, 
    "matchl": "What is the executor in a will ?", 
    "out-dataset_question_shuffle_num": 73, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 920128
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 131559, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 18, 
    "inf_sentences_id": 131576, 
    "line": "Be sure and call me tonight .", 
    "linenum": 131559, 
    "matchl": "Be sure and call me tonight .", 
    "out-dataset_question_shuffle_num": 74, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 358837
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 6847, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1184-0.txt", 
    "in-dataset_question_shuffle_num": 18, 
    "inf_sentences_id": 712747, 
    "line": "\" You ? \"", 
    "linenum": 5324, 
    "matchl": "\" You ? \"", 
    "out-dataset_question_shuffle_num": 75, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 940327
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1079, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/15", 
    "in-dataset_question_shuffle_num": 19, 
    "inf_sentences_id": 688375, 
    "line": "When a U.S. ambassador sat down with a PLO delegation for the first official meeting in 13 years , Sweden scored a triumph for a foreign policy variously described as magnanimous or meddlesome .", 
    "linenum": 0, 
    "matchl": "When a U.S. ambassador sat down with a PLO delegation for the first official meeting in 13 years , Sweden scored a triumph for a foreign policy variously described as magnanimous or meddlesome .", 
    "out-dataset_question_shuffle_num": 76, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 915955
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 9005, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "made", 
    "in-dataset_implicative_shuffle_num": 1846, 
    "in-dataset_question_shuffle_num": 19, 
    "inf_sentences_id": 699453, 
    "line": "What made the Finger Lakes in western New York state ?", 
    "linenum": 3005, 
    "matchl": "What made the Finger Lakes in western New York state ?", 
    "out-dataset_implicative_shuffle_num": 7385, 
    "out-dataset_question_shuffle_num": 77, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 927033
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 266812, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "tell", 
    "in-dataset_counterfactual_shuffle_num": 5339, 
    "in-dataset_implicative_shuffle_num": 198848, 
    "in-dataset_question_shuffle_num": 19, 
    "inf_sentences_id": 266830, 
    "line": "Do n't tell me if you do n't want to .", 
    "linenum": 266812, 
    "matchl": "Do n't tell me if you do n't want to .", 
    "out-dataset_counterfactual_shuffle_num": 10884, 
    "out-dataset_implicative_shuffle_num": 403396, 
    "out-dataset_question_shuffle_num": 78, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 494090
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 244107, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2600-0.txt", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 167081, 
    "in-dataset_question_shuffle_num": 19, 
    "inf_sentences_id": 950009, 
    "line": "When he comes , he 'll find you already know his sister and father and are liked by them .", 
    "linenum": 14986, 
    "matchl": "When he comes , he 'll find you already know his sister and father and are liked by them .", 
    "out-dataset_implicative_shuffle_num": 339863, 
    "out-dataset_question_shuffle_num": 79, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1177589
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 900, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/129", 
    "implicative_pattern": "wants", 
    "in-dataset_implicative_shuffle_num": 1872, 
    "in-dataset_question_shuffle_num": 20, 
    "inf_sentences_id": 688196, 
    "line": "Who wants to end up as the protagonist in a Bill Cohen morality play ?", 
    "linenum": 27, 
    "matchl": "Who wants to end up as the protagonist in a Bill Cohen morality play ?", 
    "out-dataset_implicative_shuffle_num": 7488, 
    "out-dataset_question_shuffle_num": 80, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 915776
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 9979, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "in-dataset_question_shuffle_num": 20, 
    "inf_sentences_id": 700427, 
    "line": "Why is Microsoft 's Windows 3 such a successful computer program ?", 
    "linenum": 3979, 
    "matchl": "Why is Microsoft 's Windows 3 such a successful computer program ?", 
    "out-dataset_question_shuffle_num": 81, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 928007
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 247446, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "admit", 
    "in-dataset_implicative_shuffle_num": 56934, 
    "in-dataset_question_shuffle_num": 20, 
    "inf_sentences_id": 247464, 
    "line": "Do n't admit anything .", 
    "linenum": 247446, 
    "matchl": "Do n't admit anything .", 
    "out-dataset_implicative_shuffle_num": 119568, 
    "out-dataset_question_shuffle_num": 82, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 474724
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 421144, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/514.txt.utf-8", 
    "in-dataset_question_shuffle_num": 20, 
    "inf_sentences_id": 1127048, 
    "line": "\" Now , dear , what are your own ?", 
    "linenum": 4305, 
    "matchl": "\" Now , dear , what are your own ?", 
    "out-dataset_question_shuffle_num": 83, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 1354628
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 886, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/129", 
    "implicative_pattern": "attack", 
    "in-dataset_implicative_shuffle_num": 444, 
    "in-dataset_question_shuffle_num": 21, 
    "inf_sentences_id": 688182, 
    "line": "What part did U.S. warnings play in the major 's unwillingness to pull the trigger when he had General Noriega in custody , but was under attack by pro-Noriega troops ?", 
    "linenum": 13, 
    "matchl": "What part did U.S. warnings play in the major 's unwillingness to pull the trigger when he had General Noriega in custody , but was under attack by pro-Noriega troops ?", 
    "out-dataset_implicative_shuffle_num": 1776, 
    "out-dataset_question_shuffle_num": 84, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 915762
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 1105, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "implicative_pattern": "known", 
    "in-dataset_implicative_shuffle_num": 3692, 
    "in-dataset_question_shuffle_num": 21, 
    "inf_sentences_id": 691553, 
    "line": "Who comprised the now-defunct comic book team known as the Champions ?", 
    "linenum": 105, 
    "matchl": "Who comprised the now-defunct comic book team known as the Champions ?", 
    "out-dataset_implicative_shuffle_num": 13065, 
    "out-dataset_question_shuffle_num": 85, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 919133
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 685728, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 21, 
    "inf_sentences_id": 685750, 
    "line": "What exactly are your plans ?", 
    "linenum": 685728, 
    "matchl": "What exactly are your plans ?", 
    "out-dataset_question_shuffle_num": 86, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 913006
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 436198, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/730.txt.utf-8", 
    "in-dataset_question_shuffle_num": 21, 
    "inf_sentences_id": 1142102, 
    "line": "Corney ? '", 
    "linenum": 4114, 
    "matchl": "Corney ? '", 
    "out-dataset_question_shuffle_num": 87, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 1369682
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 472, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/113", 
    "implicative_pattern": "say", 
    "in-dataset_implicative_shuffle_num": 1135, 
    "in-dataset_question_shuffle_num": 22, 
    "inf_sentences_id": 687768, 
    "line": "Do n't say this belongs to capitalism or what .", 
    "linenum": 39, 
    "matchl": "Do n't say this belongs to capitalism or what .", 
    "out-dataset_implicative_shuffle_num": 4540, 
    "out-dataset_question_shuffle_num": 88, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 915348
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 10087, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_question_shuffle_num": 22, 
    "inf_sentences_id": 700535, 
    "line": "What is a fear of shadows ?", 
    "linenum": 87, 
    "matchl": "What is a fear of shadows ?", 
    "out-dataset_question_shuffle_num": 89, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 928115
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 452137, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 22, 
    "inf_sentences_id": 452157, 
    "line": "Am I still in charge here ?", 
    "linenum": 452137, 
    "matchl": "Am I still in charge here ?", 
    "out-dataset_question_shuffle_num": 90, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 679415
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 82362, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/135-0.txt", 
    "implicative_pattern": "object", 
    "in-dataset_implicative_shuffle_num": 75789, 
    "in-dataset_question_shuffle_num": 22, 
    "inf_sentences_id": 788262, 
    "line": "What was this figure of the shadows which had for its only object the preservation of the rising of a star from every shadow and from every cloud ?", 
    "linenum": 33935, 
    "matchl": "What was this figure of the shadows which had for its only object the preservation of the rising of a star from every shadow and from every cloud ?", 
    "out-dataset_implicative_shuffle_num": 157279, 
    "out-dataset_question_shuffle_num": 91, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1015842
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1026, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/135", 
    "implicative_pattern": "comes", 
    "in-dataset_implicative_shuffle_num": 1396, 
    "in-dataset_question_shuffle_num": 23, 
    "inf_sentences_id": 688322, 
    "line": "When it comes to money: Once bitten , 2,000 times shy . \"", 
    "linenum": 48, 
    "matchl": "When it comes to money: Once bitten , 2,000 times shy . \"", 
    "out-dataset_implicative_shuffle_num": 5584, 
    "out-dataset_question_shuffle_num": 92, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 915902
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 5096, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 3501, 
    "in-dataset_question_shuffle_num": 23, 
    "inf_sentences_id": 695544, 
    "line": "How do birds find their way back to the same place every year ?", 
    "linenum": 2096, 
    "matchl": "How do birds find their way back to the same place every year ?", 
    "out-dataset_implicative_shuffle_num": 12492, 
    "out-dataset_question_shuffle_num": 93, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 923124
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 401564, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "know", 
    "in-dataset_implicative_shuffle_num": 126401, 
    "in-dataset_question_shuffle_num": 23, 
    "inf_sentences_id": 401584, 
    "line": "Did you really think I did n't know ?", 
    "linenum": 401564, 
    "matchl": "Did you really think I did n't know ?", 
    "out-dataset_implicative_shuffle_num": 258502, 
    "out-dataset_question_shuffle_num": 94, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 628842
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 342805, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/345.txt.utf-8", 
    "in-dataset_question_shuffle_num": 23, 
    "inf_sentences_id": 1048708, 
    "line": "\" And doctor , as to life , what is it after all ?", 
    "linenum": 6503, 
    "matchl": "\" And doctor , as to life , what is it after all ?", 
    "out-dataset_question_shuffle_num": 95, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 1276288
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2694, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/80", 
    "implicative_pattern": "said", 
    "in-dataset_counterfactual_shuffle_num": 87, 
    "in-dataset_implicative_shuffle_num": 995, 
    "in-dataset_question_shuffle_num": 24, 
    "inf_sentences_id": 689990, 
    "line": "`` People wondered , ` If you spin up the pulsar with a companion , where is the companion ? ' '' said Fruchter .", 
    "linenum": 26, 
    "matchl": "`` People wondered , ` If you spin up the pulsar with a companion , where is the companion ? ' '' said Fruchter .", 
    "out-dataset_counterfactual_shuffle_num": 348, 
    "out-dataset_implicative_shuffle_num": 3980, 
    "out-dataset_question_shuffle_num": 96, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 917570
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 7903, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "in-dataset_question_shuffle_num": 24, 
    "inf_sentences_id": 698351, 
    "line": "What is the origin of a.m. and p.m. ?", 
    "linenum": 1903, 
    "matchl": "What is the origin of a.m. and p.m. ?", 
    "out-dataset_question_shuffle_num": 97, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 925931
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 405193, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "come", 
    "in-dataset_implicative_shuffle_num": 109819, 
    "in-dataset_question_shuffle_num": 24, 
    "inf_sentences_id": 405213, 
    "line": "Can we come with you ?", 
    "linenum": 405193, 
    "matchl": "Can we come with you ?", 
    "out-dataset_implicative_shuffle_num": 225338, 
    "out-dataset_question_shuffle_num": 98, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 632471
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 250280, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2600-0.txt", 
    "implicative_pattern": "want", 
    "in-dataset_implicative_shuffle_num": 49980, 
    "in-dataset_question_shuffle_num": 24, 
    "inf_sentences_id": 956182, 
    "line": "\" Now then , what do you want ? \" asked Napoleon in the tone of a man irritated at being continually disturbed .", 
    "linenum": 21159, 
    "matchl": "\" Now then , what do you want ? \" asked Napoleon in the tone of a man irritated at being continually disturbed .", 
    "out-dataset_implicative_shuffle_num": 105661, 
    "out-dataset_question_shuffle_num": 99, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1183762
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1617, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/37", 
    "in-dataset_question_shuffle_num": 25, 
    "inf_sentences_id": 688913, 
    "line": "When asked why , a Czechoslovak customs official , muttered , `` The bloody Poles ! ''", 
    "linenum": 24, 
    "matchl": "When asked why , a Czechoslovak customs official , muttered , `` The bloody Poles ! ''", 
    "out-dataset_question_shuffle_num": 100, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 916493
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 5722, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "in-dataset_question_shuffle_num": 25, 
    "inf_sentences_id": 696170, 
    "line": "What 's the largest island in the West Indies ?", 
    "linenum": 2722, 
    "matchl": "What 's the largest island in the West Indies ?", 
    "out-dataset_question_shuffle_num": 101, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 923750
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 299395, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 25, 
    "in-dataset_request_shuffle_num": 5603, 
    "inf_sentences_id": 299413, 
    "line": "Would you step aside ?", 
    "linenum": 299395, 
    "matchl": "Would you step aside ?", 
    "out-dataset_question_shuffle_num": 102, 
    "out-dataset_request_shuffle_num": 8944, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 526673
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 215770, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2554-0.txt", 
    "in-dataset_question_shuffle_num": 25, 
    "inf_sentences_id": 921672, 
    "line": "And what right had he to criticise him in that hasty and unguarded manner ?", 
    "linenum": 5336, 
    "matchl": "And what right had he to criticise him in that hasty and unguarded manner ?", 
    "out-dataset_question_shuffle_num": 103, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 1149252
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "(were|had|Were|Had)<end?>", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 989, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/135", 
    "implicative_pattern": "started", 
    "in-dataset_counterfactual_shuffle_num": 6, 
    "in-dataset_implicative_shuffle_num": 193, 
    "in-dataset_question_shuffle_num": 26, 
    "inf_sentences_id": 688285, 
    "line": "were attending when the market started to slide Friday .", 
    "linenum": 11, 
    "matchl": "were attending when the market started to slide Friday .", 
    "out-dataset_counterfactual_shuffle_num": 24, 
    "out-dataset_implicative_shuffle_num": 772, 
    "out-dataset_question_shuffle_num": 104, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 915865
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 1129, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "in-dataset_question_shuffle_num": 26, 
    "inf_sentences_id": 691577, 
    "line": "When did the Bounty mutiny take place ?", 
    "linenum": 129, 
    "matchl": "When did the Bounty mutiny take place ?", 
    "out-dataset_question_shuffle_num": 105, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 919157
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 417471, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "think", 
    "in-dataset_implicative_shuffle_num": 215632, 
    "in-dataset_question_shuffle_num": 26, 
    "inf_sentences_id": 417491, 
    "line": "Do you think you 're handsome ?", 
    "linenum": 417471, 
    "matchl": "Do you think you 're handsome ?", 
    "out-dataset_implicative_shuffle_num": 436964, 
    "out-dataset_question_shuffle_num": 106, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 644749
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 403802, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/45-0.txt", 
    "implicative_pattern": "like", 
    "in-dataset_implicative_shuffle_num": 26992, 
    "in-dataset_question_shuffle_num": 26, 
    "inf_sentences_id": 1109706, 
    "line": "You could n't quite call it poetry , I suppose , but it sounds a lot like it , does n't it ? \"", 
    "linenum": 1237, 
    "matchl": "You could n't quite call it poetry , I suppose , but it sounds a lot like it , does n't it ? \"", 
    "out-dataset_implicative_shuffle_num": 59685, 
    "out-dataset_question_shuffle_num": 107, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1337286
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 899, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/129", 
    "implicative_pattern": "fail", 
    "in-dataset_counterfactual_shuffle_num": 44, 
    "in-dataset_implicative_shuffle_num": 551, 
    "in-dataset_question_shuffle_num": 27, 
    "inf_sentences_id": 688195, 
    "line": "What kind of initiative should anyone expect from people out on the line who 've read all this and know what can happen if they fail ?", 
    "linenum": 26, 
    "matchl": "What kind of initiative should anyone expect from people out on the line who 've read all this and know what can happen if they fail ?", 
    "out-dataset_counterfactual_shuffle_num": 176, 
    "out-dataset_implicative_shuffle_num": 2204, 
    "out-dataset_question_shuffle_num": 108, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 915775
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 12787, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_question_shuffle_num": 27, 
    "inf_sentences_id": 703235, 
    "line": "How does a hurricane form ?", 
    "linenum": 2787, 
    "matchl": "How does a hurricane form ?", 
    "out-dataset_question_shuffle_num": 109, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 930815
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 499691, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "want", 
    "in-dataset_implicative_shuffle_num": 3830, 
    "in-dataset_question_shuffle_num": 27, 
    "inf_sentences_id": 499711, 
    "line": "Do you not want me here ?", 
    "linenum": 499691, 
    "matchl": "Do you not want me here ?", 
    "out-dataset_implicative_shuffle_num": 13360, 
    "out-dataset_question_shuffle_num": 110, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 726969
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 254356, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2600-0.txt", 
    "in-dataset_question_shuffle_num": 27, 
    "inf_sentences_id": 960258, 
    "line": "So you have abundance , then ?", 
    "linenum": 25235, 
    "matchl": "So you have abundance , then ?", 
    "out-dataset_question_shuffle_num": 111, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 1187838
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 605, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/117", 
    "implicative_pattern": "begin", 
    "in-dataset_implicative_shuffle_num": 977, 
    "in-dataset_question_shuffle_num": 28, 
    "inf_sentences_id": 687901, 
    "line": "When the shuttle does begin flying non-essential passengers again , NASA said , a teacher will be the first .", 
    "linenum": 8, 
    "matchl": "When the shuttle does begin flying non-essential passengers again , NASA said , a teacher will be the first .", 
    "out-dataset_implicative_shuffle_num": 3908, 
    "out-dataset_question_shuffle_num": 112, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 915481
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 7585, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "in-dataset_question_shuffle_num": 28, 
    "inf_sentences_id": 698033, 
    "line": "What are the three secondary colors ?", 
    "linenum": 1585, 
    "matchl": "What are the three secondary colors ?", 
    "out-dataset_question_shuffle_num": 113, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 925613
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 184229, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "know", 
    "in-dataset_implicative_shuffle_num": 992, 
    "in-dataset_question_shuffle_num": 28, 
    "inf_sentences_id": 184246, 
    "line": "What do n't you know ?!", 
    "linenum": 184229, 
    "matchl": "What do n't you know ?!", 
    "out-dataset_implicative_shuffle_num": 3970, 
    "out-dataset_question_shuffle_num": 114, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 411507
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 234536, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2600-0.txt", 
    "implicative_pattern": "happened", 
    "in-dataset_implicative_shuffle_num": 258814, 
    "in-dataset_question_shuffle_num": 28, 
    "inf_sentences_id": 940438, 
    "line": "\" Can something bad have happened to me ? \"", 
    "linenum": 5415, 
    "matchl": "\" Can something bad have happened to me ? \"", 
    "out-dataset_implicative_shuffle_num": 523329, 
    "out-dataset_question_shuffle_num": 115, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1168018
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 884, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/129", 
    "in-dataset_question_shuffle_num": 29, 
    "in-dataset_request_shuffle_num": 0, 
    "inf_sentences_id": 688180, 
    "line": "But what kind of initiative can you expect given the climate set by Congress ?", 
    "linenum": 11, 
    "matchl": "But what kind of initiative can you expect given the climate set by Congress ?", 
    "out-dataset_question_shuffle_num": 116, 
    "out-dataset_request_shuffle_num": 0, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 915760
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 1957, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "implicative_pattern": "miss", 
    "in-dataset_implicative_shuffle_num": 120, 
    "in-dataset_question_shuffle_num": 29, 
    "inf_sentences_id": 692405, 
    "line": "Who replaced Bert Parks as the host of The Miss America Pageant ?", 
    "linenum": 957, 
    "matchl": "Who replaced Bert Parks as the host of The Miss America Pageant ?", 
    "out-dataset_implicative_shuffle_num": 481, 
    "out-dataset_question_shuffle_num": 117, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 919985
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 55689, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 29, 
    "inf_sentences_id": 55705, 
    "line": "How long have you been dating ?", 
    "linenum": 55689, 
    "matchl": "How long have you been dating ?", 
    "out-dataset_question_shuffle_num": 118, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 282967
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 353659, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/3600-0.txt", 
    "implicative_pattern": "makes", 
    "in-dataset_implicative_shuffle_num": 184239, 
    "in-dataset_question_shuffle_num": 29, 
    "inf_sentences_id": 1059562, 
    "line": "Which makes me hope , that the further I remove from the first , and the nearer I approach to the latter , I shall the more easily exchange the one for the other .", 
    "linenum": 1460, 
    "matchl": "Which makes me hope , that the further I remove from the first , and the nearer I approach to the latter , I shall the more easily exchange the one for the other .", 
    "out-dataset_implicative_shuffle_num": 374179, 
    "out-dataset_question_shuffle_num": 119, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1287142
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1824, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/46", 
    "in-dataset_question_shuffle_num": 30, 
    "inf_sentences_id": 689120, 
    "line": "Are they going to fight each other ?", 
    "linenum": 23, 
    "matchl": "Are they going to fight each other ?", 
    "out-dataset_question_shuffle_num": 120, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 916700
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 6300, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "used", 
    "in-dataset_implicative_shuffle_num": 3490, 
    "in-dataset_question_shuffle_num": 30, 
    "inf_sentences_id": 696748, 
    "line": "What chemicals are used in lethal injection ?", 
    "linenum": 300, 
    "matchl": "What chemicals are used in lethal injection ?", 
    "out-dataset_implicative_shuffle_num": 12459, 
    "out-dataset_question_shuffle_num": 121, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 924328
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 342582, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "get", 
    "in-dataset_implicative_shuffle_num": 280626, 
    "in-dataset_question_shuffle_num": 30, 
    "inf_sentences_id": 342601, 
    "line": "When the sun comes up , I 'll get out of bed .", 
    "linenum": 342582, 
    "matchl": "When the sun comes up , I 'll get out of bed .", 
    "out-dataset_implicative_shuffle_num": 546972, 
    "out-dataset_question_shuffle_num": 122, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 569860
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 105021, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1404.txt.utf-8", 
    "in-dataset_question_shuffle_num": 30, 
    "inf_sentences_id": 810922, 
    "line": "And how far does this combination characterize the plan which has been reported by the convention ?", 
    "linenum": 4935, 
    "matchl": "And how far does this combination characterize the plan which has been reported by the convention ?", 
    "out-dataset_question_shuffle_num": 123, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 1038502
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1737, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/43", 
    "implicative_pattern": "show", 
    "in-dataset_implicative_shuffle_num": 784, 
    "in-dataset_question_shuffle_num": 31, 
    "inf_sentences_id": 689033, 
    "line": "The top 10 shows were: `` The Karen Carpenter Story , '' `` Murder , She Wrote , '' `` 60 Minutes , '' `` NFL Playoff Post-Game Show , '' all CBS ; ABC 's `` Roseanne , '' NBC 's `` The Cosby Show '' and `` Cheers , '' ABC 's `` Who 's the Boss ? '' and NBC 's `` A Different World '' and `` Unsolved Mysteries . ''", 
    "linenum": 7, 
    "matchl": "The top 10 shows were: `` The Karen Carpenter Story , '' `` Murder , She Wrote , '' `` 60 Minutes , '' `` NFL Playoff Post-Game Show , '' all CBS ; ABC 's `` Roseanne , '' NBC 's `` The Cosby Show '' and `` Cheers , '' ABC 's `` Who 's the Boss ? '' and NBC 's `` A Different World '' and `` Unsolved Mysteries . ''", 
    "out-dataset_implicative_shuffle_num": 3136, 
    "out-dataset_question_shuffle_num": 124, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 916613
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 7802, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "made", 
    "in-dataset_implicative_shuffle_num": 1975, 
    "in-dataset_question_shuffle_num": 31, 
    "inf_sentences_id": 698250, 
    "line": "What Apollo 11 astronaut minded the store while Armstrong and Aldrin made history ?", 
    "linenum": 1802, 
    "matchl": "What Apollo 11 astronaut minded the store while Armstrong and Aldrin made history ?", 
    "out-dataset_implicative_shuffle_num": 7901, 
    "out-dataset_question_shuffle_num": 125, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 925830
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 360807, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 31, 
    "inf_sentences_id": 360826, 
    "line": "Why am I so sleepy ?", 
    "linenum": 360807, 
    "matchl": "Why am I so sleepy ?", 
    "out-dataset_question_shuffle_num": 126, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 588085
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 73847, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/135-0.txt", 
    "implicative_pattern": "allowed", 
    "in-dataset_implicative_shuffle_num": 247796, 
    "in-dataset_question_shuffle_num": 31, 
    "inf_sentences_id": 779747, 
    "line": "When he saw that this wretched resource was becoming exhausted , he gave up his garden and allowed it to run to waste .", 
    "linenum": 25420, 
    "matchl": "When he saw that this wretched resource was becoming exhausted , he gave up his garden and allowed it to run to waste .", 
    "out-dataset_implicative_shuffle_num": 501293, 
    "out-dataset_question_shuffle_num": 127, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1007327
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1565, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/35", 
    "implicative_pattern": "said", 
    "in-dataset_implicative_shuffle_num": 1927, 
    "in-dataset_question_shuffle_num": 32, 
    "inf_sentences_id": 688861, 
    "line": "When he reached for his gun , the men shot him in the thigh , police said .", 
    "linenum": 3, 
    "matchl": "When he reached for his gun , the men shot him in the thigh , police said .", 
    "out-dataset_implicative_shuffle_num": 7708, 
    "out-dataset_question_shuffle_num": 128, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 916441
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 11009, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_question_shuffle_num": 32, 
    "inf_sentences_id": 701457, 
    "line": "What is the probability that at least 2 out of 25 people will have the same birthday ?", 
    "linenum": 1009, 
    "matchl": "What is the probability that at least 2 out of 25 people will have the same birthday ?", 
    "out-dataset_question_shuffle_num": 129, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 929037
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 687086, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 32, 
    "inf_sentences_id": 687108, 
    "line": "Are you sure this is n't some kind of mistake ?", 
    "linenum": 687086, 
    "matchl": "Are you sure this is n't some kind of mistake ?", 
    "out-dataset_question_shuffle_num": 130, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 914364
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 420642, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/514.txt.utf-8", 
    "implicative_pattern": "seeing", 
    "in-dataset_implicative_shuffle_num": 135799, 
    "in-dataset_question_shuffle_num": 32, 
    "inf_sentences_id": 1126546, 
    "line": "Did you do it on your own responsibility ? \" asked Laurie , as he seated her in the hall chair and took off the rebellious boots , seeing how her hands shook .", 
    "linenum": 3803, 
    "matchl": "Did you do it on your own responsibility ? \" asked Laurie , as he seated her in the hall chair and took off the rebellious boots , seeing how her hands shook .", 
    "out-dataset_implicative_shuffle_num": 277299, 
    "out-dataset_question_shuffle_num": 131, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1354126
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1827, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/46", 
    "in-dataset_question_shuffle_num": 33, 
    "inf_sentences_id": 689123, 
    "line": "How is it going to break up ?", 
    "linenum": 26, 
    "matchl": "How is it going to break up ?", 
    "out-dataset_question_shuffle_num": 132, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 916703
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 11294, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_question_shuffle_num": 33, 
    "inf_sentences_id": 701742, 
    "line": "What was a Mae West on a World War II battleship ?", 
    "linenum": 1294, 
    "matchl": "What was a Mae West on a World War II battleship ?", 
    "out-dataset_question_shuffle_num": 133, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 929322
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 495106, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 33, 
    "inf_sentences_id": 495126, 
    "line": "Why did you poison Tom ?", 
    "linenum": 495106, 
    "matchl": "Why did you poison Tom ?", 
    "out-dataset_question_shuffle_num": 134, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 722384
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 220051, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2554-0.txt", 
    "implicative_pattern": "mean", 
    "in-dataset_implicative_shuffle_num": 164487, 
    "in-dataset_question_shuffle_num": 33, 
    "inf_sentences_id": 925953, 
    "line": "\" What do you mean by ' more honourable '? I do n't understand such expressions to describe human activity .", 
    "linenum": 9617, 
    "matchl": "\" What do you mean by ' more honourable '? I do n't understand such expressions to describe human activity .", 
    "out-dataset_implicative_shuffle_num": 334675, 
    "out-dataset_question_shuffle_num": 135, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1153533
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 877, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/129", 
    "in-dataset_question_shuffle_num": 34, 
    "inf_sentences_id": 688173, 
    "line": "What went wrong in Panama is a fitting subject for public and congressional inquiry .", 
    "linenum": 4, 
    "matchl": "What went wrong in Panama is a fitting subject for public and congressional inquiry .", 
    "out-dataset_question_shuffle_num": 136, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 915753
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 14321, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_question_shuffle_num": 34, 
    "inf_sentences_id": 704769, 
    "line": "How many cards is each player dealt in Contract Bridge ?", 
    "linenum": 4321, 
    "matchl": "How many cards is each player dealt in Contract Bridge ?", 
    "out-dataset_question_shuffle_num": 137, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 932349
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 403110, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 34, 
    "inf_sentences_id": 403130, 
    "line": "You 're students , are n't you ?", 
    "linenum": 403110, 
    "matchl": "You 're students , are n't you ?", 
    "out-dataset_question_shuffle_num": 138, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 630388
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 276164, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/28054-0.txt", 
    "in-dataset_question_shuffle_num": 34, 
    "inf_sentences_id": 982066, 
    "line": "Do n't cry , Grigory , we 'll reduce him to smoke and ashes in a moment .", 
    "linenum": 3739, 
    "matchl": "Do n't cry , Grigory , we 'll reduce him to smoke and ashes in a moment .", 
    "out-dataset_question_shuffle_num": 139, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 1209646
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1892, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/49", 
    "implicative_pattern": "know", 
    "in-dataset_counterfactual_shuffle_num": 17, 
    "in-dataset_implicative_shuffle_num": 500, 
    "in-dataset_question_shuffle_num": 35, 
    "inf_sentences_id": 689188, 
    "line": "`` Suddenly , ambassadors wanted to know what to do if they got calls from a PLO representative , saying , ` I 've been told we can have a dialogue , when can we meet ? ' '' the official said .", 
    "linenum": 11, 
    "matchl": "`` Suddenly , ambassadors wanted to know what to do if they got calls from a PLO representative , saying , ` I 've been told we can have a dialogue , when can we meet ? ' '' the official said .", 
    "out-dataset_counterfactual_shuffle_num": 68, 
    "out-dataset_implicative_shuffle_num": 2000, 
    "out-dataset_question_shuffle_num": 140, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 916768
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 14539, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "meaning", 
    "in-dataset_implicative_shuffle_num": 2160, 
    "in-dataset_question_shuffle_num": 35, 
    "inf_sentences_id": 704987, 
    "line": "What 's the meaning of the name Tatiana ?", 
    "linenum": 4539, 
    "matchl": "What 's the meaning of the name Tatiana ?", 
    "out-dataset_implicative_shuffle_num": 8469, 
    "out-dataset_question_shuffle_num": 141, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 932567
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 649243, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 35, 
    "inf_sentences_id": 649265, 
    "line": "Why do men 's and women 's clothes have buttons on opposite sides ?", 
    "linenum": 649243, 
    "matchl": "Why do men 's and women 's clothes have buttons on opposite sides ?", 
    "out-dataset_question_shuffle_num": 142, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 876521
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 389218, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/4300-0.txt", 
    "in-dataset_question_shuffle_num": 35, 
    "inf_sentences_id": 1095121, 
    "line": "Lenehan opened most genial arms. Who ?", 
    "linenum": 11447, 
    "matchl": "Lenehan opened most genial arms. Who ?", 
    "out-dataset_question_shuffle_num": 143, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 1322701
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 244, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/106", 
    "in-dataset_question_shuffle_num": 36, 
    "inf_sentences_id": 687540, 
    "line": "When federal regulations changed in 1985 from one layer of clay and plastic to two , earlier burial cells were not retrofitted .", 
    "linenum": 28, 
    "matchl": "When federal regulations changed in 1985 from one layer of clay and plastic to two , earlier burial cells were not retrofitted .", 
    "out-dataset_question_shuffle_num": 144, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 915120
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 12386, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_question_shuffle_num": 36, 
    "inf_sentences_id": 702834, 
    "line": "Which of the following did not receive a 1983 `` Outstanding Mother Award '' from the National Mother 's Day Committee ?", 
    "linenum": 2386, 
    "matchl": "Which of the following did not receive a 1983 `` Outstanding Mother Award '' from the National Mother 's Day Committee ?", 
    "out-dataset_question_shuffle_num": 145, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 930414
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 330091, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 36, 
    "in-dataset_request_shuffle_num": 7062, 
    "inf_sentences_id": 330110, 
    "line": "Would you take Tom to Boston with you ?", 
    "linenum": 330091, 
    "matchl": "Would you take Tom to Boston with you ?", 
    "out-dataset_question_shuffle_num": 146, 
    "out-dataset_request_shuffle_num": 10403, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 557369
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 8488, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1184-0.txt", 
    "implicative_pattern": "said", 
    "in-dataset_implicative_shuffle_num": 94749, 
    "in-dataset_question_shuffle_num": 36, 
    "inf_sentences_id": 714388, 
    "line": "\" Sinbad the Sailor ? \" he said .", 
    "linenum": 6965, 
    "matchl": "\" Sinbad the Sailor ? \" he said .", 
    "out-dataset_implicative_shuffle_num": 195199, 
    "out-dataset_question_shuffle_num": 147, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 941968
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 557, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/116", 
    "implicative_pattern": "failing", 
    "in-dataset_implicative_shuffle_num": 158, 
    "in-dataset_question_shuffle_num": 37, 
    "inf_sentences_id": 687853, 
    "line": "When the museum did not return the painting as ordered , a magistrate charged chief curator Jean-Daniel Ludmann , 51 , with `` breach of trust , '' for failing to do so .", 
    "linenum": 3, 
    "matchl": "When the museum did not return the painting as ordered , a magistrate charged chief curator Jean-Daniel Ludmann , 51 , with `` breach of trust , '' for failing to do so .", 
    "out-dataset_implicative_shuffle_num": 632, 
    "out-dataset_question_shuffle_num": 148, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 915433
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 8143, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "in-dataset_question_shuffle_num": 37, 
    "inf_sentences_id": 698591, 
    "line": "What ocean was Amelia Earhart flying over when she disappeared ?", 
    "linenum": 2143, 
    "matchl": "What ocean was Amelia Earhart flying over when she disappeared ?", 
    "out-dataset_question_shuffle_num": 149, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 926171
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 158424, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 37, 
    "inf_sentences_id": 158441, 
    "line": "Have you recently taken a trip anywhere ?", 
    "linenum": 158424, 
    "matchl": "Have you recently taken a trip anywhere ?", 
    "out-dataset_question_shuffle_num": 150, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 385702
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 333763, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/33.txt.utf-8", 
    "implicative_pattern": "prove", 
    "in-dataset_implicative_shuffle_num": 7035, 
    "in-dataset_question_shuffle_num": 37, 
    "inf_sentences_id": 1039666, 
    "line": "Hast thou enticed me into a bond that will prove the ruin of my soul ? \"", 
    "linenum": 874, 
    "matchl": "Hast thou enticed me into a bond that will prove the ruin of my soul ? \"", 
    "out-dataset_implicative_shuffle_num": 19771, 
    "out-dataset_question_shuffle_num": 151, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1267246
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2721, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/81", 
    "implicative_pattern": "say", 
    "in-dataset_implicative_shuffle_num": 1867, 
    "in-dataset_question_shuffle_num": 38, 
    "inf_sentences_id": 690017, 
    "line": "`` Did he say he had the murders done ? ''", 
    "linenum": 18, 
    "matchl": "`` Did he say he had the murders done ? ''", 
    "out-dataset_implicative_shuffle_num": 7468, 
    "out-dataset_question_shuffle_num": 152, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 917597
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 4522, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "in-dataset_question_shuffle_num": 38, 
    "inf_sentences_id": 694970, 
    "line": "Where is the Isle of Man ?", 
    "linenum": 1522, 
    "matchl": "Where is the Isle of Man ?", 
    "out-dataset_question_shuffle_num": 153, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 922550
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 181750, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 38, 
    "inf_sentences_id": 181767, 
    "line": "Do you look your age ?", 
    "linenum": 181750, 
    "matchl": "Do you look your age ?", 
    "out-dataset_question_shuffle_num": 154, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 409028
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 103814, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1404.txt.utf-8", 
    "in-dataset_question_shuffle_num": 38, 
    "inf_sentences_id": 809715, 
    "line": "What effect may be produced by this partial reform , must be left to further experience .", 
    "linenum": 3728, 
    "matchl": "What effect may be produced by this partial reform , must be left to further experience .", 
    "out-dataset_question_shuffle_num": 155, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 1037295
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1118, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/15", 
    "implicative_pattern": "make", 
    "in-dataset_implicative_shuffle_num": 1107, 
    "in-dataset_question_shuffle_num": 39, 
    "inf_sentences_id": 688414, 
    "line": "Where we have a contribution to make , we do all we can .", 
    "linenum": 39, 
    "matchl": "Where we have a contribution to make , we do all we can .", 
    "out-dataset_implicative_shuffle_num": 4428, 
    "out-dataset_question_shuffle_num": 156, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 915994
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 10780, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_question_shuffle_num": 39, 
    "inf_sentences_id": 701228, 
    "line": "What Asian country has a bill of rights for cows ?", 
    "linenum": 780, 
    "matchl": "What Asian country has a bill of rights for cows ?", 
    "out-dataset_question_shuffle_num": 157, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 928808
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 226416, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 39, 
    "inf_sentences_id": 226434, 
    "line": "How much time do we have ?", 
    "linenum": 226416, 
    "matchl": "How much time do we have ?", 
    "out-dataset_question_shuffle_num": 158, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 453694
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 374279, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/4093.txt.utf-8", 
    "implicative_pattern": "see", 
    "in-dataset_implicative_shuffle_num": 120546, 
    "in-dataset_question_shuffle_num": 39, 
    "inf_sentences_id": 1080182, 
    "line": "Do you see anything absurd in my being overjoyed at the news !", 
    "linenum": 4239, 
    "matchl": "Do you see anything absurd in my being overjoyed at the news !", 
    "out-dataset_implicative_shuffle_num": 246793, 
    "out-dataset_question_shuffle_num": 159, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1307762
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2799, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/85", 
    "in-dataset_question_shuffle_num": 40, 
    "inf_sentences_id": 690095, 
    "line": "When President-elect Bush sits down later this week with his Cabinet choices , the question is whether there will be an empty seat at the table .", 
    "linenum": 0, 
    "matchl": "When President-elect Bush sits down later this week with his Cabinet choices , the question is whether there will be an empty seat at the table .", 
    "out-dataset_question_shuffle_num": 160, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 917675
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 13248, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "using", 
    "in-dataset_implicative_shuffle_num": 147, 
    "in-dataset_question_shuffle_num": 40, 
    "inf_sentences_id": 703696, 
    "line": "Who sued the Dannon yougurt company for using a character named Ron Raider for promotion ?", 
    "linenum": 3248, 
    "matchl": "Who sued the Dannon yougurt company for using a character named Ron Raider for promotion ?", 
    "out-dataset_implicative_shuffle_num": 589, 
    "out-dataset_question_shuffle_num": 161, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 931276
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 675063, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "happened", 
    "in-dataset_implicative_shuffle_num": 73677, 
    "in-dataset_question_shuffle_num": 40, 
    "inf_sentences_id": 675085, 
    "line": "What happened after Tom disappeared ?", 
    "linenum": 675063, 
    "matchl": "What happened after Tom disappeared ?", 
    "out-dataset_implicative_shuffle_num": 153054, 
    "out-dataset_question_shuffle_num": 162, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 902341
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 116272, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1497.txt.utf-8", 
    "in-dataset_question_shuffle_num": 40, 
    "inf_sentences_id": 822173, 
    "line": "And our guardian is both warrior and philosopher ?", 
    "linenum": 6988, 
    "matchl": "And our guardian is both warrior and philosopher ?", 
    "out-dataset_question_shuffle_num": 163, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 1049753
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 678, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/120", 
    "in-dataset_question_shuffle_num": 41, 
    "inf_sentences_id": 687974, 
    "line": "`` Give me a wand ?", 
    "linenum": 2, 
    "matchl": "`` Give me a wand ?", 
    "out-dataset_question_shuffle_num": 164, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 915554
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 15226, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_question_shuffle_num": 41, 
    "inf_sentences_id": 705674, 
    "line": "What character in The Beverly Hillbillies has the given names Daisy Moses ?", 
    "linenum": 5226, 
    "matchl": "What character in The Beverly Hillbillies has the given names Daisy Moses ?", 
    "out-dataset_question_shuffle_num": 165, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 933254
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 409565, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "tell", 
    "in-dataset_implicative_shuffle_num": 51526, 
    "in-dataset_question_shuffle_num": 41, 
    "in-dataset_request_shuffle_num": 6991, 
    "inf_sentences_id": 409585, 
    "line": "Could you tell us what happened next ?", 
    "linenum": 409565, 
    "matchl": "Could you tell us what happened next ?", 
    "out-dataset_implicative_shuffle_num": 108752, 
    "out-dataset_question_shuffle_num": 166, 
    "out-dataset_request_shuffle_num": 10332, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 636843
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>if<mid>(was|were|had|<past>|<ppart>) .+", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 52145, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/135-0.txt", 
    "implicative_pattern": "cease", 
    "in-dataset_counterfactual_shuffle_num": 10544, 
    "in-dataset_implicative_shuffle_num": 5257, 
    "in-dataset_question_shuffle_num": 41, 
    "in-dataset_request_shuffle_num": 1520, 
    "inf_sentences_id": 758045, 
    "line": "\" What would you do , Favourite , if I were to cease to love you ? \"", 
    "linenum": 3718, 
    "matchl": "\" What would you do , Favourite , if I were to cease to love you ? \"", 
    "out-dataset_counterfactual_shuffle_num": 21295, 
    "out-dataset_implicative_shuffle_num": 16215, 
    "out-dataset_question_shuffle_num": 167, 
    "out-dataset_request_shuffle_num": 3428, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "counterfactual", 
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 985625
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If)<mid>(was|were|had|<past>|<ppart>)<mid?>(<futr>) .+", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2607, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/77", 
    "implicative_pattern": "allow", 
    "in-dataset_counterfactual_shuffle_num": 95, 
    "in-dataset_implicative_shuffle_num": 1669, 
    "in-dataset_question_shuffle_num": 42, 
    "inf_sentences_id": 689903, 
    "line": "He added , referring to Libyan leader Col. Moammar Gadhafi: `` Even if an accord were reached for investigators to leave the moment they had a suspicion , who in their right mind would believe that someone like Colonel Gadhafi would allow it to happen ? ''", 
    "linenum": 32, 
    "matchl": "He added , referring to Libyan leader Col. Moammar Gadhafi: `` Even if an accord were reached for investigators to leave the moment they had a suspicion , who in their right mind would believe that someone like Colonel Gadhafi would allow it to happen ? ''", 
    "out-dataset_counterfactual_shuffle_num": 380, 
    "out-dataset_implicative_shuffle_num": 6676, 
    "out-dataset_question_shuffle_num": 168, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 917483
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 5410, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "in-dataset_question_shuffle_num": 42, 
    "inf_sentences_id": 695858, 
    "line": "What does 7847+5943 equal ?", 
    "linenum": 2410, 
    "matchl": "What does 7847+5943 equal ?", 
    "out-dataset_question_shuffle_num": 169, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 923438
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 223879, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 42, 
    "inf_sentences_id": 223897, 
    "line": "What wonderful weather !", 
    "linenum": 223879, 
    "matchl": "What wonderful weather !", 
    "out-dataset_question_shuffle_num": 170, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 451157
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 240069, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2600-0.txt", 
    "in-dataset_question_shuffle_num": 42, 
    "inf_sentences_id": 945971, 
    "line": "\" Now , what are you pestewing me for ? \" cried Denisov , suddenly losing his temper .", 
    "linenum": 10948, 
    "matchl": "\" Now , what are you pestewing me for ? \" cried Denisov , suddenly losing his temper .", 
    "out-dataset_question_shuffle_num": 171, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 1173551
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1689, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/40", 
    "implicative_pattern": "said", 
    "in-dataset_implicative_shuffle_num": 1552, 
    "in-dataset_question_shuffle_num": 43, 
    "inf_sentences_id": 688985, 
    "line": "She said the vigil was both for the family members and to `` ask governments: How many more days can a normal human being take ?", 
    "linenum": 4, 
    "matchl": "She said the vigil was both for the family members and to `` ask governments: How many more days can a normal human being take ?", 
    "out-dataset_implicative_shuffle_num": 6208, 
    "out-dataset_question_shuffle_num": 172, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 916565
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 2914, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "in-dataset_question_shuffle_num": 43, 
    "inf_sentences_id": 693362, 
    "line": "Who 's the only man to have won the Olympic decathlon twice ?", 
    "linenum": 1914, 
    "matchl": "Who 's the only man to have won the Olympic decathlon twice ?", 
    "out-dataset_question_shuffle_num": 173, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 920942
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 506029, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 43, 
    "inf_sentences_id": 506050, 
    "line": "Why were you with them ?", 
    "linenum": 506029, 
    "matchl": "Why were you with them ?", 
    "out-dataset_question_shuffle_num": 174, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 733307
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 419968, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/514.txt.utf-8", 
    "implicative_pattern": "know", 
    "in-dataset_implicative_shuffle_num": 48117, 
    "in-dataset_question_shuffle_num": 43, 
    "inf_sentences_id": 1125872, 
    "line": "She stood and stared at him for a minute , looking both surprised and displeased , then walked on , saying sharply , \" How do you know ? \"", 
    "linenum": 3129, 
    "matchl": "She stood and stared at him for a minute , looking both surprised and displeased , then walked on , saying sharply , \" How do you know ? \"", 
    "out-dataset_implicative_shuffle_num": 101935, 
    "out-dataset_question_shuffle_num": 175, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1353452
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 374, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/11", 
    "implicative_pattern": "help", 
    "in-dataset_implicative_shuffle_num": 1200, 
    "in-dataset_question_shuffle_num": 44, 
    "inf_sentences_id": 687670, 
    "line": "Do n't wait -- a savings institution needs your help now !", 
    "linenum": 16, 
    "matchl": "Do n't wait -- a savings institution needs your help now !", 
    "out-dataset_implicative_shuffle_num": 4800, 
    "out-dataset_question_shuffle_num": 176, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 915250
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 15320, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_question_shuffle_num": 44, 
    "inf_sentences_id": 705768, 
    "line": "What 's a Craps player called ?", 
    "linenum": 5320, 
    "matchl": "What 's a Craps player called ?", 
    "out-dataset_question_shuffle_num": 177, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 933348
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 236569, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "tried", 
    "in-dataset_implicative_shuffle_num": 104680, 
    "in-dataset_question_shuffle_num": 44, 
    "inf_sentences_id": 236587, 
    "line": "Have you tried it before ?", 
    "linenum": 236569, 
    "matchl": "Have you tried it before ?", 
    "out-dataset_implicative_shuffle_num": 215060, 
    "out-dataset_question_shuffle_num": 178, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 463847
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 40194, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1260.txt.utf-8", 
    "implicative_pattern": "tell", 
    "in-dataset_implicative_shuffle_num": 40764, 
    "in-dataset_question_shuffle_num": 44, 
    "inf_sentences_id": 746094, 
    "line": "What he suddenly saw on this blank paper , it was impossible for me to tell ; but something had caught his eye .", 
    "linenum": 7902, 
    "matchl": "What he suddenly saw on this blank paper , it was impossible for me to tell ; but something had caught his eye .", 
    "out-dataset_implicative_shuffle_num": 87229, 
    "out-dataset_question_shuffle_num": 179, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 973674
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1448, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/3", 
    "in-dataset_question_shuffle_num": 45, 
    "in-dataset_request_shuffle_num": 1, 
    "inf_sentences_id": 688744, 
    "line": "What would you do ? ''", 
    "linenum": 22, 
    "matchl": "What would you do ? ''", 
    "out-dataset_question_shuffle_num": 180, 
    "out-dataset_request_shuffle_num": 4, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 916324
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 7396, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "in-dataset_question_shuffle_num": 45, 
    "inf_sentences_id": 697844, 
    "line": "What does e.g. stand for ?", 
    "linenum": 1396, 
    "matchl": "What does e.g. stand for ?", 
    "out-dataset_question_shuffle_num": 181, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 925424
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 181731, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 45, 
    "inf_sentences_id": 181748, 
    "line": "Do you feel birthdays are important ?", 
    "linenum": 181731, 
    "matchl": "Do you feel birthdays are important ?", 
    "out-dataset_question_shuffle_num": 182, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 409009
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 93130, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1400-0.txt", 
    "implicative_pattern": "know", 
    "in-dataset_implicative_shuffle_num": 201149, 
    "in-dataset_question_shuffle_num": 45, 
    "inf_sentences_id": 799030, 
    "line": "\" You know best , Pip ; but do n't you think you are happier as you are ? \"", 
    "linenum": 2480, 
    "matchl": "\" You know best , Pip ; but do n't you think you are happier as you are ? \"", 
    "out-dataset_implicative_shuffle_num": 407999, 
    "out-dataset_question_shuffle_num": 183, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1026610
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1141, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/16", 
    "in-dataset_question_shuffle_num": 46, 
    "inf_sentences_id": 688437, 
    "line": "`` What are they for , for pills ? ''", 
    "linenum": 21, 
    "matchl": "`` What are they for , for pills ? ''", 
    "out-dataset_question_shuffle_num": 184, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 916017
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 6895, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "in-dataset_question_shuffle_num": 46, 
    "inf_sentences_id": 697343, 
    "line": "How many casinos are in Atlantic City , NJ ?", 
    "linenum": 895, 
    "matchl": "How many casinos are in Atlantic City , NJ ?", 
    "out-dataset_question_shuffle_num": 185, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 924923
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 47081, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 46, 
    "inf_sentences_id": 47097, 
    "line": "What a feast we had when we visited my aunt !", 
    "linenum": 47081, 
    "matchl": "What a feast we had when we visited my aunt !", 
    "out-dataset_question_shuffle_num": 186, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 274359
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 206949, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2542.txt.utf-8", 
    "in-dataset_question_shuffle_num": 46, 
    "inf_sentences_id": 912851, 
    "line": "Linde ( in a dejected and timid voice). How do you do , Nora ?", 
    "linenum": 241, 
    "matchl": "Linde ( in a dejected and timid voice). How do you do , Nora ?", 
    "out-dataset_question_shuffle_num": 187, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 1140431
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 7096, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "make", 
    "in-dataset_implicative_shuffle_num": 481, 
    "in-dataset_question_shuffle_num": 47, 
    "inf_sentences_id": 697544, 
    "line": "How do you make panoramic sugar eggs for Easter - the ones with the scene inside ?", 
    "linenum": 1096, 
    "matchl": "How do you make panoramic sugar eggs for Easter - the ones with the scene inside ?", 
    "out-dataset_implicative_shuffle_num": 1925, 
    "out-dataset_question_shuffle_num": 188, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 925124
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 570191, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 47, 
    "inf_sentences_id": 570212, 
    "line": "How close is too close ?", 
    "linenum": 570191, 
    "matchl": "How close is too close ?", 
    "out-dataset_question_shuffle_num": 189, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 797469
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 273031, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/28054-0.txt", 
    "implicative_pattern": "made", 
    "in-dataset_implicative_shuffle_num": 23173, 
    "in-dataset_question_shuffle_num": 47, 
    "inf_sentences_id": 978933, 
    "line": "\" Who has made me a judge over them ? \" was all he said , smilingly , to Alyosha .", 
    "linenum": 606, 
    "matchl": "\" Who has made me a judge over them ? \" was all he said , smilingly , to Alyosha .", 
    "out-dataset_implicative_shuffle_num": 52047, 
    "out-dataset_question_shuffle_num": 190, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1206513
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 6814, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "in-dataset_question_shuffle_num": 48, 
    "inf_sentences_id": 697262, 
    "line": "What is an isthmus ?", 
    "linenum": 814, 
    "matchl": "What is an isthmus ?", 
    "out-dataset_question_shuffle_num": 191, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 924842
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 52531, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "get", 
    "in-dataset_implicative_shuffle_num": 223844, 
    "in-dataset_question_shuffle_num": 48, 
    "inf_sentences_id": 52547, 
    "line": "Shall I get some for you ?", 
    "linenum": 52531, 
    "matchl": "Shall I get some for you ?", 
    "out-dataset_implicative_shuffle_num": 453388, 
    "out-dataset_question_shuffle_num": 192, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 279809
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 463728, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/786-0.txt", 
    "implicative_pattern": "remaining", 
    "in-dataset_implicative_shuffle_num": 214782, 
    "in-dataset_question_shuffle_num": 48, 
    "inf_sentences_id": 1169632, 
    "line": "The sole remaining question then is : Shall I marry him ?", 
    "linenum": 2025, 
    "matchl": "The sole remaining question then is : Shall I marry him ?", 
    "out-dataset_implicative_shuffle_num": 435265, 
    "out-dataset_question_shuffle_num": 193, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1397212
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 7469, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "forces", 
    "in-dataset_implicative_shuffle_num": 1933, 
    "in-dataset_question_shuffle_num": 49, 
    "inf_sentences_id": 697917, 
    "line": "What two commanders directed the forces in the Battle of El Alamein ?", 
    "linenum": 1469, 
    "matchl": "What two commanders directed the forces in the Battle of El Alamein ?", 
    "out-dataset_implicative_shuffle_num": 7733, 
    "out-dataset_question_shuffle_num": 194, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 925497
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 497796, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "notes", 
    "in-dataset_implicative_shuffle_num": 207226, 
    "in-dataset_question_shuffle_num": 49, 
    "inf_sentences_id": 497816, 
    "line": "Do n't throw away your notes .", 
    "linenum": 497796, 
    "matchl": "Do n't throw away your notes .", 
    "out-dataset_implicative_shuffle_num": 420152, 
    "out-dataset_question_shuffle_num": 195, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 725074
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If)<mid>(was|were|had|<past>|<ppart>)<mid?>(<futr>) .+", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 316344, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/30360.txt.utf-8", 
    "implicative_pattern": "comes", 
    "in-dataset_counterfactual_shuffle_num": 27501, 
    "in-dataset_implicative_shuffle_num": 123172, 
    "in-dataset_question_shuffle_num": 49, 
    "inf_sentences_id": 1022247, 
    "line": "\" They be all up at the hay , \" said she , \" but Missus comes every fine morning to the dairy ( that was true ), she wo n't be here for an hour ; but if she were , what would I do ? my husband will be back , he 'll take breakfast to the fields , to save time , in chance of wet again coming on. Oh ! do go . \"", 
    "linenum": 4073, 
    "matchl": "\" They be all up at the hay , \" said she , \" but Missus comes every fine morning to the dairy ( that was true ), she wo n't be here for an hour ; but if she were , what would I do ? my husband will be back , he 'll take breakfast to the fields , to save time , in chance of wet again coming on. Oh ! do go . \"", 
    "out-dataset_counterfactual_shuffle_num": 43357, 
    "out-dataset_implicative_shuffle_num": 252045, 
    "out-dataset_question_shuffle_num": 196, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1249827
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 6853, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "invented", 
    "in-dataset_implicative_shuffle_num": 3375, 
    "in-dataset_question_shuffle_num": 50, 
    "inf_sentences_id": 697301, 
    "line": "What is the full name of the man who invented the multicolored game cube that has 42.3 quintillion potential combinations ?", 
    "linenum": 853, 
    "matchl": "What is the full name of the man who invented the multicolored game cube that has 42.3 quintillion potential combinations ?", 
    "out-dataset_implicative_shuffle_num": 12114, 
    "out-dataset_question_shuffle_num": 197, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 924881
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 130784, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 50, 
    "in-dataset_request_shuffle_num": 7534, 
    "inf_sentences_id": 130801, 
    "line": "Could you exchange it with another one ?", 
    "linenum": 130784, 
    "matchl": "Could you exchange it with another one ?", 
    "out-dataset_question_shuffle_num": 198, 
    "out-dataset_request_shuffle_num": 10875, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 358062
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 101087, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1404.txt.utf-8", 
    "in-dataset_question_shuffle_num": 50, 
    "inf_sentences_id": 806988, 
    "line": "Why has government been instituted at all ?", 
    "linenum": 1001, 
    "matchl": "Why has government been instituted at all ?", 
    "out-dataset_question_shuffle_num": 199, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question"
    ], 
    "ulf_sentences_id": 1034568
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 279, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/107", 
    "implicative_pattern": "happening", 
    "in-dataset_implicative_shuffle_num": 0, 
    "inf_sentences_id": 687575, 
    "line": "Ms. Shamir said in an interview: `` When I sat opposite the television last January , and they started showing me what was happening , I could n't sleep nights .", 
    "linenum": 15, 
    "matchl": "Ms. Shamir said in an interview: `` When I sat opposite the television last January , and they started showing me what was happening , I could n't sleep nights .", 
    "out-dataset_implicative_shuffle_num": 0, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 915155
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 12134, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "live", 
    "in-dataset_implicative_shuffle_num": 0, 
    "in-dataset_question_shuffle_num": 685, 
    "inf_sentences_id": 702582, 
    "line": "What is the name of the planet that the Ewoks live on ?", 
    "linenum": 2134, 
    "matchl": "What is the name of the planet that the Ewoks live on ?", 
    "out-dataset_implicative_shuffle_num": 1, 
    "out-dataset_question_shuffle_num": 2102, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 930162
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If)<mid>(was|were|had|<past>|<ppart>)<mid?>(<futr>) .+", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 159994, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "truth", 
    "in-dataset_counterfactual_shuffle_num": 15158, 
    "in-dataset_implicative_shuffle_num": 0, 
    "inf_sentences_id": 160011, 
    "line": "The truth is always something that is told , not something that is known. If there were no speaking or writing , there would be no truth about anything. There would only be what is .", 
    "linenum": 159994, 
    "matchl": "The truth is always something that is told , not something that is known. If there were no speaking or writing , there would be no truth about anything. There would only be what is .", 
    "out-dataset_counterfactual_shuffle_num": 30522, 
    "out-dataset_implicative_shuffle_num": 2, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 387272
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 4639, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1184-0.txt", 
    "implicative_pattern": "work", 
    "in-dataset_implicative_shuffle_num": 0, 
    "in-dataset_question_shuffle_num": 19432, 
    "inf_sentences_id": 710539, 
    "line": "\" But for such a work you must have needed books--had you any ? \"", 
    "linenum": 3116, 
    "matchl": "\" But for such a work you must have needed books--had you any ? \"", 
    "out-dataset_implicative_shuffle_num": 3, 
    "out-dataset_question_shuffle_num": 54117, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 938119
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2948, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/9", 
    "implicative_pattern": "growing", 
    "in-dataset_implicative_shuffle_num": 1, 
    "inf_sentences_id": 690244, 
    "line": "\" This is a company that has invested in capacity additions more aggressively than any other company in the industry and now the industry is growing more slowly and they are suddenly poorly positioned , \" said Michael Stark , chip analyst at Robertson , Stephens & Co .", 
    "linenum": 13, 
    "matchl": "\" This is a company that has invested in capacity additions more aggressively than any other company in the industry and now the industry is growing more slowly and they are suddenly poorly positioned , \" said Michael Stark , chip analyst at Robertson , Stephens & Co .", 
    "out-dataset_implicative_shuffle_num": 4, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 917824
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 3188, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "mean", 
    "in-dataset_implicative_shuffle_num": 1, 
    "in-dataset_question_shuffle_num": 4878, 
    "inf_sentences_id": 693636, 
    "line": "What does gringo mean ?", 
    "linenum": 188, 
    "matchl": "What does gringo mean ?", 
    "out-dataset_implicative_shuffle_num": 5, 
    "out-dataset_question_shuffle_num": 14681, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 921216
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 151508, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "came", 
    "in-dataset_implicative_shuffle_num": 1, 
    "inf_sentences_id": 151525, 
    "line": "I came here yesterday .", 
    "linenum": 151508, 
    "matchl": "I came here yesterday .", 
    "out-dataset_implicative_shuffle_num": 6, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 378786
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 107230, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/148.txt.utf-8", 
    "implicative_pattern": "like", 
    "in-dataset_implicative_shuffle_num": 1, 
    "inf_sentences_id": 813131, 
    "line": "Accordingly , in the evening , when the workmen were gone , I assembled a number of my play-fellows , and working with them diligently like so many emmets , sometimes two or three to a stone , we brought them all away and built our little wharff .", 
    "linenum": 132, 
    "matchl": "Accordingly , in the evening , when the workmen were gone , I assembled a number of my play-fellows , and working with them diligently like so many emmets , sometimes two or three to a stone , we brought them all away and built our little wharff .", 
    "out-dataset_implicative_shuffle_num": 7, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1040711
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2984, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/91", 
    "implicative_pattern": "get", 
    "in-dataset_implicative_shuffle_num": 2, 
    "inf_sentences_id": 690280, 
    "line": "She sometimes arranged to get the three of them aboard the ships , where they dined with officers and heard tales about life on the high seas .", 
    "linenum": 9, 
    "matchl": "She sometimes arranged to get the three of them aboard the ships , where they dined with officers and heard tales about life on the high seas .", 
    "out-dataset_implicative_shuffle_num": 8, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 917860
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 10944, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "get", 
    "in-dataset_implicative_shuffle_num": 2, 
    "in-dataset_question_shuffle_num": 5152, 
    "inf_sentences_id": 701392, 
    "line": "Who was chairman of the Senate select committee that tried to get to the bottom of Watergate ?", 
    "linenum": 944, 
    "matchl": "Who was chairman of the Senate select committee that tried to get to the bottom of Watergate ?", 
    "out-dataset_implicative_shuffle_num": 9, 
    "out-dataset_question_shuffle_num": 15503, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 928972
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 516568, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "try", 
    "in-dataset_implicative_shuffle_num": 2, 
    "inf_sentences_id": 516589, 
    "line": "Let 's let them try that again .", 
    "linenum": 516568, 
    "matchl": "Let 's let them try that again .", 
    "out-dataset_implicative_shuffle_num": 10, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 743846
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 266092, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2701-0.txt", 
    "implicative_pattern": "living", 
    "in-dataset_implicative_shuffle_num": 2, 
    "inf_sentences_id": 971994, 
    "line": "But in each event--in the living act , the undoubted deed--there , some unknown but still reasoning thing puts forth the mouldings of its features from behind the unreasoning mask .", 
    "linenum": 3079, 
    "matchl": "But in each event--in the living act , the undoubted deed--there , some unknown but still reasoning thing puts forth the mouldings of its features from behind the unreasoning mask .", 
    "out-dataset_implicative_shuffle_num": 11, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1199574
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 246, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/106", 
    "implicative_pattern": "said", 
    "in-dataset_implicative_shuffle_num": 3, 
    "inf_sentences_id": 687542, 
    "line": "`` As technology progresses , we adopt it , '' said GSX Vice President Roger Davis .", 
    "linenum": 30, 
    "matchl": "`` As technology progresses , we adopt it , '' said GSX Vice President Roger Davis .", 
    "out-dataset_implicative_shuffle_num": 12, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 915122
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 7475, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 3, 
    "in-dataset_question_shuffle_num": 13400, 
    "in-dataset_request_shuffle_num": 5, 
    "inf_sentences_id": 697923, 
    "line": "Where can I find all the information I need to know about the English Civil War , 1642-1649 , ?", 
    "linenum": 1475, 
    "matchl": "Where can I find all the information I need to know about the English Civil War , 1642-1649 , ?", 
    "out-dataset_implicative_shuffle_num": 13, 
    "out-dataset_question_shuffle_num": 40247, 
    "out-dataset_request_shuffle_num": 17, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 925503
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 355726, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "used", 
    "in-dataset_implicative_shuffle_num": 3, 
    "inf_sentences_id": 355745, 
    "line": "The culture was completely different from the one she was used to .", 
    "linenum": 355726, 
    "matchl": "The culture was completely different from the one she was used to .", 
    "out-dataset_implicative_shuffle_num": 14, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 583004
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 41763, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1260.txt.utf-8", 
    "implicative_pattern": "said", 
    "in-dataset_implicative_shuffle_num": 3, 
    "inf_sentences_id": 747663, 
    "line": "\" It is a bright , sunny morning , sir , \" I said .", 
    "linenum": 9471, 
    "matchl": "\" It is a bright , sunny morning , sir , \" I said .", 
    "out-dataset_implicative_shuffle_num": 15, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 975243
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 3110, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/97", 
    "implicative_pattern": "alleged", 
    "in-dataset_implicative_shuffle_num": 4, 
    "inf_sentences_id": 690406, 
    "line": "Salem said $14 million was the largest back pay award ever obtained by the department in a case involving alleged sex or race discrimination .", 
    "linenum": 21, 
    "matchl": "Salem said $14 million was the largest back pay award ever obtained by the department in a case involving alleged sex or race discrimination .", 
    "out-dataset_implicative_shuffle_num": 16, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 917986
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 5706, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "said", 
    "in-dataset_implicative_shuffle_num": 4, 
    "in-dataset_question_shuffle_num": 11688, 
    "inf_sentences_id": 696154, 
    "line": "Who said : `` What contemptible scoundrel stole the cork from my lunch ? ''", 
    "linenum": 2706, 
    "matchl": "Who said : `` What contemptible scoundrel stole the cork from my lunch ? ''", 
    "out-dataset_implicative_shuffle_num": 17, 
    "out-dataset_question_shuffle_num": 35111, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 923734
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 330656, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "like", 
    "in-dataset_implicative_shuffle_num": 4, 
    "inf_sentences_id": 330675, 
    "line": "You were n't at Woodstock like I was .", 
    "linenum": 330656, 
    "matchl": "You were n't at Woodstock like I was .", 
    "out-dataset_implicative_shuffle_num": 18, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 557934
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 330302, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/3296.txt.utf-8", 
    "implicative_pattern": "stay", 
    "in-dataset_implicative_shuffle_num": 4, 
    "inf_sentences_id": 1036205, 
    "line": "And yet refusing to return without me , I scarcely persuaded her to stay that night in a place hard by our ship , where was an Oratory in memory of the blessed Cyprian .", 
    "linenum": 874, 
    "matchl": "And yet refusing to return without me , I scarcely persuaded her to stay that night in a place hard by our ship , where was an Oratory in memory of the blessed Cyprian .", 
    "out-dataset_implicative_shuffle_num": 19, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1263785
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2454, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/73", 
    "implicative_pattern": "agreed", 
    "in-dataset_implicative_shuffle_num": 5, 
    "inf_sentences_id": 689750, 
    "line": "Early last year , the city agreed to buy power wholesale from the Canton-based Ohio Power Co. at 3.1 cents per kilowatt hour .", 
    "linenum": 14, 
    "matchl": "Early last year , the city agreed to buy power wholesale from the Canton-based Ohio Power Co. at 3.1 cents per kilowatt hour .", 
    "out-dataset_implicative_shuffle_num": 20, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 917330
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 13714, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "get", 
    "in-dataset_implicative_shuffle_num": 5, 
    "in-dataset_question_shuffle_num": 12397, 
    "inf_sentences_id": 704162, 
    "line": "How do I get my LAN card activated so that it can hook up to another computer without using a HUB ?", 
    "linenum": 3714, 
    "matchl": "How do I get my LAN card activated so that it can hook up to another computer without using a HUB ?", 
    "out-dataset_implicative_shuffle_num": 21, 
    "out-dataset_question_shuffle_num": 37238, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 931742
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 430120, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "understand", 
    "in-dataset_implicative_shuffle_num": 5, 
    "inf_sentences_id": 430140, 
    "line": "I do not understand Tom 's ostensible contempt for satorial concerns of his peers .", 
    "linenum": 430120, 
    "matchl": "I do not understand Tom 's ostensible contempt for satorial concerns of his peers .", 
    "out-dataset_implicative_shuffle_num": 22, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 657398
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 251501, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2600-0.txt", 
    "implicative_pattern": "get", 
    "in-dataset_implicative_shuffle_num": 5, 
    "inf_sentences_id": 957403, 
    "line": "\" We do n't expect to get him home alive !", 
    "linenum": 22380, 
    "matchl": "\" We do n't expect to get him home alive !", 
    "out-dataset_implicative_shuffle_num": 23, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1184983
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1883, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/49", 
    "implicative_pattern": "allowed", 
    "in-dataset_implicative_shuffle_num": 6, 
    "inf_sentences_id": 689179, 
    "line": "`` There have been instructions that have allowed people in social settings to respond socially to introductions , '' Mrs. Oakley said .", 
    "linenum": 2, 
    "matchl": "`` There have been instructions that have allowed people in social settings to respond socially to introductions , '' Mrs. Oakley said .", 
    "out-dataset_implicative_shuffle_num": 24, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 916759
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 8426, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 6, 
    "in-dataset_question_shuffle_num": 6314, 
    "in-dataset_request_shuffle_num": 364, 
    "inf_sentences_id": 698874, 
    "line": "Where can I find the history of the Taiwanese language ?", 
    "linenum": 2426, 
    "matchl": "Where can I find the history of the Taiwanese language ?", 
    "out-dataset_implicative_shuffle_num": 25, 
    "out-dataset_question_shuffle_num": 18989, 
    "out-dataset_request_shuffle_num": 1094, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 926454
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 421383, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "mind", 
    "in-dataset_implicative_shuffle_num": 6, 
    "in-dataset_question_shuffle_num": 4888, 
    "in-dataset_request_shuffle_num": 10395, 
    "inf_sentences_id": 421403, 
    "line": "Would you mind not talking about your surgery now - I 'm trying to eat .", 
    "linenum": 421383, 
    "matchl": "Would you mind not talking about your surgery now - I 'm trying to eat .", 
    "out-dataset_implicative_shuffle_num": 26, 
    "out-dataset_question_shuffle_num": 14712, 
    "out-dataset_request_shuffle_num": 13736, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 648661
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 95978, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1400-0.txt", 
    "implicative_pattern": "think", 
    "in-dataset_implicative_shuffle_num": 6, 
    "inf_sentences_id": 801878, 
    "line": "But Herbert 's was a very different case , and it often caused me a twinge to think that I had done him evil service in crowding his sparely furnished chambers with incongruous upholstery work , and placing the Canary-breasted Avenger at his disposal .", 
    "linenum": 5328, 
    "matchl": "But Herbert 's was a very different case , and it often caused me a twinge to think that I had done him evil service in crowding his sparely furnished chambers with incongruous upholstery work , and placing the Canary-breasted Avenger at his disposal .", 
    "out-dataset_implicative_shuffle_num": 27, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1029458
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2514, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/74", 
    "implicative_pattern": "work", 
    "in-dataset_implicative_shuffle_num": 7, 
    "inf_sentences_id": 689810, 
    "line": "Desmond Anderson , who lives 400 yards from the airport 's main runway , said , ` The far side engine was on fire , backfiring and roaring away ... An Automobile Association manager , John McKnight , said: `` There are still people trapped and work is going on to free them .", 
    "linenum": 46, 
    "matchl": "Desmond Anderson , who lives 400 yards from the airport 's main runway , said , ` The far side engine was on fire , backfiring and roaring away ... An Automobile Association manager , John McKnight , said: `` There are still people trapped and work is going on to free them .", 
    "out-dataset_implicative_shuffle_num": 28, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 917390
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 3515, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "live", 
    "in-dataset_implicative_shuffle_num": 7, 
    "in-dataset_question_shuffle_num": 7717, 
    "inf_sentences_id": 693963, 
    "line": "What do I need to do to take my dog with me to live in Dominica , West Indies for a year ?", 
    "linenum": 515, 
    "matchl": "What do I need to do to take my dog with me to live in Dominica , West Indies for a year ?", 
    "out-dataset_implicative_shuffle_num": 29, 
    "out-dataset_question_shuffle_num": 23198, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 921543
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 156543, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "working", 
    "in-dataset_implicative_shuffle_num": 7, 
    "in-dataset_question_shuffle_num": 35833, 
    "inf_sentences_id": 156560, 
    "line": "Where are you working ?", 
    "linenum": 156543, 
    "matchl": "Where are you working ?", 
    "out-dataset_implicative_shuffle_num": 30, 
    "out-dataset_question_shuffle_num": 86918, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 383821
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 216176, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2554-0.txt", 
    "implicative_pattern": "remember", 
    "in-dataset_implicative_shuffle_num": 7, 
    "inf_sentences_id": 922078, 
    "line": "\" A-a-h ! Yes , I remember ....", 
    "linenum": 5742, 
    "matchl": "\" A-a-h ! Yes , I remember ....", 
    "out-dataset_implicative_shuffle_num": 31, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1149658
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2961, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/90", 
    "implicative_pattern": "permitted", 
    "in-dataset_implicative_shuffle_num": 8, 
    "inf_sentences_id": 690257, 
    "line": "It said all refugee boats were permitted to land and that arrivals were taken to a special camp in cooperation with the U.N. High Commissioner for Refugees .", 
    "linenum": 8, 
    "matchl": "It said all refugee boats were permitted to land and that arrivals were taken to a special camp in cooperation with the U.N. High Commissioner for Refugees .", 
    "out-dataset_implicative_shuffle_num": 32, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 917837
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 420, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_1000.raw", 
    "implicative_pattern": "reason", 
    "in-dataset_implicative_shuffle_num": 8, 
    "inf_sentences_id": 690868, 
    "line": "Give a reason for American Indians oftentimes dropping out of school .", 
    "linenum": 420, 
    "matchl": "Give a reason for American Indians oftentimes dropping out of school .", 
    "out-dataset_implicative_shuffle_num": 33, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 918448
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 118553, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "like", 
    "in-dataset_implicative_shuffle_num": 8, 
    "inf_sentences_id": 118570, 
    "line": "They like to play in the snow .", 
    "linenum": 118553, 
    "matchl": "They like to play in the snow .", 
    "out-dataset_implicative_shuffle_num": 34, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 345831
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 57649, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/135-0.txt", 
    "implicative_pattern": "accepting", 
    "in-dataset_implicative_shuffle_num": 8, 
    "inf_sentences_id": 763549, 
    "line": "Some feats of arms were serious ; the taking of the Trocadero , among others , was a fine military action ; but after all , we repeat , the trumpets of this war give back a cracked sound , the whole effect was suspicious ; history approves of France for making a difficulty about accepting this false triumph .", 
    "linenum": 9222, 
    "matchl": "Some feats of arms were serious ; the taking of the Trocadero , among others , was a fine military action ; but after all , we repeat , the trumpets of this war give back a cracked sound , the whole effect was suspicious ; history approves of France for making a difficulty about accepting this false triumph .", 
    "out-dataset_implicative_shuffle_num": 35, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 991129
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2179, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/62", 
    "implicative_pattern": "think", 
    "in-dataset_implicative_shuffle_num": 9, 
    "inf_sentences_id": 689475, 
    "line": "Prior to the awards ceremony , de la Renta , president of the council , said of Mrs. Reagan: `` I think she put American fashion on the pedestal where it belongs and brought elegance back to American fashion . ''", 
    "linenum": 10, 
    "matchl": "Prior to the awards ceremony , de la Renta , president of the council , said of Mrs. Reagan: `` I think she put American fashion on the pedestal where it belongs and brought elegance back to American fashion . ''", 
    "out-dataset_implicative_shuffle_num": 36, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 917055
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 7768, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "invented", 
    "in-dataset_implicative_shuffle_num": 9, 
    "in-dataset_question_shuffle_num": 4186, 
    "inf_sentences_id": 698216, 
    "line": "When was the first flush toilet invented ?", 
    "linenum": 1768, 
    "matchl": "When was the first flush toilet invented ?", 
    "out-dataset_implicative_shuffle_num": 37, 
    "out-dataset_question_shuffle_num": 12605, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 925796
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 92521, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "says", 
    "in-dataset_implicative_shuffle_num": 9, 
    "inf_sentences_id": 92537, 
    "line": "My little brother says that he had a dreadful dream last night .", 
    "linenum": 92521, 
    "matchl": "My little brother says that he had a dreadful dream last night .", 
    "out-dataset_implicative_shuffle_num": 38, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 319799
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 279447, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/28054-0.txt", 
    "implicative_pattern": "live", 
    "in-dataset_implicative_shuffle_num": 9, 
    "inf_sentences_id": 985349, 
    "line": "You do n't live on tea alone , I suppose , \" cried Ivan , apparently delighted at having got hold of Alyosha .", 
    "linenum": 7022, 
    "matchl": "You do n't live on tea alone , I suppose , \" cried Ivan , apparently delighted at having got hold of Alyosha .", 
    "out-dataset_implicative_shuffle_num": 39, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1212929
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 936, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/132", 
    "implicative_pattern": "use", 
    "in-dataset_implicative_shuffle_num": 10, 
    "inf_sentences_id": 688232, 
    "line": "The Justice Department has revised certain internal guidelines and clarified others in a move that could restrict the use of criminal racketeering charges against white-collar defendants .", 
    "linenum": 0, 
    "matchl": "The Justice Department has revised certain internal guidelines and clarified others in a move that could restrict the use of criminal racketeering charges against white-collar defendants .", 
    "out-dataset_implicative_shuffle_num": 40, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 915812
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 13770, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "uses", 
    "in-dataset_implicative_shuffle_num": 10, 
    "in-dataset_question_shuffle_num": 1980, 
    "inf_sentences_id": 704218, 
    "line": "What is the name of the deranged super-criminal Otto Octavius uses ?", 
    "linenum": 3770, 
    "matchl": "What is the name of the deranged super-criminal Otto Octavius uses ?", 
    "out-dataset_implicative_shuffle_num": 41, 
    "out-dataset_question_shuffle_num": 5987, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 931798
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 620650, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "makes", 
    "in-dataset_implicative_shuffle_num": 10, 
    "inf_sentences_id": 620672, 
    "line": "This song makes me homesick .", 
    "linenum": 620650, 
    "matchl": "This song makes me homesick .", 
    "out-dataset_implicative_shuffle_num": 42, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 847928
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 27191, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1184-0.txt", 
    "implicative_pattern": "found", 
    "in-dataset_implicative_shuffle_num": 10, 
    "inf_sentences_id": 733091, 
    "line": "They had found the door of the grotto opened , and gone forth ; on the azure dome of heaven still glittered a few remaining stars .", 
    "linenum": 25668, 
    "matchl": "They had found the door of the grotto opened , and gone forth ; on the azure dome of heaven still glittered a few remaining stars .", 
    "out-dataset_implicative_shuffle_num": 43, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 960671
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2868, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/87", 
    "implicative_pattern": "know", 
    "in-dataset_implicative_shuffle_num": 11, 
    "inf_sentences_id": 690164, 
    "line": "--People who leak and lie and do n't know when to give up .", 
    "linenum": 9, 
    "matchl": "--People who leak and lie and do n't know when to give up .", 
    "out-dataset_implicative_shuffle_num": 44, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 917744
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 5770, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "daring", 
    "in-dataset_implicative_shuffle_num": 11, 
    "in-dataset_question_shuffle_num": 6998, 
    "inf_sentences_id": 696218, 
    "line": "What film had Bette Davis creating a scandal by wearing a daring red gown to a society ball ?", 
    "linenum": 2770, 
    "matchl": "What film had Bette Davis creating a scandal by wearing a daring red gown to a society ball ?", 
    "out-dataset_implicative_shuffle_num": 45, 
    "out-dataset_question_shuffle_num": 21041, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 923798
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 351842, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "wanted", 
    "in-dataset_implicative_shuffle_num": 11, 
    "inf_sentences_id": 351861, 
    "line": "Tom wanted it this way .", 
    "linenum": 351842, 
    "matchl": "Tom wanted it this way .", 
    "out-dataset_implicative_shuffle_num": 46, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 579120
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 436841, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/730.txt.utf-8", 
    "implicative_pattern": "said", 
    "in-dataset_implicative_shuffle_num": 11, 
    "inf_sentences_id": 1142745, 
    "line": "' What a precious muddle-headed chap you are ! ' said Duff , addressing Mr. Giles , with supreme contempt .", 
    "linenum": 4757, 
    "matchl": "' What a precious muddle-headed chap you are ! ' said Duff , addressing Mr. Giles , with supreme contempt .", 
    "out-dataset_implicative_shuffle_num": 47, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1370325
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1285, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/23", 
    "implicative_pattern": "begun", 
    "in-dataset_implicative_shuffle_num": 12, 
    "inf_sentences_id": 688581, 
    "line": "1989 has begun for Soviets with Mikhail S. Gorbachev warning them not to expect `` manna from heaven '' and a multitude of signs - from barren shop shelves to astrology - heralding another hard year in the building of communism .", 
    "linenum": 0, 
    "matchl": "1989 has begun for Soviets with Mikhail S. Gorbachev warning them not to expect `` manna from heaven '' and a multitude of signs - from barren shop shelves to astrology - heralding another hard year in the building of communism .", 
    "out-dataset_implicative_shuffle_num": 48, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 916161
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 3680, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "try", 
    "in-dataset_implicative_shuffle_num": 12, 
    "in-dataset_question_shuffle_num": 5914, 
    "inf_sentences_id": 694128, 
    "line": "What do players try to do when the music stops in a game of musical chairs ?", 
    "linenum": 680, 
    "matchl": "What do players try to do when the music stops in a game of musical chairs ?", 
    "out-dataset_implicative_shuffle_num": 49, 
    "out-dataset_question_shuffle_num": 17789, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 921708
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 503353, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "like", 
    "in-dataset_implicative_shuffle_num": 12, 
    "inf_sentences_id": 503374, 
    "line": "The earthquake left the city looking like a war zone .", 
    "linenum": 503353, 
    "matchl": "The earthquake left the city looking like a war zone .", 
    "out-dataset_implicative_shuffle_num": 50, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 730631
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 176226, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/205-0.txt", 
    "implicative_pattern": "get", 
    "in-dataset_implicative_shuffle_num": 12, 
    "inf_sentences_id": 882127, 
    "line": "I say to my friend , Suppose we try who will get there first .", 
    "linenum": 610, 
    "matchl": "I say to my friend , Suppose we try who will get there first .", 
    "out-dataset_implicative_shuffle_num": 51, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1109707
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1290, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/23", 
    "implicative_pattern": "think", 
    "in-dataset_implicative_shuffle_num": 13, 
    "inf_sentences_id": 688586, 
    "line": "`` It is wrong to think , comrades , that somebody will solve our problems for us and that everything around us will change at the wave of a magic wand , with the chime of the clock on New Year 's Eve , '' he said .", 
    "linenum": 5, 
    "matchl": "`` It is wrong to think , comrades , that somebody will solve our problems for us and that everything around us will change at the wave of a magic wand , with the chime of the clock on New Year 's Eve , '' he said .", 
    "out-dataset_implicative_shuffle_num": 52, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 916166
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 6190, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "attempts", 
    "in-dataset_implicative_shuffle_num": 13, 
    "in-dataset_question_shuffle_num": 7801, 
    "inf_sentences_id": 696638, 
    "line": "What therapy attempts to elicit the `` primal scream '' ?", 
    "linenum": 190, 
    "matchl": "What therapy attempts to elicit the `` primal scream '' ?", 
    "out-dataset_implicative_shuffle_num": 53, 
    "out-dataset_question_shuffle_num": 23450, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 924218
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 425353, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "know", 
    "in-dataset_implicative_shuffle_num": 13, 
    "in-dataset_question_shuffle_num": 32271, 
    "inf_sentences_id": 425373, 
    "line": "Do you know how fast you were going ?", 
    "linenum": 425353, 
    "matchl": "Do you know how fast you were going ?", 
    "out-dataset_implicative_shuffle_num": 54, 
    "out-dataset_question_shuffle_num": 79794, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 652631
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 348817, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/35-0.txt", 
    "implicative_pattern": "know", 
    "in-dataset_implicative_shuffle_num": 13, 
    "inf_sentences_id": 1054720, 
    "line": "\" I know , \" he said , after a pause , \" that all this will be absolutely incredible to you , but to me the one incredible thing is that I am here tonight in this old familiar room looking into your friendly faces and telling you these strange adventures. \" He looked at the Medical Man .", 
    "linenum": 1797, 
    "matchl": "\" I know , \" he said , after a pause , \" that all this will be absolutely incredible to you , but to me the one incredible thing is that I am here tonight in this old familiar room looking into your friendly faces and telling you these strange adventures. \" He looked at the Medical Man .", 
    "out-dataset_implicative_shuffle_num": 55, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1282300
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2702, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/80", 
    "implicative_pattern": "exciting", 
    "in-dataset_implicative_shuffle_num": 14, 
    "inf_sentences_id": 689998, 
    "line": "`` But there is the exciting possibility that there will be many more . ''", 
    "linenum": 34, 
    "matchl": "`` But there is the exciting possibility that there will be many more . ''", 
    "out-dataset_implicative_shuffle_num": 56, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 917578
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 9798, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "meaning", 
    "in-dataset_implicative_shuffle_num": 14, 
    "in-dataset_question_shuffle_num": 12060, 
    "inf_sentences_id": 700246, 
    "line": "What is the meaning of `` CPR '' ?", 
    "linenum": 3798, 
    "matchl": "What is the meaning of `` CPR '' ?", 
    "out-dataset_implicative_shuffle_num": 57, 
    "out-dataset_question_shuffle_num": 36227, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 927826
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 514165, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "say", 
    "in-dataset_implicative_shuffle_num": 14, 
    "inf_sentences_id": 514186, 
    "line": "I did n't say I persuaded them .", 
    "linenum": 514165, 
    "matchl": "I did n't say I persuaded them .", 
    "out-dataset_implicative_shuffle_num": 58, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 741443
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 452662, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/76-0.txt", 
    "implicative_pattern": "make", 
    "in-dataset_implicative_shuffle_num": 14, 
    "inf_sentences_id": 1158566, 
    "line": "He turns on me , looking pitying enough to make a body cry , and says :", 
    "linenum": 5492, 
    "matchl": "He turns on me , looking pitying enough to make a body cry , and says :", 
    "out-dataset_implicative_shuffle_num": 59, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1386146
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 3054, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/95", 
    "implicative_pattern": "says", 
    "in-dataset_implicative_shuffle_num": 15, 
    "inf_sentences_id": 690350, 
    "line": "The man who would be education president says he 'll push certain public school reforms and provide whatever aid he can in `` tough budgetary times '' to districts trying to improve their schools .", 
    "linenum": 0, 
    "matchl": "The man who would be education president says he 'll push certain public school reforms and provide whatever aid he can in `` tough budgetary times '' to districts trying to improve their schools .", 
    "out-dataset_implicative_shuffle_num": 60, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 917930
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 8168, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "come", 
    "in-dataset_implicative_shuffle_num": 15, 
    "in-dataset_question_shuffle_num": 7196, 
    "inf_sentences_id": 698616, 
    "line": "What year did the first issue of `` Playboy '' come out ?", 
    "linenum": 2168, 
    "matchl": "What year did the first issue of `` Playboy '' come out ?", 
    "out-dataset_implicative_shuffle_num": 61, 
    "out-dataset_question_shuffle_num": 21635, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 926196
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 500000, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "happen", 
    "in-dataset_implicative_shuffle_num": 15, 
    "inf_sentences_id": 500021, 
    "line": "I never thought I 'd see this happen .", 
    "linenum": 500000, 
    "matchl": "I never thought I 'd see this happen .", 
    "out-dataset_implicative_shuffle_num": 62, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 727278
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 364102, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/3600-0.txt", 
    "implicative_pattern": "see", 
    "in-dataset_implicative_shuffle_num": 15, 
    "inf_sentences_id": 1070005, 
    "line": "I am afraid our knowledge is weak in all senses ; we neither see far forward nor far backward ; our understanding comprehends little , and lives but a little while ; ' tis short both in extent of time and extent of matter :", 
    "linenum": 11903, 
    "matchl": "I am afraid our knowledge is weak in all senses ; we neither see far forward nor far backward ; our understanding comprehends little , and lives but a little while ; ' tis short both in extent of time and extent of matter :", 
    "out-dataset_implicative_shuffle_num": 63, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1297585
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2840, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/86", 
    "implicative_pattern": "know", 
    "in-dataset_implicative_shuffle_num": 16, 
    "inf_sentences_id": 690136, 
    "line": "`` What we need to know before Congress can go to work is what George Bush wants in his defense budget .", 
    "linenum": 10, 
    "matchl": "`` What we need to know before Congress can go to work is what George Bush wants in his defense budget .", 
    "out-dataset_implicative_shuffle_num": 64, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 917716
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 14724, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "live", 
    "in-dataset_implicative_shuffle_num": 16, 
    "in-dataset_question_shuffle_num": 11142, 
    "inf_sentences_id": 705172, 
    "line": "How long do you have to live in a community to vote ?", 
    "linenum": 4724, 
    "matchl": "How long do you have to live in a community to vote ?", 
    "out-dataset_implicative_shuffle_num": 65, 
    "out-dataset_question_shuffle_num": 33473, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 932752
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 618493, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "work", 
    "in-dataset_implicative_shuffle_num": 16, 
    "inf_sentences_id": 618515, 
    "line": "We have a bit more work to do .", 
    "linenum": 618493, 
    "matchl": "We have a bit more work to do .", 
    "out-dataset_implicative_shuffle_num": 66, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 845771
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 72804, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/135-0.txt", 
    "implicative_pattern": "love", 
    "in-dataset_implicative_shuffle_num": 16, 
    "inf_sentences_id": 778704, 
    "line": "This bordered on a strange theme , the flesh , before which that immense and innocent love recoiled with a sort of sacred fright .", 
    "linenum": 24377, 
    "matchl": "This bordered on a strange theme , the flesh , before which that immense and innocent love recoiled with a sort of sacred fright .", 
    "out-dataset_implicative_shuffle_num": 67, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1006284
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 478, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/113", 
    "implicative_pattern": "like", 
    "in-dataset_implicative_shuffle_num": 17, 
    "inf_sentences_id": 687774, 
    "line": "They have to worry about marketing , everything , just like any other businessman . ''", 
    "linenum": 45, 
    "matchl": "They have to worry about marketing , everything , just like any other businessman . ''", 
    "out-dataset_implicative_shuffle_num": 68, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 915354
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 6002, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 17, 
    "in-dataset_question_shuffle_num": 8104, 
    "in-dataset_request_shuffle_num": 64, 
    "inf_sentences_id": 696450, 
    "line": "How can I find a list of celebrities ' real names ?", 
    "linenum": 2, 
    "matchl": "How can I find a list of celebrities ' real names ?", 
    "out-dataset_implicative_shuffle_num": 69, 
    "out-dataset_question_shuffle_num": 24359, 
    "out-dataset_request_shuffle_num": 194, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 924030
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 465877, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "claimed", 
    "in-dataset_implicative_shuffle_num": 17, 
    "inf_sentences_id": 465897, 
    "line": "Columbus claimed the Earth was round .", 
    "linenum": 465877, 
    "matchl": "Columbus claimed the Earth was round .", 
    "out-dataset_implicative_shuffle_num": 70, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 693155
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 30353, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/120.txt.utf-8", 
    "implicative_pattern": "says", 
    "in-dataset_implicative_shuffle_num": 17, 
    "in-dataset_question_shuffle_num": 35855, 
    "inf_sentences_id": 736253, 
    "line": "' Who 's that ? ' says one .", 
    "linenum": 3078, 
    "matchl": "' Who 's that ? ' says one .", 
    "out-dataset_implicative_shuffle_num": 71, 
    "out-dataset_question_shuffle_num": 86963, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 963833
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2809, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/85", 
    "implicative_pattern": "remain", 
    "in-dataset_implicative_shuffle_num": 18, 
    "inf_sentences_id": 690105, 
    "line": "One top adviser who turned down an offer of a White House job after weeks of agonizing was pollster Robert M. Teeter , who informed Bush that for personal and family considerations he preferred to remain in Michigan .", 
    "linenum": 10, 
    "matchl": "One top adviser who turned down an offer of a White House job after weeks of agonizing was pollster Robert M. Teeter , who informed Bush that for personal and family considerations he preferred to remain in Michigan .", 
    "out-dataset_implicative_shuffle_num": 72, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 917685
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 10499, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "meant", 
    "in-dataset_implicative_shuffle_num": 18, 
    "in-dataset_question_shuffle_num": 10102, 
    "inf_sentences_id": 700947, 
    "line": "Which oil company almost picked a word that meant `` stalled car '' in Japanese as its new international name ?", 
    "linenum": 499, 
    "matchl": "Which oil company almost picked a word that meant `` stalled car '' in Japanese as its new international name ?", 
    "out-dataset_implicative_shuffle_num": 73, 
    "out-dataset_question_shuffle_num": 30353, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 928527
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 646611, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "help", 
    "in-dataset_implicative_shuffle_num": 18, 
    "in-dataset_question_shuffle_num": 98599, 
    "inf_sentences_id": 646633, 
    "line": "How did you persuade Tom to help us ?", 
    "linenum": 646611, 
    "matchl": "How did you persuade Tom to help us ?", 
    "out-dataset_implicative_shuffle_num": 74, 
    "out-dataset_question_shuffle_num": 172383, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 873889
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 452802, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/76-0.txt", 
    "implicative_pattern": "make", 
    "in-dataset_implicative_shuffle_num": 18, 
    "in-dataset_question_shuffle_num": 33248, 
    "inf_sentences_id": 1158706, 
    "line": "\" But my lan ', Mars Sid , how 's I gwyne to make ' m a witch pie ?", 
    "linenum": 5632, 
    "matchl": "\" But my lan ', Mars Sid , how 's I gwyne to make ' m a witch pie ?", 
    "out-dataset_implicative_shuffle_num": 75, 
    "out-dataset_question_shuffle_num": 81749, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1386286
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1444, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/3", 
    "implicative_pattern": "make", 
    "in-dataset_implicative_shuffle_num": 19, 
    "inf_sentences_id": 688740, 
    "line": "However , Turner has complained that the program , which sends swarms of officers through drug-infested neighborhoods to make arrests , has done little more than further clog the city 's already-overcrowded jail and court systems .", 
    "linenum": 18, 
    "matchl": "However , Turner has complained that the program , which sends swarms of officers through drug-infested neighborhoods to make arrests , has done little more than further clog the city 's already-overcrowded jail and court systems .", 
    "out-dataset_implicative_shuffle_num": 76, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 916320
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 4469, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "forces", 
    "in-dataset_implicative_shuffle_num": 19, 
    "in-dataset_question_shuffle_num": 6275, 
    "inf_sentences_id": 694917, 
    "line": "What two commanders directed the forces in the Battle of El Alamein ?", 
    "linenum": 1469, 
    "matchl": "What two commanders directed the forces in the Battle of El Alamein ?", 
    "out-dataset_implicative_shuffle_num": 77, 
    "out-dataset_question_shuffle_num": 18872, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 922497
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 421759, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "stopped", 
    "in-dataset_implicative_shuffle_num": 19, 
    "inf_sentences_id": 421779, 
    "line": "Tom told me you had stopped by .", 
    "linenum": 421759, 
    "matchl": "Tom told me you had stopped by .", 
    "out-dataset_implicative_shuffle_num": 78, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 649037
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 408674, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/45-0.txt", 
    "implicative_pattern": "like", 
    "in-dataset_implicative_shuffle_num": 19, 
    "inf_sentences_id": 1114578, 
    "line": "There are times and seasons even yet when I do n't feel that I 've made any great headway in learning to like Josie Pye !", 
    "linenum": 6109, 
    "matchl": "There are times and seasons even yet when I do n't feel that I 've made any great headway in learning to like Josie Pye !", 
    "out-dataset_implicative_shuffle_num": 79, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1342158
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2914, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/89", 
    "implicative_pattern": "said", 
    "in-dataset_implicative_shuffle_num": 20, 
    "inf_sentences_id": 690210, 
    "line": "Beryl W. Sprinkel , the president 's chief economic adviser , said the new report was aimed at placing the Reagan record in the context of post-World War II economic history .", 
    "linenum": 7, 
    "matchl": "Beryl W. Sprinkel , the president 's chief economic adviser , said the new report was aimed at placing the Reagan record in the context of post-World War II economic history .", 
    "out-dataset_implicative_shuffle_num": 80, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 917790
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 12830, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "determine", 
    "in-dataset_counterfactual_shuffle_num": 57, 
    "in-dataset_implicative_shuffle_num": 20, 
    "in-dataset_question_shuffle_num": 6909, 
    "inf_sentences_id": 703278, 
    "line": "How do you determine if a computer monitor has an SVGA adapter ?", 
    "linenum": 2830, 
    "matchl": "How do you determine if a computer monitor has an SVGA adapter ?", 
    "out-dataset_counterfactual_shuffle_num": 229, 
    "out-dataset_implicative_shuffle_num": 81, 
    "out-dataset_question_shuffle_num": 20774, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 930858
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 327032, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "come", 
    "in-dataset_implicative_shuffle_num": 20, 
    "inf_sentences_id": 327051, 
    "line": "He says that he will come tomorrow .", 
    "linenum": 327032, 
    "matchl": "He says that he will come tomorrow .", 
    "out-dataset_implicative_shuffle_num": 82, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 554310
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 249760, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2600-0.txt", 
    "implicative_pattern": "made", 
    "in-dataset_counterfactual_shuffle_num": 1376, 
    "in-dataset_implicative_shuffle_num": 20, 
    "inf_sentences_id": 955662, 
    "line": "Napoleon made ironic remarks during Fabvier 's account , as if he had not expected that matters could go otherwise in his absence .", 
    "linenum": 20639, 
    "matchl": "Napoleon made ironic remarks during Fabvier 's account , as if he had not expected that matters could go otherwise in his absence .", 
    "out-dataset_counterfactual_shuffle_num": 2959, 
    "out-dataset_implicative_shuffle_num": 83, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1183242
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 408, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/111", 
    "implicative_pattern": "lead", 
    "in-dataset_implicative_shuffle_num": 21, 
    "inf_sentences_id": 687704, 
    "line": "The president 's bowl rests on a 14-pound , beveled , lead glass plinth , or flat base .", 
    "linenum": 17, 
    "matchl": "The president 's bowl rests on a 14-pound , beveled , lead glass plinth , or flat base .", 
    "out-dataset_implicative_shuffle_num": 84, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 915284
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 711, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_1000.raw", 
    "implicative_pattern": "makes", 
    "in-dataset_implicative_shuffle_num": 21, 
    "in-dataset_question_shuffle_num": 11428, 
    "inf_sentences_id": 691159, 
    "line": "What type of food makes you fat ?", 
    "linenum": 711, 
    "matchl": "What type of food makes you fat ?", 
    "out-dataset_implicative_shuffle_num": 85, 
    "out-dataset_question_shuffle_num": 34331, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 918739
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 90591, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "tell", 
    "in-dataset_implicative_shuffle_num": 21, 
    "inf_sentences_id": 90607, 
    "line": "Whoever calls , tell him I 'm out .", 
    "linenum": 90591, 
    "matchl": "Whoever calls , tell him I 'm out .", 
    "out-dataset_implicative_shuffle_num": 86, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 317869
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 417132, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/514.txt.utf-8", 
    "implicative_pattern": "said", 
    "in-dataset_implicative_shuffle_num": 21, 
    "inf_sentences_id": 1123036, 
    "line": "\" Funny angels in hoods and mittens , \" said Jo , and set them to laughing .", 
    "linenum": 293, 
    "matchl": "\" Funny angels in hoods and mittens , \" said Jo , and set them to laughing .", 
    "out-dataset_implicative_shuffle_num": 87, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1350616
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 185, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/105", 
    "implicative_pattern": "helped", 
    "in-dataset_implicative_shuffle_num": 22, 
    "inf_sentences_id": 687481, 
    "line": "Chancellor Helmut Kohl says he no longer can rule out the possibility charges may be brought against West Germany companies reported to have helped Libya build a suspected chemical weapons factory .", 
    "linenum": 0, 
    "matchl": "Chancellor Helmut Kohl says he no longer can rule out the possibility charges may be brought against West Germany companies reported to have helped Libya build a suspected chemical weapons factory .", 
    "out-dataset_implicative_shuffle_num": 88, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 915061
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 13542, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "started", 
    "in-dataset_counterfactual_shuffle_num": 43, 
    "in-dataset_implicative_shuffle_num": 22, 
    "in-dataset_question_shuffle_num": 12510, 
    "inf_sentences_id": 703990, 
    "line": "Why is the universe flat , if it started by an explosion , shouldn 't it be a sphere ?", 
    "linenum": 3542, 
    "matchl": "Why is the universe flat , if it started by an explosion , shouldn 't it be a sphere ?", 
    "out-dataset_counterfactual_shuffle_num": 173, 
    "out-dataset_implicative_shuffle_num": 89, 
    "out-dataset_question_shuffle_num": 37577, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 931570
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 37229, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "says", 
    "in-dataset_implicative_shuffle_num": 22, 
    "inf_sentences_id": 37245, 
    "line": "I 'm still alive , and that 's the main thing , Father says .", 
    "linenum": 37229, 
    "matchl": "I 'm still alive , and that 's the main thing , Father says .", 
    "out-dataset_implicative_shuffle_num": 90, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 264507
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 187343, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2147-0.txt", 
    "implicative_pattern": "make", 
    "in-dataset_implicative_shuffle_num": 22, 
    "in-dataset_question_shuffle_num": 27849, 
    "inf_sentences_id": 893244, 
    "line": "Could make out several words , but cannot now remember all .", 
    "linenum": 2170, 
    "matchl": "Could make out several words , but cannot now remember all .", 
    "out-dataset_implicative_shuffle_num": 91, 
    "out-dataset_question_shuffle_num": 70951, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1120824
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 3111, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/97", 
    "implicative_pattern": "said", 
    "in-dataset_implicative_shuffle_num": 23, 
    "inf_sentences_id": 690407, 
    "line": "The previous record was $10 million , he said .", 
    "linenum": 22, 
    "matchl": "The previous record was $10 million , he said .", 
    "out-dataset_implicative_shuffle_num": 92, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 917987
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 8693, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "identify", 
    "in-dataset_implicative_shuffle_num": 23, 
    "in-dataset_question_shuffle_num": 12586, 
    "inf_sentences_id": 699141, 
    "line": "How do you identify prime numbers ?", 
    "linenum": 2693, 
    "matchl": "How do you identify prime numbers ?", 
    "out-dataset_implicative_shuffle_num": 93, 
    "out-dataset_question_shuffle_num": 37805, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 926721
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 685797, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "know", 
    "in-dataset_implicative_shuffle_num": 23, 
    "in-dataset_question_shuffle_num": 97448, 
    "inf_sentences_id": 685819, 
    "line": "Does anyone here know how this works ?", 
    "linenum": 685797, 
    "matchl": "Does anyone here know how this works ?", 
    "out-dataset_implicative_shuffle_num": 94, 
    "out-dataset_question_shuffle_num": 171232, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 913075
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 148266, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1661.txt.utf-8", 
    "implicative_pattern": "got", 
    "in-dataset_implicative_shuffle_num": 23, 
    "inf_sentences_id": 854167, 
    "line": "So far I had got before I ever heard Lord St .", 
    "linenum": 5486, 
    "matchl": "So far I had got before I ever heard Lord St .", 
    "out-dataset_implicative_shuffle_num": 95, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1081747
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2504, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/74", 
    "implicative_pattern": "came", 
    "in-dataset_implicative_shuffle_num": 24, 
    "inf_sentences_id": 689800, 
    "line": "The cockpit with a large chunk of fuselage came to rest in thick brambles and trees near the top of the embankment .", 
    "linenum": 36, 
    "matchl": "The cockpit with a large chunk of fuselage came to rest in thick brambles and trees near the top of the embankment .", 
    "out-dataset_implicative_shuffle_num": 96, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 917380
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 9175, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "get", 
    "in-dataset_implicative_shuffle_num": 24, 
    "in-dataset_question_shuffle_num": 2902, 
    "inf_sentences_id": 699623, 
    "line": "How did the 7th inning stretch get started ?", 
    "linenum": 3175, 
    "matchl": "How did the 7th inning stretch get started ?", 
    "out-dataset_implicative_shuffle_num": 97, 
    "out-dataset_question_shuffle_num": 8753, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 927203
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 132319, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "mind", 
    "in-dataset_implicative_shuffle_num": 24, 
    "inf_sentences_id": 132336, 
    "line": "Books are to the mind what food is to the body .", 
    "linenum": 132319, 
    "matchl": "Books are to the mind what food is to the body .", 
    "out-dataset_implicative_shuffle_num": 98, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 359597
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 3871, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1184-0.txt", 
    "implicative_pattern": "saw", 
    "in-dataset_implicative_shuffle_num": 24, 
    "inf_sentences_id": 709771, 
    "line": "He had entered Villefort 's office expecting that the magistrate would tremble at the sight of him ; on the contrary , he felt a cold shudder all over him when he saw Villefort sitting there with his elbow on his desk , and his head leaning on his hand .", 
    "linenum": 2348, 
    "matchl": "He had entered Villefort 's office expecting that the magistrate would tremble at the sight of him ; on the contrary , he felt a cold shudder all over him when he saw Villefort sitting there with his elbow on his desk , and his head leaning on his hand .", 
    "out-dataset_implicative_shuffle_num": 99, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 937351
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 20, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/1", 
    "implicative_pattern": "like", 
    "in-dataset_implicative_shuffle_num": 25, 
    "inf_sentences_id": 687316, 
    "line": "Ms. Alptekin said automation is widespread in the automobile industry , but she would like to see it expanded .", 
    "linenum": 20, 
    "matchl": "Ms. Alptekin said automation is widespread in the automobile industry , but she would like to see it expanded .", 
    "out-dataset_implicative_shuffle_num": 100, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 914896
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 13707, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "lie", 
    "in-dataset_implicative_shuffle_num": 25, 
    "in-dataset_question_shuffle_num": 3936, 
    "inf_sentences_id": 704155, 
    "line": "How many tenths of the Earth 's surface lie under water ?", 
    "linenum": 3707, 
    "matchl": "How many tenths of the Earth 's surface lie under water ?", 
    "out-dataset_implicative_shuffle_num": 101, 
    "out-dataset_question_shuffle_num": 11855, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 931735
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 636011, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "got", 
    "in-dataset_implicative_shuffle_num": 25, 
    "inf_sentences_id": 636033, 
    "line": "We 've got a real good car .", 
    "linenum": 636011, 
    "matchl": "We 've got a real good car .", 
    "out-dataset_implicative_shuffle_num": 102, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 863289
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 42524, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1342-0.txt", 
    "implicative_pattern": "makes", 
    "in-dataset_implicative_shuffle_num": 25, 
    "inf_sentences_id": 748424, 
    "line": "\" With great energy ; but it is always a subject which makes a lady energetic . \"", 
    "linenum": 384, 
    "matchl": "\" With great energy ; but it is always a subject which makes a lady energetic . \"", 
    "out-dataset_implicative_shuffle_num": 103, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 976004
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2324, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/69", 
    "implicative_pattern": "said", 
    "in-dataset_implicative_shuffle_num": 26, 
    "inf_sentences_id": 689620, 
    "line": "Minutes before the tornado stuck Allendale , twisters hit nearby Mill Shoals and Albion , officials said .", 
    "linenum": 16, 
    "matchl": "Minutes before the tornado stuck Allendale , twisters hit nearby Mill Shoals and Albion , officials said .", 
    "out-dataset_implicative_shuffle_num": 104, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 917200
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 6809, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "meaning", 
    "in-dataset_implicative_shuffle_num": 26, 
    "in-dataset_question_shuffle_num": 7137, 
    "inf_sentences_id": 697257, 
    "line": "What is the meaning of W.B. Yeat 's poem , `` The Three Hermits ? ''", 
    "linenum": 809, 
    "matchl": "What is the meaning of W.B. Yeat 's poem , `` The Three Hermits ? ''", 
    "out-dataset_implicative_shuffle_num": 105, 
    "out-dataset_question_shuffle_num": 21458, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 924837
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 650179, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "tell", 
    "in-dataset_implicative_shuffle_num": 26, 
    "inf_sentences_id": 650201, 
    "line": "Let me tell you my plans .", 
    "linenum": 650179, 
    "matchl": "Let me tell you my plans .", 
    "out-dataset_implicative_shuffle_num": 106, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 877457
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 181008, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/209-0.txt", 
    "implicative_pattern": "see", 
    "in-dataset_counterfactual_shuffle_num": 28674, 
    "in-dataset_implicative_shuffle_num": 26, 
    "inf_sentences_id": 886909, 
    "line": "But she was a magnificent monument to the blessing of a want of imagination , and if she could see in our little charges nothing but their beauty and amiability , their happiness and cleverness , she had no direct communication with the sources of my trouble .", 
    "linenum": 1267, 
    "matchl": "But she was a magnificent monument to the blessing of a want of imagination , and if she could see in our little charges nothing but their beauty and amiability , their happiness and cleverness , she had no direct communication with the sources of my trouble .", 
    "out-dataset_counterfactual_shuffle_num": 44530, 
    "out-dataset_implicative_shuffle_num": 107, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1114489
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1838, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/47", 
    "implicative_pattern": "began", 
    "in-dataset_implicative_shuffle_num": 27, 
    "inf_sentences_id": 689134, 
    "line": "A high school canceled classes for a second day Thursday after a custodian was diagnosed with Legionnaires ' disease and another custodian began showing symptoms of the disease .", 
    "linenum": 0, 
    "matchl": "A high school canceled classes for a second day Thursday after a custodian was diagnosed with Legionnaires ' disease and another custodian began showing symptoms of the disease .", 
    "out-dataset_implicative_shuffle_num": 108, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 916714
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 15111, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "leading", 
    "in-dataset_implicative_shuffle_num": 27, 
    "in-dataset_question_shuffle_num": 8625, 
    "inf_sentences_id": 705559, 
    "line": "What country is the worlds leading supplier of cannabis ?", 
    "linenum": 5111, 
    "matchl": "What country is the worlds leading supplier of cannabis ?", 
    "out-dataset_implicative_shuffle_num": 109, 
    "out-dataset_question_shuffle_num": 25922, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 933139
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 416817, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "annoyed", 
    "in-dataset_implicative_shuffle_num": 27, 
    "inf_sentences_id": 416837, 
    "line": "Tom seemed somewhat annoyed by that .", 
    "linenum": 416817, 
    "matchl": "Tom seemed somewhat annoyed by that .", 
    "out-dataset_implicative_shuffle_num": 110, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 644095
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 474838, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/829-0.txt", 
    "implicative_pattern": "work", 
    "in-dataset_implicative_shuffle_num": 27, 
    "inf_sentences_id": 1180742, 
    "line": "He then sent his servants to their work , and taking his handkerchief out of his pocket , he doubled and spread it on his left hand , which he placed flat on the ground with the palm upward , making me a sign to step into it , as I could easily do , for it was not above a foot in thickness .", 
    "linenum": 758, 
    "matchl": "He then sent his servants to their work , and taking his handkerchief out of his pocket , he doubled and spread it on his left hand , which he placed flat on the ground with the palm upward , making me a sign to step into it , as I could easily do , for it was not above a foot in thickness .", 
    "out-dataset_implicative_shuffle_num": 111, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1408322
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1534, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/34", 
    "implicative_pattern": "get", 
    "in-dataset_implicative_shuffle_num": 28, 
    "inf_sentences_id": 688830, 
    "line": "`` Maybe this time he will finally get it straight: Whenever he threatens American forces , we will defend ourselves . ''", 
    "linenum": 22, 
    "matchl": "`` Maybe this time he will finally get it straight: Whenever he threatens American forces , we will defend ourselves . ''", 
    "out-dataset_implicative_shuffle_num": 112, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 916410
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 2289, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "implicative_pattern": "come", 
    "in-dataset_implicative_shuffle_num": 28, 
    "in-dataset_question_shuffle_num": 820, 
    "inf_sentences_id": 692737, 
    "line": "How did ` stat ' come to be used as an expression for quickly ?", 
    "linenum": 1289, 
    "matchl": "How did ` stat ' come to be used as an expression for quickly ?", 
    "out-dataset_implicative_shuffle_num": 113, 
    "out-dataset_question_shuffle_num": 2507, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 920317
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 322615, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "know", 
    "in-dataset_implicative_shuffle_num": 28, 
    "inf_sentences_id": 322634, 
    "line": "Tom does n't like people to know that he ca n't speak French well .", 
    "linenum": 322615, 
    "matchl": "Tom does n't like people to know that he ca n't speak French well .", 
    "out-dataset_implicative_shuffle_num": 114, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 549893
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 368117, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/408.txt.utf-8", 
    "implicative_pattern": "discover", 
    "in-dataset_implicative_shuffle_num": 28, 
    "inf_sentences_id": 1074020, 
    "line": "Few know of these problems , few who know notice them ; and yet there they are , awaiting student , artist , and seer,--a field for somebody sometime to discover .", 
    "linenum": 750, 
    "matchl": "Few know of these problems , few who know notice them ; and yet there they are , awaiting student , artist , and seer,--a field for somebody sometime to discover .", 
    "out-dataset_implicative_shuffle_num": 115, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1301600
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1976, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/52", 
    "implicative_pattern": "add", 
    "in-dataset_implicative_shuffle_num": 29, 
    "inf_sentences_id": 689272, 
    "line": "Goddard said cities recognize the federal deficit problem and do n't seek a return to their pampered days , `` but we do need a positive administration response , one which is willing to use national leadership and coordination to help us save money and add a sense of direction . ''", 
    "linenum": 11, 
    "matchl": "Goddard said cities recognize the federal deficit problem and do n't seek a return to their pampered days , `` but we do need a positive administration response , one which is willing to use national leadership and coordination to help us save money and add a sense of direction . ''", 
    "out-dataset_implicative_shuffle_num": 116, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 916852
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 13356, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "invented", 
    "in-dataset_implicative_shuffle_num": 29, 
    "in-dataset_question_shuffle_num": 77, 
    "inf_sentences_id": 703804, 
    "line": "Who invented the lawnmower ?", 
    "linenum": 3356, 
    "matchl": "Who invented the lawnmower ?", 
    "out-dataset_implicative_shuffle_num": 117, 
    "out-dataset_question_shuffle_num": 278, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 931384
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 658054, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "think", 
    "in-dataset_implicative_shuffle_num": 29, 
    "in-dataset_question_shuffle_num": 61388, 
    "inf_sentences_id": 658076, 
    "line": "Do you think I look happy ?", 
    "linenum": 658054, 
    "matchl": "Do you think I look happy ?", 
    "out-dataset_implicative_shuffle_num": 118, 
    "out-dataset_question_shuffle_num": 135172, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 885332
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 856, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/11-0.txt", 
    "implicative_pattern": "know", 
    "in-dataset_implicative_shuffle_num": 29, 
    "inf_sentences_id": 706756, 
    "line": "' They could n't have done that , you know , ' Alice gently remarked ; ' they 'd have been ill . '", 
    "linenum": 787, 
    "matchl": "' They could n't have done that , you know , ' Alice gently remarked ; ' they 'd have been ill . '", 
    "out-dataset_implicative_shuffle_num": 119, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 934336
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2089, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/59", 
    "implicative_pattern": "discovered", 
    "in-dataset_implicative_shuffle_num": 30, 
    "inf_sentences_id": 689385, 
    "line": "But the agency said since then it has discovered cracks on more than 20 aircraft that had between 45,000 and 52,000 landings , prompting the special precautions for the additional aircraft .", 
    "linenum": 9, 
    "matchl": "But the agency said since then it has discovered cracks on more than 20 aircraft that had between 45,000 and 52,000 landings , prompting the special precautions for the additional aircraft .", 
    "out-dataset_implicative_shuffle_num": 120, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 916965
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 1684, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "implicative_pattern": "made", 
    "in-dataset_implicative_shuffle_num": 30, 
    "in-dataset_question_shuffle_num": 9828, 
    "inf_sentences_id": 692132, 
    "line": "What Judith Rossner novel was made into a film starring Diane Keaton ?", 
    "linenum": 684, 
    "matchl": "What Judith Rossner novel was made into a film starring Diane Keaton ?", 
    "out-dataset_implicative_shuffle_num": 121, 
    "out-dataset_question_shuffle_num": 29531, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 919712
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 455155, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "happened", 
    "in-dataset_implicative_shuffle_num": 30, 
    "inf_sentences_id": 455175, 
    "line": "Tom says he 's sorry about what happened yesterday .", 
    "linenum": 455155, 
    "matchl": "Tom says he 's sorry about what happened yesterday .", 
    "out-dataset_implicative_shuffle_num": 122, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 682433
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 279999, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/28054-0.txt", 
    "implicative_pattern": "consent", 
    "in-dataset_implicative_shuffle_num": 30, 
    "inf_sentences_id": 985901, 
    "line": "\" No , I would n't consent , \" said Alyosha softly .", 
    "linenum": 7574, 
    "matchl": "\" No , I would n't consent , \" said Alyosha softly .", 
    "out-dataset_implicative_shuffle_num": 123, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1213481
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 647, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/119", 
    "implicative_pattern": "think", 
    "in-dataset_implicative_shuffle_num": 31, 
    "inf_sentences_id": 687943, 
    "line": "`` I think clearly that older workers should be tapped across the board . ''", 
    "linenum": 2, 
    "matchl": "`` I think clearly that older workers should be tapped across the board . ''", 
    "out-dataset_implicative_shuffle_num": 124, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 915523
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 1854, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "implicative_pattern": "mean", 
    "in-dataset_implicative_shuffle_num": 31, 
    "in-dataset_question_shuffle_num": 11304, 
    "inf_sentences_id": 692302, 
    "line": "What does the word LASER mean ?", 
    "linenum": 854, 
    "matchl": "What does the word LASER mean ?", 
    "out-dataset_implicative_shuffle_num": 125, 
    "out-dataset_question_shuffle_num": 33959, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 919882
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 610148, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "work", 
    "in-dataset_implicative_shuffle_num": 31, 
    "inf_sentences_id": 610170, 
    "line": "She 's been out of work for over a week .", 
    "linenum": 610148, 
    "matchl": "She 's been out of work for over a week .", 
    "out-dataset_implicative_shuffle_num": 126, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 837426
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 487990, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/863-0.txt", 
    "implicative_pattern": "know", 
    "in-dataset_implicative_shuffle_num": 31, 
    "inf_sentences_id": 1193894, 
    "line": "I did not quite know what to say .", 
    "linenum": 4242, 
    "matchl": "I did not quite know what to say .", 
    "out-dataset_implicative_shuffle_num": 127, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1421474
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1579, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/36", 
    "implicative_pattern": "know", 
    "in-dataset_counterfactual_shuffle_num": 27, 
    "in-dataset_implicative_shuffle_num": 32, 
    "inf_sentences_id": 688875, 
    "line": "`` But I do n't know if they will be actually sons and daughters .", 
    "linenum": 2, 
    "matchl": "`` But I do n't know if they will be actually sons and daughters .", 
    "out-dataset_counterfactual_shuffle_num": 108, 
    "out-dataset_implicative_shuffle_num": 128, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 916455
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 10377, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "tend", 
    "in-dataset_implicative_shuffle_num": 32, 
    "in-dataset_question_shuffle_num": 924, 
    "inf_sentences_id": 700825, 
    "line": "What war did Florence Nightingale tend the troops in ?", 
    "linenum": 377, 
    "matchl": "What war did Florence Nightingale tend the troops in ?", 
    "out-dataset_implicative_shuffle_num": 129, 
    "out-dataset_question_shuffle_num": 2819, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 928405
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 495716, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "thought", 
    "in-dataset_implicative_shuffle_num": 32, 
    "inf_sentences_id": 495736, 
    "line": "Tom probably thought I was thirsty .", 
    "linenum": 495716, 
    "matchl": "Tom probably thought I was thirsty .", 
    "out-dataset_implicative_shuffle_num": 130, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 722994
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 467971, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/815.txt.utf-8", 
    "implicative_pattern": "remain", 
    "in-dataset_implicative_shuffle_num": 32, 
    "inf_sentences_id": 1173875, 
    "line": "Though not originally written for Americans , \" Democracy in America \" must always remain a work of engrossing and constantly increasing interest to citizens of the United States as the first philosophic and comprehensive view of our society , institutions , and destiny .", 
    "linenum": 93, 
    "matchl": "Though not originally written for Americans , \" Democracy in America \" must always remain a work of engrossing and constantly increasing interest to citizens of the United States as the first philosophic and comprehensive view of our society , institutions , and destiny .", 
    "out-dataset_implicative_shuffle_num": 131, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1401455
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1388, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/27", 
    "implicative_pattern": "failed", 
    "in-dataset_implicative_shuffle_num": 33, 
    "inf_sentences_id": 688684, 
    "line": "According to individuals familiar with the situation , the Frankfurt loss stemmed from a computer program for calculating prices on forward-rate agreements that failed to envision an interest-rate environment where short-term rates were equal to or higher than long-term rates .", 
    "linenum": 11, 
    "matchl": "According to individuals familiar with the situation , the Frankfurt loss stemmed from a computer program for calculating prices on forward-rate agreements that failed to envision an interest-rate environment where short-term rates were equal to or higher than long-term rates .", 
    "out-dataset_implicative_shuffle_num": 132, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 916264
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 2909, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "implicative_pattern": "said", 
    "in-dataset_implicative_shuffle_num": 33, 
    "in-dataset_question_shuffle_num": 9051, 
    "inf_sentences_id": 693357, 
    "line": "Who said : `` Old soldiers never die ; they just fade away '' ?", 
    "linenum": 1909, 
    "matchl": "Who said : `` Old soldiers never die ; they just fade away '' ?", 
    "out-dataset_implicative_shuffle_num": 133, 
    "out-dataset_question_shuffle_num": 27200, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 920937
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 1159, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "dare", 
    "in-dataset_implicative_shuffle_num": 33, 
    "in-dataset_question_shuffle_num": 36046, 
    "inf_sentences_id": 1175, 
    "line": "How dare you say such a thing to me ?", 
    "linenum": 1159, 
    "matchl": "How dare you say such a thing to me ?", 
    "out-dataset_implicative_shuffle_num": 134, 
    "out-dataset_question_shuffle_num": 87344, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 228437
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 417583, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/514.txt.utf-8", 
    "implicative_pattern": "make", 
    "in-dataset_implicative_shuffle_num": 33, 
    "inf_sentences_id": 1123487, 
    "line": "Hannah never forgot to make them , no matter how busy or grumpy she might be , for the walk was long and bleak .", 
    "linenum": 744, 
    "matchl": "Hannah never forgot to make them , no matter how busy or grumpy she might be , for the walk was long and bleak .", 
    "out-dataset_implicative_shuffle_num": 135, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1351067
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2426, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/72", 
    "implicative_pattern": "desire", 
    "in-dataset_implicative_shuffle_num": 34, 
    "inf_sentences_id": 689722, 
    "line": "And new Senate Budget Committee Chairman Jim Sasser , D-Tenn. , expressed the same desire in a telephone interview last week , adding that the delay caused by the presidential transition `` does n't waive the provisions of the law '' setting the budget work schedule .", 
    "linenum": 11, 
    "matchl": "And new Senate Budget Committee Chairman Jim Sasser , D-Tenn. , expressed the same desire in a telephone interview last week , adding that the delay caused by the presidential transition `` does n't waive the provisions of the law '' setting the budget work schedule .", 
    "out-dataset_implicative_shuffle_num": 136, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 917302
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 4543, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "happen", 
    "in-dataset_implicative_shuffle_num": 34, 
    "in-dataset_question_shuffle_num": 858, 
    "inf_sentences_id": 694991, 
    "line": "What will happen when sodium is put in water ?", 
    "linenum": 1543, 
    "matchl": "What will happen when sodium is put in water ?", 
    "out-dataset_implicative_shuffle_num": 137, 
    "out-dataset_question_shuffle_num": 2621, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 922571
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 420060, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "think", 
    "in-dataset_implicative_shuffle_num": 34, 
    "inf_sentences_id": 420080, 
    "line": "I think Tom really likes me .", 
    "linenum": 420060, 
    "matchl": "I think Tom really likes me .", 
    "out-dataset_implicative_shuffle_num": 138, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 647338
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 361630, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/3600-0.txt", 
    "implicative_pattern": "come", 
    "in-dataset_implicative_shuffle_num": 34, 
    "inf_sentences_id": 1067533, 
    "line": "You shall see them come out with fire and fury sparkling in their eyes :", 
    "linenum": 9431, 
    "matchl": "You shall see them come out with fire and fury sparkling in their eyes :", 
    "out-dataset_implicative_shuffle_num": 139, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1295113
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1293, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/23", 
    "implicative_pattern": "drive", 
    "in-dataset_implicative_shuffle_num": 35, 
    "inf_sentences_id": 688589, 
    "line": "For some , that message may have seemed distressingly like Gorbachev 's forecast at the beginning of 1988 , when he said `` immense and hard work '' lay ahead in his drive for economic change .", 
    "linenum": 8, 
    "matchl": "For some , that message may have seemed distressingly like Gorbachev 's forecast at the beginning of 1988 , when he said `` immense and hard work '' lay ahead in his drive for economic change .", 
    "out-dataset_implicative_shuffle_num": 140, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 916169
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 2819, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 35, 
    "in-dataset_question_shuffle_num": 14414, 
    "in-dataset_request_shuffle_num": 223, 
    "inf_sentences_id": 693267, 
    "line": "How can I find online spelling ?", 
    "linenum": 1819, 
    "matchl": "How can I find online spelling ?", 
    "out-dataset_implicative_shuffle_num": 141, 
    "out-dataset_question_shuffle_num": 43289, 
    "out-dataset_request_shuffle_num": 671, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 920847
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 599216, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 35, 
    "inf_sentences_id": 599237, 
    "line": "You 'll find that out soon enough .", 
    "linenum": 599216, 
    "matchl": "You 'll find that out soon enough .", 
    "out-dataset_implicative_shuffle_num": 142, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 826494
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 326980, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/3207.txt.utf-8", 
    "implicative_pattern": "consent", 
    "in-dataset_implicative_shuffle_num": 35, 
    "inf_sentences_id": 1032883, 
    "line": "The Kingdome of God in the Writings of Divines , and specially in Sermons , and Treatises of Devotion , is taken most commonly for Eternall Felicity , after this life , in the Highest Heaven , which they also call the Kingdome of Glory ; and sometimes for ( the earnest of that felicity ) Sanctification , which they terme the Kingdome of Grace , but never for the Monarchy , that is to say , the Soveraign Power of God over any Subjects acquired by their own consent , which is the proper signification of Kingdome .", 
    "linenum": 3531, 
    "matchl": "The Kingdome of God in the Writings of Divines , and specially in Sermons , and Treatises of Devotion , is taken most commonly for Eternall Felicity , after this life , in the Highest Heaven , which they also call the Kingdome of Glory ; and sometimes for ( the earnest of that felicity ) Sanctification , which they terme the Kingdome of Grace , but never for the Monarchy , that is to say , the Soveraign Power of God over any Subjects acquired by their own consent , which is the proper signification of Kingdome .", 
    "out-dataset_implicative_shuffle_num": 143, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1260463
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 648, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/119", 
    "implicative_pattern": "force", 
    "in-dataset_implicative_shuffle_num": 36, 
    "inf_sentences_id": 687944, 
    "line": "One of the reports , the department 's first extensive analysis of potential labor shortages , said major shortages could occur because the economy is projected to grow at 2 percent to 3 percent annually while the rate of work force growth will be just 1 percent .", 
    "linenum": 3, 
    "matchl": "One of the reports , the department 's first extensive analysis of potential labor shortages , said major shortages could occur because the economy is projected to grow at 2 percent to 3 percent annually while the rate of work force growth will be just 1 percent .", 
    "out-dataset_implicative_shuffle_num": 144, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 915524
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 13257, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "work", 
    "in-dataset_implicative_shuffle_num": 36, 
    "in-dataset_question_shuffle_num": 7205, 
    "inf_sentences_id": 703705, 
    "line": "How does an abacus work ?", 
    "linenum": 3257, 
    "matchl": "How does an abacus work ?", 
    "out-dataset_implicative_shuffle_num": 145, 
    "out-dataset_question_shuffle_num": 21662, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 931285
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 332641, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "worked", 
    "in-dataset_implicative_shuffle_num": 36, 
    "in-dataset_question_shuffle_num": 25321, 
    "inf_sentences_id": 332660, 
    "line": "You worked for Tom , did n't you ?", 
    "linenum": 332641, 
    "matchl": "You worked for Tom , did n't you ?", 
    "out-dataset_implicative_shuffle_num": 146, 
    "out-dataset_question_shuffle_num": 65894, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 559919
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 36346, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1260.txt.utf-8", 
    "implicative_pattern": "attempt", 
    "in-dataset_implicative_shuffle_num": 36, 
    "inf_sentences_id": 742246, 
    "line": "Besides , you might have waited till to-morrow , and had me with you : it was mere folly to attempt the interview to-night , and alone . \"", 
    "linenum": 4054, 
    "matchl": "Besides , you might have waited till to-morrow , and had me with you : it was mere folly to attempt the interview to-night , and alone . \"", 
    "out-dataset_implicative_shuffle_num": 147, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 969826
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 3014, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/93", 
    "implicative_pattern": "prepare", 
    "in-dataset_implicative_shuffle_num": 37, 
    "inf_sentences_id": 690310, 
    "line": "The shooting came a month after Contorno testified before Italian magistrates , who questioned him in the United States to prepare another mass Mafia trial .", 
    "linenum": 5, 
    "matchl": "The shooting came a month after Contorno testified before Italian magistrates , who questioned him in the United States to prepare another mass Mafia trial .", 
    "out-dataset_implicative_shuffle_num": 148, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 917890
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 15359, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "used", 
    "in-dataset_implicative_shuffle_num": 37, 
    "in-dataset_question_shuffle_num": 14695, 
    "inf_sentences_id": 705807, 
    "line": "Who used AuH2O as an election slogan ?", 
    "linenum": 5359, 
    "matchl": "Who used AuH2O as an election slogan ?", 
    "out-dataset_implicative_shuffle_num": 149, 
    "out-dataset_question_shuffle_num": 44132, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 933387
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 285232, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "show", 
    "in-dataset_implicative_shuffle_num": 37, 
    "inf_sentences_id": 285250, 
    "line": "Show me the picture .", 
    "linenum": 285232, 
    "matchl": "Show me the picture .", 
    "out-dataset_implicative_shuffle_num": 150, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 512510
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 492012, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/98-0.txt", 
    "implicative_pattern": "say", 
    "in-dataset_implicative_shuffle_num": 37, 
    "inf_sentences_id": 1197916, 
    "line": "Now , pray say no more about it .", 
    "linenum": 2777, 
    "matchl": "Now , pray say no more about it .", 
    "out-dataset_implicative_shuffle_num": 151, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1425496
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 783, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/124", 
    "implicative_pattern": "said", 
    "in-dataset_implicative_shuffle_num": 38, 
    "inf_sentences_id": 688079, 
    "line": "Shoney 's Inc. said it will report a write-off of $2.5 million , or seven cents a share , for its fourth quarter ended yesterday .", 
    "linenum": 0, 
    "matchl": "Shoney 's Inc. said it will report a write-off of $2.5 million , or seven cents a share , for its fourth quarter ended yesterday .", 
    "out-dataset_implicative_shuffle_num": 152, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 915659
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 3525, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "get", 
    "in-dataset_implicative_shuffle_num": 38, 
    "in-dataset_question_shuffle_num": 11003, 
    "inf_sentences_id": 693973, 
    "line": "Whose first presidential order was : `` Let 's get this goddamn thing airborne '' ?", 
    "linenum": 525, 
    "matchl": "Whose first presidential order was : `` Let 's get this goddamn thing airborne '' ?", 
    "out-dataset_implicative_shuffle_num": 153, 
    "out-dataset_question_shuffle_num": 33056, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 921553
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 462697, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "led", 
    "in-dataset_implicative_shuffle_num": 38, 
    "inf_sentences_id": 462717, 
    "line": "Tom took her by the arm and led her out on the dance floor .", 
    "linenum": 462697, 
    "matchl": "Tom took her by the arm and led her out on the dance floor .", 
    "out-dataset_implicative_shuffle_num": 154, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 689975
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 187850, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2147-0.txt", 
    "implicative_pattern": "failed", 
    "in-dataset_implicative_shuffle_num": 38, 
    "inf_sentences_id": 893751, 
    "line": "It may readily be supposed that the part played by my friend , in the drama at the Rue Morgue , had not failed of its impression upon the fancies of the Parisian police .", 
    "linenum": 2677, 
    "matchl": "It may readily be supposed that the part played by my friend , in the drama at the Rue Morgue , had not failed of its impression upon the fancies of the Parisian police .", 
    "out-dataset_implicative_shuffle_num": 155, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1121331
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2164, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/61", 
    "implicative_pattern": "doubt", 
    "in-dataset_implicative_shuffle_num": 39, 
    "inf_sentences_id": 689460, 
    "line": "`` But the question is whether or not he can adapt his behavior to what he knows is right and wrong , and there 's no doubt in this particular case that he knows the difference between right and wrong .", 
    "linenum": 28, 
    "matchl": "`` But the question is whether or not he can adapt his behavior to what he knows is right and wrong , and there 's no doubt in this particular case that he knows the difference between right and wrong .", 
    "out-dataset_implicative_shuffle_num": 156, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 917040
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 14266, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "say", 
    "in-dataset_implicative_shuffle_num": 39, 
    "in-dataset_question_shuffle_num": 9296, 
    "inf_sentences_id": 704714, 
    "line": "How do you say 2 in Latin ?", 
    "linenum": 4266, 
    "matchl": "How do you say 2 in Latin ?", 
    "out-dataset_implicative_shuffle_num": 157, 
    "out-dataset_question_shuffle_num": 27935, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 932294
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 73271, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "try", 
    "in-dataset_implicative_shuffle_num": 39, 
    "inf_sentences_id": 73287, 
    "line": "I never try to go to there .", 
    "linenum": 73271, 
    "matchl": "I never try to go to there .", 
    "out-dataset_implicative_shuffle_num": 158, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 300549
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 393070, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/4300-0.txt", 
    "implicative_pattern": "saw", 
    "in-dataset_implicative_shuffle_num": 39, 
    "inf_sentences_id": 1098973, 
    "line": "I saw all .", 
    "linenum": 15299, 
    "matchl": "I saw all .", 
    "out-dataset_implicative_shuffle_num": 159, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1326553
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 524, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/115", 
    "implicative_pattern": "helped", 
    "in-dataset_implicative_shuffle_num": 40, 
    "inf_sentences_id": 687820, 
    "line": "Don Kohler , 64 , of Rogers , Ark. , the torpedoman who helped pull a grateful Bush to safety from his orange life raft onto the Finback 's deck , remembers offering a smile and a hearty `` welcome aboard , '' but recalls little else about the incident .", 
    "linenum": 1, 
    "matchl": "Don Kohler , 64 , of Rogers , Ark. , the torpedoman who helped pull a grateful Bush to safety from his orange life raft onto the Finback 's deck , remembers offering a smile and a hearty `` welcome aboard , '' but recalls little else about the incident .", 
    "out-dataset_implicative_shuffle_num": 160, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 915400
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 12823, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "make", 
    "in-dataset_implicative_shuffle_num": 40, 
    "in-dataset_question_shuffle_num": 8391, 
    "inf_sentences_id": 703271, 
    "line": "What four tournaments make up tennis ' Grand Slam ?", 
    "linenum": 2823, 
    "matchl": "What four tournaments make up tennis ' Grand Slam ?", 
    "out-dataset_implicative_shuffle_num": 161, 
    "out-dataset_question_shuffle_num": 25220, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 930851
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 234991, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "help", 
    "in-dataset_implicative_shuffle_num": 40, 
    "inf_sentences_id": 235009, 
    "line": "This is the first time I 've ever needed help .", 
    "linenum": 234991, 
    "matchl": "This is the first time I 've ever needed help .", 
    "out-dataset_implicative_shuffle_num": 162, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 462269
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 333757, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/33.txt.utf-8", 
    "implicative_pattern": "said", 
    "in-dataset_implicative_shuffle_num": 40, 
    "inf_sentences_id": 1039660, 
    "line": "\" And now , Mistress Prynne , \" said old Roger Chillingworth , as he was hereafter to be named , \" I leave thee alone : alone with thy infant and the scarlet letter !", 
    "linenum": 868, 
    "matchl": "\" And now , Mistress Prynne , \" said old Roger Chillingworth , as he was hereafter to be named , \" I leave thee alone : alone with thy infant and the scarlet letter !", 
    "out-dataset_implicative_shuffle_num": 163, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1267240
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1788, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/45", 
    "implicative_pattern": "warrant", 
    "in-dataset_implicative_shuffle_num": 41, 
    "inf_sentences_id": 689084, 
    "line": "- Parkin paid Jean Uebele , a former contract negotiator at the cruise missile office where Parkin once worked , $100 a week for information , the warrant says .", 
    "linenum": 18, 
    "matchl": "- Parkin paid Jean Uebele , a former contract negotiator at the cruise missile office where Parkin once worked , $100 a week for information , the warrant says .", 
    "out-dataset_implicative_shuffle_num": 164, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 916664
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 10782, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "made", 
    "in-dataset_implicative_shuffle_num": 41, 
    "in-dataset_question_shuffle_num": 6544, 
    "inf_sentences_id": 701230, 
    "line": "What are two plants that clothes are made from ?", 
    "linenum": 782, 
    "matchl": "What are two plants that clothes are made from ?", 
    "out-dataset_implicative_shuffle_num": 165, 
    "out-dataset_question_shuffle_num": 19679, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 928810
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 486728, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "remind", 
    "in-dataset_implicative_shuffle_num": 41, 
    "inf_sentences_id": 486748, 
    "line": "Remind me to thank Tom the next time I see him .", 
    "linenum": 486728, 
    "matchl": "Remind me to thank Tom the next time I see him .", 
    "out-dataset_implicative_shuffle_num": 166, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 714006
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 301429, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2852-0.txt", 
    "implicative_pattern": "understand", 
    "in-dataset_implicative_shuffle_num": 41, 
    "in-dataset_question_shuffle_num": 34806, 
    "inf_sentences_id": 1007332, 
    "line": "\" Then I understand that on your arrival in London yesterday you went out at once and bought a pair of boots ? \"", 
    "linenum": 708, 
    "matchl": "\" Then I understand that on your arrival in London yesterday you went out at once and bought a pair of boots ? \"", 
    "out-dataset_implicative_shuffle_num": 167, 
    "out-dataset_question_shuffle_num": 84865, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1234912
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2228, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/65", 
    "implicative_pattern": "discouraging", 
    "in-dataset_implicative_shuffle_num": 42, 
    "inf_sentences_id": 689524, 
    "line": "Fear that the U.S. government will go it alone in world trade is discouraging other countries from joining in an accord that could cut spending on farmers by tens of billions of dollars every year , according to a report published by the International Monetary Fund .", 
    "linenum": 0, 
    "matchl": "Fear that the U.S. government will go it alone in world trade is discouraging other countries from joining in an accord that could cut spending on farmers by tens of billions of dollars every year , according to a report published by the International Monetary Fund .", 
    "out-dataset_implicative_shuffle_num": 168, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 917104
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 13156, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "control", 
    "in-dataset_implicative_shuffle_num": 42, 
    "in-dataset_question_shuffle_num": 6010, 
    "inf_sentences_id": 703604, 
    "line": "What is the brand name of a chemical used to control ripening ?", 
    "linenum": 3156, 
    "matchl": "What is the brand name of a chemical used to control ripening ?", 
    "out-dataset_implicative_shuffle_num": 169, 
    "out-dataset_question_shuffle_num": 18077, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 931184
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 264048, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "see", 
    "in-dataset_implicative_shuffle_num": 42, 
    "in-dataset_question_shuffle_num": 28429, 
    "inf_sentences_id": 264066, 
    "line": "What did he see ?", 
    "linenum": 264048, 
    "matchl": "What did he see ?", 
    "out-dataset_implicative_shuffle_num": 170, 
    "out-dataset_question_shuffle_num": 72110, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 491326
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 205588, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2500.txt.utf-8", 
    "implicative_pattern": "admitted", 
    "in-dataset_implicative_shuffle_num": 42, 
    "inf_sentences_id": 911490, 
    "line": "\" Well yes , \" she admitted .", 
    "linenum": 723, 
    "matchl": "\" Well yes , \" she admitted .", 
    "out-dataset_implicative_shuffle_num": 171, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1139070
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2056, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/56", 
    "implicative_pattern": "showed", 
    "in-dataset_implicative_shuffle_num": 43, 
    "inf_sentences_id": 689352, 
    "line": "Affadavits showed that Parkin , Berlin and Savaides had planned at one time to divide $150,000 from Teledyne .", 
    "linenum": 18, 
    "matchl": "Affadavits showed that Parkin , Berlin and Savaides had planned at one time to divide $150,000 from Teledyne .", 
    "out-dataset_implicative_shuffle_num": 172, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 916932
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 1657, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "implicative_pattern": "determined", 
    "in-dataset_implicative_shuffle_num": 43, 
    "in-dataset_question_shuffle_num": 14752, 
    "inf_sentences_id": 692105, 
    "line": "How is Easter Sunday 's date determined ?", 
    "linenum": 657, 
    "matchl": "How is Easter Sunday 's date determined ?", 
    "out-dataset_implicative_shuffle_num": 173, 
    "out-dataset_question_shuffle_num": 44303, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 919685
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 265451, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "know", 
    "in-dataset_implicative_shuffle_num": 43, 
    "inf_sentences_id": 265469, 
    "line": "I want to know who did that .", 
    "linenum": 265451, 
    "matchl": "I want to know who did that .", 
    "out-dataset_implicative_shuffle_num": 174, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 492729
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 429020, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/521-0.txt", 
    "implicative_pattern": "coming", 
    "in-dataset_implicative_shuffle_num": 43, 
    "inf_sentences_id": 1134924, 
    "line": "We had , upon the first appearance of the boat 's coming from the ship , considered of separating our prisoners ; and we had , indeed , secured them effectually .", 
    "linenum": 2092, 
    "matchl": "We had , upon the first appearance of the boat 's coming from the ship , considered of separating our prisoners ; and we had , indeed , secured them effectually .", 
    "out-dataset_implicative_shuffle_num": 175, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1362504
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 460, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/113", 
    "implicative_pattern": "come", 
    "in-dataset_implicative_shuffle_num": 44, 
    "inf_sentences_id": 687756, 
    "line": "`` We try very hard to keep some of the hotels in a decent state so the foreign investors can come in .", 
    "linenum": 27, 
    "matchl": "`` We try very hard to keep some of the hotels in a decent state so the foreign investors can come in .", 
    "out-dataset_implicative_shuffle_num": 176, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 915336
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 6775, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "happened", 
    "in-dataset_implicative_shuffle_num": 44, 
    "in-dataset_question_shuffle_num": 14233, 
    "inf_sentences_id": 697223, 
    "line": "What historical event happened in Dogtown in 1899 ?", 
    "linenum": 775, 
    "matchl": "What historical event happened in Dogtown in 1899 ?", 
    "out-dataset_implicative_shuffle_num": 177, 
    "out-dataset_question_shuffle_num": 42746, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 924803
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 176759, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "happen", 
    "in-dataset_implicative_shuffle_num": 44, 
    "in-dataset_question_shuffle_num": 53523, 
    "inf_sentences_id": 176776, 
    "line": "How could this happen ? I thought you were on the pill .", 
    "linenum": 176759, 
    "matchl": "How could this happen ? I thought you were on the pill .", 
    "out-dataset_implicative_shuffle_num": 178, 
    "out-dataset_question_shuffle_num": 122298, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 404037
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 16888, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1184-0.txt", 
    "implicative_pattern": "accept", 
    "in-dataset_implicative_shuffle_num": 44, 
    "in-dataset_question_shuffle_num": 19274, 
    "in-dataset_request_shuffle_num": 2404, 
    "inf_sentences_id": 722788, 
    "line": "\" You are a great almsgiver , \" said the visitor , \" and although you are said to be rich , I will venture to offer you something for your poor people ; will you accept my offering ? \"", 
    "linenum": 15365, 
    "matchl": "\" You are a great almsgiver , \" said the visitor , \" and although you are said to be rich , I will venture to offer you something for your poor people ; will you accept my offering ? \"", 
    "out-dataset_implicative_shuffle_num": 179, 
    "out-dataset_question_shuffle_num": 53801, 
    "out-dataset_request_shuffle_num": 5196, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 950368
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1002, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/135", 
    "implicative_pattern": "wonder", 
    "in-dataset_implicative_shuffle_num": 45, 
    "inf_sentences_id": 688298, 
    "line": "Others wonder how many more of these shocks the small investor can stand .", 
    "linenum": 24, 
    "matchl": "Others wonder how many more of these shocks the small investor can stand .", 
    "out-dataset_implicative_shuffle_num": 180, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 915878
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 2163, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "implicative_pattern": "stop", 
    "in-dataset_implicative_shuffle_num": 45, 
    "in-dataset_question_shuffle_num": 6381, 
    "in-dataset_request_shuffle_num": 236, 
    "inf_sentences_id": 692611, 
    "line": "How can you stop the itch from poison ivy ?", 
    "linenum": 1163, 
    "matchl": "How can you stop the itch from poison ivy ?", 
    "out-dataset_implicative_shuffle_num": 181, 
    "out-dataset_question_shuffle_num": 19190, 
    "out-dataset_request_shuffle_num": 710, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 920191
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 624123, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "upset", 
    "in-dataset_implicative_shuffle_num": 45, 
    "inf_sentences_id": 624145, 
    "line": "I got a little upset over it .", 
    "linenum": 624123, 
    "matchl": "I got a little upset over it .", 
    "out-dataset_implicative_shuffle_num": 182, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 851401
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 387404, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/4300-0.txt", 
    "implicative_pattern": "began", 
    "in-dataset_implicative_shuffle_num": 45, 
    "inf_sentences_id": 1093307, 
    "line": "He began to scribble on a slip of paper .", 
    "linenum": 9633, 
    "matchl": "He began to scribble on a slip of paper .", 
    "out-dataset_implicative_shuffle_num": 183, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1320887
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 291, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/107", 
    "implicative_pattern": "get", 
    "in-dataset_implicative_shuffle_num": 46, 
    "inf_sentences_id": 687587, 
    "line": "... With the stones , we get rid of the enemy . ''", 
    "linenum": 27, 
    "matchl": "... With the stones , we get rid of the enemy . ''", 
    "out-dataset_implicative_shuffle_num": 184, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 915167
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 10941, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "supposed", 
    "in-dataset_implicative_shuffle_num": 46, 
    "in-dataset_question_shuffle_num": 8704, 
    "inf_sentences_id": 701389, 
    "line": "What sports event is Meyer Wolfsheim supposed to have fixed in The Great Gatsby ?", 
    "linenum": 941, 
    "matchl": "What sports event is Meyer Wolfsheim supposed to have fixed in The Great Gatsby ?", 
    "out-dataset_implicative_shuffle_num": 185, 
    "out-dataset_question_shuffle_num": 26159, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 928969
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 511180, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "tell", 
    "in-dataset_implicative_shuffle_num": 46, 
    "inf_sentences_id": 511201, 
    "line": "Tell them I 'll be there by 2:30 .", 
    "linenum": 511180, 
    "matchl": "Tell them I 'll be there by 2:30 .", 
    "out-dataset_implicative_shuffle_num": 186, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 738458
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 14396, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1184-0.txt", 
    "implicative_pattern": "see", 
    "in-dataset_implicative_shuffle_num": 46, 
    "inf_sentences_id": 720296, 
    "line": "\" Ah , you see ---- \"", 
    "linenum": 12873, 
    "matchl": "\" Ah , you see ---- \"", 
    "out-dataset_implicative_shuffle_num": 187, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 947876
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1953, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/51", 
    "implicative_pattern": "mentioned", 
    "in-dataset_implicative_shuffle_num": 47, 
    "inf_sentences_id": 689249, 
    "line": "He has had nothing to do with the hiring or the service of those mentioned in this article .", 
    "linenum": 8, 
    "matchl": "He has had nothing to do with the hiring or the service of those mentioned in this article .", 
    "out-dataset_implicative_shuffle_num": 188, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 916829
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 4237, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "seen", 
    "in-dataset_implicative_shuffle_num": 47, 
    "inf_sentences_id": 694685, 
    "line": "Name the On Stage character whose face was never seen .", 
    "linenum": 1237, 
    "matchl": "Name the On Stage character whose face was never seen .", 
    "out-dataset_implicative_shuffle_num": 189, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 922265
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 368067, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "think", 
    "in-dataset_implicative_shuffle_num": 47, 
    "in-dataset_question_shuffle_num": 874, 
    "inf_sentences_id": 368086, 
    "line": "When do you think the Philippines will host the Olympic Games ?", 
    "linenum": 368067, 
    "matchl": "When do you think the Philippines will host the Olympic Games ?", 
    "out-dataset_implicative_shuffle_num": 190, 
    "out-dataset_question_shuffle_num": 2670, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 595345
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 124726, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/158-0.txt", 
    "implicative_pattern": "miss", 
    "in-dataset_counterfactual_shuffle_num": 5742, 
    "in-dataset_implicative_shuffle_num": 47, 
    "inf_sentences_id": 830627, 
    "line": "' Aye , pray do , ' said Mr. Frank Churchill , ' Miss Woodhouse 's opinion of the instrument will be worth having.'--But , said I , I shall be more sure of succeeding if one of you will go with me . --", 
    "linenum": 3879, 
    "matchl": "' Aye , pray do , ' said Mr. Frank Churchill , ' Miss Woodhouse 's opinion of the instrument will be worth having.'--But , said I , I shall be more sure of succeeding if one of you will go with me . --", 
    "out-dataset_counterfactual_shuffle_num": 11691, 
    "out-dataset_implicative_shuffle_num": 191, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1058207
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 820, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/125", 
    "implicative_pattern": "determined", 
    "in-dataset_implicative_shuffle_num": 48, 
    "inf_sentences_id": 688116, 
    "line": "The company said losses from the Oct. 17 earthquake in California have n't yet been determined , but that it provides earthquake coverage to about 1,400 properties in the stricken area .", 
    "linenum": 30, 
    "matchl": "The company said losses from the Oct. 17 earthquake in California have n't yet been determined , but that it provides earthquake coverage to about 1,400 properties in the stricken area .", 
    "out-dataset_implicative_shuffle_num": 192, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 915696
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 5244, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "show", 
    "in-dataset_implicative_shuffle_num": 48, 
    "in-dataset_question_shuffle_num": 691, 
    "inf_sentences_id": 695692, 
    "line": "What well-known TV talk show host was a lay preacher by the time he was seventeen ?", 
    "linenum": 2244, 
    "matchl": "What well-known TV talk show host was a lay preacher by the time he was seventeen ?", 
    "out-dataset_implicative_shuffle_num": 193, 
    "out-dataset_question_shuffle_num": 2120, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 923272
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 486473, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "see", 
    "in-dataset_counterfactual_shuffle_num": 14430, 
    "in-dataset_implicative_shuffle_num": 48, 
    "inf_sentences_id": 486493, 
    "line": "I 'm calling to see if you 'd be interested in going to Boston with me next week .", 
    "linenum": 486473, 
    "matchl": "I 'm calling to see if you 'd be interested in going to Boston with me next week .", 
    "out-dataset_counterfactual_shuffle_num": 29066, 
    "out-dataset_implicative_shuffle_num": 194, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 713751
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 155650, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/174.txt.utf-8", 
    "implicative_pattern": "think", 
    "in-dataset_implicative_shuffle_num": 48, 
    "inf_sentences_id": 861551, 
    "line": "It was better not to think of the past .", 
    "linenum": 6163, 
    "matchl": "It was better not to think of the past .", 
    "out-dataset_implicative_shuffle_num": 195, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1089131
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 99, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/100", 
    "implicative_pattern": "used", 
    "in-dataset_implicative_shuffle_num": 49, 
    "inf_sentences_id": 687395, 
    "line": "The CFM56s used on 737s have been in service for about five years .", 
    "linenum": 27, 
    "matchl": "The CFM56s used on 737s have been in service for about five years .", 
    "out-dataset_implicative_shuffle_num": 196, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 914975
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 12886, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "get", 
    "in-dataset_implicative_shuffle_num": 49, 
    "in-dataset_question_shuffle_num": 14575, 
    "in-dataset_request_shuffle_num": 14, 
    "inf_sentences_id": 703334, 
    "line": "Where can I get cotton textiles importer details ?", 
    "linenum": 2886, 
    "matchl": "Where can I get cotton textiles importer details ?", 
    "out-dataset_implicative_shuffle_num": 197, 
    "out-dataset_question_shuffle_num": 43772, 
    "out-dataset_request_shuffle_num": 44, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 930914
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 518352, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "help", 
    "in-dataset_implicative_shuffle_num": 49, 
    "inf_sentences_id": 518373, 
    "line": "I could n't help him .", 
    "linenum": 518352, 
    "matchl": "I could n't help him .", 
    "out-dataset_implicative_shuffle_num": 198, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 745630
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 98373, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1400-0.txt", 
    "implicative_pattern": "disappointed", 
    "in-dataset_implicative_shuffle_num": 49, 
    "inf_sentences_id": 804273, 
    "line": "I went on with my explanation , and told her how I had hoped to complete the transaction out of my means , but how in this I was disappointed .", 
    "linenum": 7723, 
    "matchl": "I went on with my explanation , and told her how I had hoped to complete the transaction out of my means , but how in this I was disappointed .", 
    "out-dataset_implicative_shuffle_num": 199, 
    "sampled": [
      "implicative"
    ], 
    "ulf_sentences_id": 1031853
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 10237, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 1326, 
    "in-dataset_question_shuffle_num": 3595, 
    "in-dataset_request_shuffle_num": 0, 
    "inf_sentences_id": 700685, 
    "line": "Where can I find a review of Nightmare on Elm Street in a film journal ?", 
    "linenum": 237, 
    "matchl": "Where can I find a review of Nightmare on Elm Street in a film journal ?", 
    "out-dataset_implicative_shuffle_num": 5305, 
    "out-dataset_question_shuffle_num": 10832, 
    "out-dataset_request_shuffle_num": 1, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 928265
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 80695, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 55448, 
    "in-dataset_request_shuffle_num": 0, 
    "inf_sentences_id": 80711, 
    "line": "Will you give me a ride ?", 
    "linenum": 80695, 
    "matchl": "Will you give me a ride ?", 
    "out-dataset_question_shuffle_num": 126148, 
    "out-dataset_request_shuffle_num": 2, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 307973
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 317198, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/30360.txt.utf-8", 
    "implicative_pattern": "know", 
    "in-dataset_implicative_shuffle_num": 105235, 
    "in-dataset_question_shuffle_num": 6717, 
    "in-dataset_request_shuffle_num": 0, 
    "inf_sentences_id": 1023101, 
    "line": "She counted on her fingers and said , \" Four months and about a week. \" \" Are you sure ? \" \" Yes. \" \" How can you tell ? \" \" I have never been done but on one day. \" \" Nonsense. \" \" It 's true. \" \" Do you mean that once putting it up you got you in the family way ? \" \" I did n't mean that , \" said she , \" he were only once with me , but he did it all night , and nearly all the next day. \" \" A dozen times ? \" \" Do n't know , I was so ill , so sleepy. \" \" Who is the father ? \" She shook her head .", 
    "linenum": 4927, 
    "matchl": "She counted on her fingers and said , \" Four months and about a week. \" \" Are you sure ? \" \" Yes. \" \" How can you tell ? \" \" I have never been done but on one day. \" \" Nonsense. \" \" It 's true. \" \" Do you mean that once putting it up you got you in the family way ? \" \" I did n't mean that , \" said she , \" he were only once with me , but he did it all night , and nearly all the next day. \" \" A dozen times ? \" \" Do n't know , I was so ill , so sleepy. \" \" Who is the father ? \" She shook her head .", 
    "out-dataset_implicative_shuffle_num": 216171, 
    "out-dataset_question_shuffle_num": 20200, 
    "out-dataset_request_shuffle_num": 3, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1250681
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 8156, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 189, 
    "in-dataset_question_shuffle_num": 3632, 
    "in-dataset_request_shuffle_num": 1, 
    "inf_sentences_id": 698604, 
    "line": "How can I find out how much it costs to raise a baby for six months ?", 
    "linenum": 2156, 
    "matchl": "How can I find out how much it costs to raise a baby for six months ?", 
    "out-dataset_implicative_shuffle_num": 757, 
    "out-dataset_question_shuffle_num": 10943, 
    "out-dataset_request_shuffle_num": 5, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 926184
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 406827, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "please", 
    "in-dataset_implicative_shuffle_num": 282059, 
    "in-dataset_question_shuffle_num": 67655, 
    "in-dataset_request_shuffle_num": 1, 
    "inf_sentences_id": 406847, 
    "line": "Would you please take me home ?", 
    "linenum": 406827, 
    "matchl": "Would you please take me home ?", 
    "out-dataset_implicative_shuffle_num": 548405, 
    "out-dataset_question_shuffle_num": 141439, 
    "out-dataset_request_shuffle_num": 6, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 634105
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 240669, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2600-0.txt", 
    "in-dataset_question_shuffle_num": 47262, 
    "in-dataset_request_shuffle_num": 1, 
    "inf_sentences_id": 946571, 
    "line": "\" Oh , how can you sleep ?", 
    "linenum": 11548, 
    "matchl": "\" Oh , how can you sleep ?", 
    "out-dataset_question_shuffle_num": 109777, 
    "out-dataset_request_shuffle_num": 7, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 1174151
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 660, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_1000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 427, 
    "in-dataset_question_shuffle_num": 6968, 
    "in-dataset_request_shuffle_num": 2, 
    "inf_sentences_id": 691108, 
    "line": "Where can I find information on the Narragansett Indians and other tribes in Rhode Island ?", 
    "linenum": 660, 
    "matchl": "Where can I find information on the Narragansett Indians and other tribes in Rhode Island ?", 
    "out-dataset_implicative_shuffle_num": 1709, 
    "out-dataset_question_shuffle_num": 20951, 
    "out-dataset_request_shuffle_num": 8, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 918688
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 235459, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "help", 
    "in-dataset_implicative_shuffle_num": 179106, 
    "in-dataset_request_shuffle_num": 2, 
    "inf_sentences_id": 235477, 
    "line": "I cannot knead this dough by myself. I need you to help me .", 
    "linenum": 235459, 
    "matchl": "I cannot knead this dough by myself. I need you to help me .", 
    "out-dataset_implicative_shuffle_num": 363912, 
    "out-dataset_request_shuffle_num": 9, 
    "request_pattern": "<begin?>(<1stpron>) need you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "implicative"
    ], 
    "ulf_sentences_id": 462737
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 481701, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/844.txt.utf-8", 
    "in-dataset_question_shuffle_num": 26608, 
    "in-dataset_request_shuffle_num": 2, 
    "inf_sentences_id": 1187605, 
    "line": "And you will shake hands with him , wo n't you , Uncle Jack ?  [ Runs back into the house .]", 
    "linenum": 1401, 
    "matchl": "And you will shake hands with him , wo n't you , Uncle Jack ?  [ Runs back into the house .]", 
    "out-dataset_question_shuffle_num": 68469, 
    "out-dataset_request_shuffle_num": 10, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) (n't|not) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 1415185
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 14665, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_question_shuffle_num": 14059, 
    "in-dataset_request_shuffle_num": 3, 
    "inf_sentences_id": 705113, 
    "line": "What kind of education would you need to become an athletic trainer for the NFL ?", 
    "linenum": 4665, 
    "matchl": "What kind of education would you need to become an athletic trainer for the NFL ?", 
    "out-dataset_question_shuffle_num": 42224, 
    "out-dataset_request_shuffle_num": 11, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 932693
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 463131, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "tell", 
    "in-dataset_implicative_shuffle_num": 255930, 
    "in-dataset_question_shuffle_num": 29298, 
    "in-dataset_request_shuffle_num": 3, 
    "inf_sentences_id": 463151, 
    "line": "Can you tell me where you were at the time of the murder ?", 
    "linenum": 463131, 
    "matchl": "Can you tell me where you were at the time of the murder ?", 
    "out-dataset_implicative_shuffle_num": 517560, 
    "out-dataset_question_shuffle_num": 73848, 
    "out-dataset_request_shuffle_num": 12, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 690409
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 99153, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1400-0.txt", 
    "implicative_pattern": "come", 
    "in-dataset_implicative_shuffle_num": 112467, 
    "in-dataset_question_shuffle_num": 12375, 
    "in-dataset_request_shuffle_num": 3, 
    "inf_sentences_id": 805053, 
    "line": "He was not to come down till he saw us. Can you see his signal ? \"", 
    "linenum": 8503, 
    "matchl": "He was not to come down till he saw us. Can you see his signal ? \"", 
    "out-dataset_implicative_shuffle_num": 230635, 
    "out-dataset_question_shuffle_num": 37174, 
    "out-dataset_request_shuffle_num": 13, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1032633
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 4163, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "stop", 
    "in-dataset_implicative_shuffle_num": 1987, 
    "in-dataset_question_shuffle_num": 6015, 
    "in-dataset_request_shuffle_num": 4, 
    "inf_sentences_id": 694611, 
    "line": "How can you stop the itch from poison ivy ?", 
    "linenum": 1163, 
    "matchl": "How can you stop the itch from poison ivy ?", 
    "out-dataset_implicative_shuffle_num": 7949, 
    "out-dataset_question_shuffle_num": 18092, 
    "out-dataset_request_shuffle_num": 14, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 922191
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If)<mid>(was|were|had|<past>|<ppart>)<mid?>(<futr>) .+", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 132763, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "come", 
    "in-dataset_counterfactual_shuffle_num": 3962, 
    "in-dataset_implicative_shuffle_num": 58218, 
    "in-dataset_question_shuffle_num": 44616, 
    "in-dataset_request_shuffle_num": 4, 
    "inf_sentences_id": 132780, 
    "line": "If a tiger should come out of the cage , what would you do ?", 
    "linenum": 132763, 
    "matchl": "If a tiger should come out of the cage , what would you do ?", 
    "out-dataset_counterfactual_shuffle_num": 8130, 
    "out-dataset_implicative_shuffle_num": 122136, 
    "out-dataset_question_shuffle_num": 104484, 
    "out-dataset_request_shuffle_num": 15, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "counterfactual", 
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 360041
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 280664, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/28054-0.txt", 
    "implicative_pattern": "dare", 
    "in-dataset_implicative_shuffle_num": 150613, 
    "in-dataset_question_shuffle_num": 16443, 
    "in-dataset_request_shuffle_num": 4, 
    "inf_sentences_id": 986566, 
    "line": "How could I dare to keep it back from him ?", 
    "linenum": 8239, 
    "matchl": "How could I dare to keep it back from him ?", 
    "out-dataset_implicative_shuffle_num": 306927, 
    "out-dataset_question_shuffle_num": 48139, 
    "out-dataset_request_shuffle_num": 16, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1214146
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 42662, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "tell", 
    "in-dataset_implicative_shuffle_num": 242766, 
    "in-dataset_question_shuffle_num": 2515, 
    "in-dataset_request_shuffle_num": 5, 
    "inf_sentences_id": 42678, 
    "line": "Will you tell me how to sing this song ?", 
    "linenum": 42662, 
    "matchl": "Will you tell me how to sing this song ?", 
    "out-dataset_implicative_shuffle_num": 491232, 
    "out-dataset_question_shuffle_num": 7593, 
    "out-dataset_request_shuffle_num": 18, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 269940
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 39925, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1260.txt.utf-8", 
    "in-dataset_question_shuffle_num": 14521, 
    "in-dataset_request_shuffle_num": 5, 
    "inf_sentences_id": 745825, 
    "line": "He is alone this evening , and not very well : will you return with me and visit him ? \"", 
    "linenum": 7633, 
    "matchl": "He is alone this evening , and not very well : will you return with me and visit him ? \"", 
    "out-dataset_question_shuffle_num": 43612, 
    "out-dataset_request_shuffle_num": 19, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 973405
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 7062, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "get", 
    "in-dataset_implicative_shuffle_num": 337, 
    "in-dataset_question_shuffle_num": 15021, 
    "in-dataset_request_shuffle_num": 6, 
    "inf_sentences_id": 697510, 
    "line": "How can I get a comic character I made copyrighted and published ?", 
    "linenum": 1062, 
    "matchl": "How can I get a comic character I made copyrighted and published ?", 
    "out-dataset_implicative_shuffle_num": 1349, 
    "out-dataset_question_shuffle_num": 45110, 
    "out-dataset_request_shuffle_num": 20, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 925090
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 15027, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "make", 
    "in-dataset_counterfactual_shuffle_num": 5702, 
    "in-dataset_implicative_shuffle_num": 104181, 
    "in-dataset_question_shuffle_num": 47123, 
    "in-dataset_request_shuffle_num": 6, 
    "inf_sentences_id": 15043, 
    "line": "If you ca n't keep your promise , what excuse will you make ?", 
    "linenum": 15027, 
    "matchl": "If you ca n't keep your promise , what excuse will you make ?", 
    "out-dataset_counterfactual_shuffle_num": 11610, 
    "out-dataset_implicative_shuffle_num": 214062, 
    "out-dataset_question_shuffle_num": 109498, 
    "out-dataset_request_shuffle_num": 21, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "counterfactual", 
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 242305
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 207985, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2542.txt.utf-8", 
    "implicative_pattern": "come", 
    "in-dataset_implicative_shuffle_num": 14480, 
    "in-dataset_question_shuffle_num": 12555, 
    "in-dataset_request_shuffle_num": 6, 
    "inf_sentences_id": 913887, 
    "line": "No , mother ; but will you come and play again ?", 
    "linenum": 1277, 
    "matchl": "No , mother ; but will you come and play again ?", 
    "out-dataset_implicative_shuffle_num": 34661, 
    "out-dataset_question_shuffle_num": 37714, 
    "out-dataset_request_shuffle_num": 22, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1141467
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 6953, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 3193, 
    "in-dataset_question_shuffle_num": 3575, 
    "in-dataset_request_shuffle_num": 7, 
    "inf_sentences_id": 697401, 
    "line": "Where can I find information on George Bush ?", 
    "linenum": 953, 
    "matchl": "Where can I find information on George Bush ?", 
    "out-dataset_implicative_shuffle_num": 11568, 
    "out-dataset_question_shuffle_num": 10772, 
    "out-dataset_request_shuffle_num": 23, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 924981
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 307364, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "want", 
    "in-dataset_implicative_shuffle_num": 151266, 
    "in-dataset_question_shuffle_num": 74410, 
    "in-dataset_request_shuffle_num": 7, 
    "inf_sentences_id": 307383, 
    "line": "What would you want to drink ?", 
    "linenum": 307364, 
    "matchl": "What would you want to drink ?", 
    "out-dataset_implicative_shuffle_num": 308232, 
    "out-dataset_question_shuffle_num": 148194, 
    "out-dataset_request_shuffle_num": 24, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 534642
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 281416, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/28054-0.txt", 
    "implicative_pattern": "like", 
    "in-dataset_implicative_shuffle_num": 136928, 
    "in-dataset_request_shuffle_num": 7, 
    "inf_sentences_id": 987318, 
    "line": "The seconds , especially mine , were shouting too : \" Can you disgrace the regiment like this , facing your antagonist and begging his forgiveness !", 
    "linenum": 8991, 
    "matchl": "The seconds , especially mine , were shouting too : \" Can you disgrace the regiment like this , facing your antagonist and begging his forgiveness !", 
    "out-dataset_implicative_shuffle_num": 279557, 
    "out-dataset_request_shuffle_num": 25, 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "implicative"
    ], 
    "ulf_sentences_id": 1214898
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 14820, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "use", 
    "in-dataset_implicative_shuffle_num": 2815, 
    "in-dataset_question_shuffle_num": 7788, 
    "in-dataset_request_shuffle_num": 8, 
    "inf_sentences_id": 705268, 
    "line": "Who would you use the Heimlich maneuver on ?", 
    "linenum": 4820, 
    "matchl": "Who would you use the Heimlich maneuver on ?", 
    "out-dataset_implicative_shuffle_num": 10434, 
    "out-dataset_question_shuffle_num": 23411, 
    "out-dataset_request_shuffle_num": 26, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 932848
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 203845, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 20915, 
    "in-dataset_request_shuffle_num": 8, 
    "inf_sentences_id": 203863, 
    "line": "I ca n't keep up with you. Could you dictate a bit slower ?", 
    "linenum": 203845, 
    "matchl": "I ca n't keep up with you. Could you dictate a bit slower ?", 
    "out-dataset_question_shuffle_num": 57082, 
    "out-dataset_request_shuffle_num": 27, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 431123
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 297373, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2814-0.txt", 
    "in-dataset_question_shuffle_num": 51004, 
    "in-dataset_request_shuffle_num": 8, 
    "inf_sentences_id": 1003275, 
    "line": "What will you have ?", 
    "linenum": 1389, 
    "matchl": "What will you have ?", 
    "out-dataset_question_shuffle_num": 117261, 
    "out-dataset_request_shuffle_num": 28, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 1230855
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 5156, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 2367, 
    "in-dataset_question_shuffle_num": 9058, 
    "in-dataset_request_shuffle_num": 9, 
    "inf_sentences_id": 695604, 
    "line": "How can I find out how much it costs to raise a baby for six months ?", 
    "linenum": 2156, 
    "matchl": "How can I find out how much it costs to raise a baby for six months ?", 
    "out-dataset_implicative_shuffle_num": 9090, 
    "out-dataset_question_shuffle_num": 27221, 
    "out-dataset_request_shuffle_num": 29, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 923184
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 91225, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "get", 
    "in-dataset_implicative_shuffle_num": 249898, 
    "in-dataset_question_shuffle_num": 87569, 
    "in-dataset_request_shuffle_num": 9, 
    "inf_sentences_id": 91241, 
    "line": "Could you tell me how to get to the subway station ?", 
    "linenum": 91225, 
    "matchl": "Could you tell me how to get to the subway station ?", 
    "out-dataset_implicative_shuffle_num": 505496, 
    "out-dataset_question_shuffle_num": 161353, 
    "out-dataset_request_shuffle_num": 30, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 318503
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 88793, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/140-0.txt", 
    "in-dataset_question_shuffle_num": 30605, 
    "in-dataset_request_shuffle_num": 9, 
    "inf_sentences_id": 794693, 
    "line": "\" Can you change me a hundred-dollar bill ? \" he demanded .", 
    "linenum": 4611, 
    "matchl": "\" Can you change me a hundred-dollar bill ? \" he demanded .", 
    "out-dataset_question_shuffle_num": 76463, 
    "out-dataset_request_shuffle_num": 31, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 1022273
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 3376, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 1436, 
    "in-dataset_question_shuffle_num": 3382, 
    "in-dataset_request_shuffle_num": 10, 
    "inf_sentences_id": 693824, 
    "line": "Where can I find a case on Individuals with Disabilities Education Act of 1991 ?", 
    "linenum": 376, 
    "matchl": "Where can I find a case on Individuals with Disabilities Education Act of 1991 ?", 
    "out-dataset_implicative_shuffle_num": 5745, 
    "out-dataset_question_shuffle_num": 10193, 
    "out-dataset_request_shuffle_num": 32, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 921404
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 559499, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 80167, 
    "in-dataset_request_shuffle_num": 10, 
    "inf_sentences_id": 559520, 
    "line": "Would you trust them ?", 
    "linenum": 559499, 
    "matchl": "Would you trust them ?", 
    "out-dataset_question_shuffle_num": 153951, 
    "out-dataset_request_shuffle_num": 33, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 786777
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 114735, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1497.txt.utf-8", 
    "implicative_pattern": "allow", 
    "in-dataset_implicative_shuffle_num": 30702, 
    "in-dataset_question_shuffle_num": 4824, 
    "in-dataset_request_shuffle_num": 10, 
    "inf_sentences_id": 820636, 
    "line": "Well , I said , would you not allow that assent and dissent , desire and aversion , attraction and repulsion , are all of them opposites , whether they are regarded as active or passive ( for that makes no difference in the fact of their opposition )?", 
    "linenum": 5451, 
    "matchl": "Well , I said , would you not allow that assent and dissent , desire and aversion , attraction and repulsion , are all of them opposites , whether they are regarded as active or passive ( for that makes no difference in the fact of their opposition )?", 
    "out-dataset_implicative_shuffle_num": 67105, 
    "out-dataset_question_shuffle_num": 14521, 
    "out-dataset_request_shuffle_num": 34, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1048216
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 12227, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 2144, 
    "in-dataset_question_shuffle_num": 8748, 
    "in-dataset_request_shuffle_num": 11, 
    "inf_sentences_id": 702675, 
    "line": "Where can I find a website that gives comparisons of good prices ?", 
    "linenum": 2227, 
    "matchl": "Where can I find a website that gives comparisons of good prices ?", 
    "out-dataset_implicative_shuffle_num": 8421, 
    "out-dataset_question_shuffle_num": 26291, 
    "out-dataset_request_shuffle_num": 35, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 930255
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 535003, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 77230, 
    "in-dataset_request_shuffle_num": 11, 
    "inf_sentences_id": 535024, 
    "line": "Would you lend me a hand ?", 
    "linenum": 535003, 
    "matchl": "Would you lend me a hand ?", 
    "out-dataset_question_shuffle_num": 151014, 
    "out-dataset_request_shuffle_num": 36, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 762281
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 181967, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/209-0.txt", 
    "implicative_pattern": "mean", 
    "in-dataset_implicative_shuffle_num": 146889, 
    "in-dataset_question_shuffle_num": 40472, 
    "in-dataset_request_shuffle_num": 11, 
    "inf_sentences_id": 887868, 
    "line": "\" How can I stop with her , you mean ?", 
    "linenum": 2226, 
    "matchl": "\" How can I stop with her , you mean ?", 
    "out-dataset_implicative_shuffle_num": 299479, 
    "out-dataset_question_shuffle_num": 96197, 
    "out-dataset_request_shuffle_num": 37, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1115448
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 180, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_1000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 1117, 
    "in-dataset_question_shuffle_num": 10186, 
    "in-dataset_request_shuffle_num": 12, 
    "inf_sentences_id": 690628, 
    "line": "Where can I find pictorial directions on how to build a very simple treehouse ?", 
    "linenum": 180, 
    "matchl": "Where can I find pictorial directions on how to build a very simple treehouse ?", 
    "out-dataset_implicative_shuffle_num": 4469, 
    "out-dataset_question_shuffle_num": 30605, 
    "out-dataset_request_shuffle_num": 38, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 918208
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 7481, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "please", 
    "in-dataset_implicative_shuffle_num": 7817, 
    "in-dataset_question_shuffle_num": 31781, 
    "in-dataset_request_shuffle_num": 12, 
    "inf_sentences_id": 7497, 
    "line": "Could you please call him into the meeting ?", 
    "linenum": 7481, 
    "matchl": "Could you please call him into the meeting ?", 
    "out-dataset_implicative_shuffle_num": 21334, 
    "out-dataset_question_shuffle_num": 78814, 
    "out-dataset_request_shuffle_num": 39, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 234759
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 72195, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/135-0.txt", 
    "implicative_pattern": "began", 
    "in-dataset_implicative_shuffle_num": 21728, 
    "in-dataset_question_shuffle_num": 56515, 
    "in-dataset_request_shuffle_num": 12, 
    "inf_sentences_id": 778095, 
    "line": "\" Will you ? \" began Brujon again .", 
    "linenum": 23768, 
    "matchl": "\" Will you ? \" began Brujon again .", 
    "out-dataset_implicative_shuffle_num": 49157, 
    "out-dataset_question_shuffle_num": 128283, 
    "out-dataset_request_shuffle_num": 40, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1005675
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 2936, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 1401, 
    "in-dataset_question_shuffle_num": 7795, 
    "in-dataset_request_shuffle_num": 13, 
    "inf_sentences_id": 693384, 
    "line": "Where on the Internet can I find information on laundry detergent ?", 
    "linenum": 1936, 
    "matchl": "Where on the Internet can I find information on laundry detergent ?", 
    "out-dataset_implicative_shuffle_num": 5605, 
    "out-dataset_question_shuffle_num": 23432, 
    "out-dataset_request_shuffle_num": 41, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 920964
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 229705, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 247283, 
    "in-dataset_question_shuffle_num": 3322, 
    "in-dataset_request_shuffle_num": 13, 
    "inf_sentences_id": 229723, 
    "line": "Where can I find them ?", 
    "linenum": 229705, 
    "matchl": "Where can I find them ?", 
    "out-dataset_implicative_shuffle_num": 500266, 
    "out-dataset_question_shuffle_num": 10014, 
    "out-dataset_request_shuffle_num": 42, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 456983
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 163865, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1998-0.txt", 
    "in-dataset_request_shuffle_num": 13, 
    "inf_sentences_id": 869766, 
    "line": "Not for you do I wait here in these mountains ; not with you may I descend for the last time .", 
    "linenum": 5803, 
    "matchl": "Not for you do I wait here in these mountains ; not with you may I descend for the last time .", 
    "out-dataset_request_shuffle_num": 43, 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request"
    ], 
    "ulf_sentences_id": 1097346
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 528831, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 60853, 
    "in-dataset_request_shuffle_num": 14, 
    "inf_sentences_id": 528852, 
    "line": "How will you solve the problem ?", 
    "linenum": 528831, 
    "matchl": "How will you solve the problem ?", 
    "out-dataset_question_shuffle_num": 134637, 
    "out-dataset_request_shuffle_num": 45, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 756109
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 254620, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2600-0.txt", 
    "implicative_pattern": "like", 
    "in-dataset_implicative_shuffle_num": 38461, 
    "in-dataset_question_shuffle_num": 8478, 
    "in-dataset_request_shuffle_num": 14, 
    "inf_sentences_id": 960522, 
    "line": "Princess Mary suddenly said in a trembling voice , \" would you like to see little Nicholas ?", 
    "linenum": 25499, 
    "matchl": "Princess Mary suddenly said in a trembling voice , \" would you like to see little Nicholas ?", 
    "out-dataset_implicative_shuffle_num": 82623, 
    "out-dataset_question_shuffle_num": 25483, 
    "out-dataset_request_shuffle_num": 46, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1188102
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 10455, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 540, 
    "in-dataset_question_shuffle_num": 9376, 
    "in-dataset_request_shuffle_num": 15, 
    "inf_sentences_id": 700903, 
    "line": "Where can I find a person 's address from a telephone number ?", 
    "linenum": 455, 
    "matchl": "Where can I find a person 's address from a telephone number ?", 
    "out-dataset_implicative_shuffle_num": 2161, 
    "out-dataset_question_shuffle_num": 28175, 
    "out-dataset_request_shuffle_num": 47, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 928483
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 37836, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "use", 
    "in-dataset_implicative_shuffle_num": 129215, 
    "in-dataset_question_shuffle_num": 82037, 
    "in-dataset_request_shuffle_num": 15, 
    "inf_sentences_id": 37852, 
    "line": "May I use this ?", 
    "linenum": 37836, 
    "matchl": "May I use this ?", 
    "out-dataset_implicative_shuffle_num": 264130, 
    "out-dataset_question_shuffle_num": 155821, 
    "out-dataset_request_shuffle_num": 48, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 265114
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 496478, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/98-0.txt", 
    "implicative_pattern": "miss", 
    "in-dataset_implicative_shuffle_num": 104823, 
    "in-dataset_question_shuffle_num": 51218, 
    "in-dataset_request_shuffle_num": 15, 
    "inf_sentences_id": 1202382, 
    "line": "\" Where could you wait for me ? \" asked Miss Pross .", 
    "linenum": 7243, 
    "matchl": "\" Where could you wait for me ? \" asked Miss Pross .", 
    "out-dataset_implicative_shuffle_num": 215347, 
    "out-dataset_question_shuffle_num": 117689, 
    "out-dataset_request_shuffle_num": 49, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1429962
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 6376, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 2195, 
    "in-dataset_question_shuffle_num": 1179, 
    "in-dataset_request_shuffle_num": 16, 
    "inf_sentences_id": 696824, 
    "line": "Where can I find a case on Individuals with Disabilities Education Act of 1991 ?", 
    "linenum": 376, 
    "matchl": "Where can I find a case on Individuals with Disabilities Education Act of 1991 ?", 
    "out-dataset_implicative_shuffle_num": 8574, 
    "out-dataset_question_shuffle_num": 3584, 
    "out-dataset_request_shuffle_num": 50, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 924404
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 252013, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 55496, 
    "in-dataset_request_shuffle_num": 16, 
    "inf_sentences_id": 252031, 
    "line": "May I assist you ?", 
    "linenum": 252013, 
    "matchl": "May I assist you ?", 
    "out-dataset_question_shuffle_num": 126244, 
    "out-dataset_request_shuffle_num": 51, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 479291
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 229917, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2600-0.txt", 
    "implicative_pattern": "come", 
    "in-dataset_implicative_shuffle_num": 85888, 
    "in-dataset_question_shuffle_num": 45281, 
    "in-dataset_request_shuffle_num": 16, 
    "inf_sentences_id": 935819, 
    "line": "But wo n't you come to this other table ? \" repeated Anna Pavlovna .", 
    "linenum": 796, 
    "matchl": "But wo n't you come to this other table ? \" repeated Anna Pavlovna .", 
    "out-dataset_implicative_shuffle_num": 177477, 
    "out-dataset_question_shuffle_num": 105815, 
    "out-dataset_request_shuffle_num": 52, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) (n't|not) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1163399
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 14484, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "determine", 
    "in-dataset_implicative_shuffle_num": 3322, 
    "in-dataset_question_shuffle_num": 7366, 
    "in-dataset_request_shuffle_num": 17, 
    "inf_sentences_id": 704932, 
    "line": "How can I determine the radius of an ellipse ?", 
    "linenum": 4484, 
    "matchl": "How can I determine the radius of an ellipse ?", 
    "out-dataset_implicative_shuffle_num": 11955, 
    "out-dataset_question_shuffle_num": 22145, 
    "out-dataset_request_shuffle_num": 53, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 932512
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 231166, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "see", 
    "in-dataset_implicative_shuffle_num": 79498, 
    "in-dataset_question_shuffle_num": 92150, 
    "in-dataset_request_shuffle_num": 17, 
    "inf_sentences_id": 231184, 
    "line": "Can I see you a moment ?", 
    "linenum": 231166, 
    "matchl": "Can I see you a moment ?", 
    "out-dataset_implicative_shuffle_num": 164696, 
    "out-dataset_question_shuffle_num": 165934, 
    "out-dataset_request_shuffle_num": 54, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 458444
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 493239, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/98-0.txt", 
    "in-dataset_counterfactual_shuffle_num": 15988, 
    "in-dataset_question_shuffle_num": 11071, 
    "in-dataset_request_shuffle_num": 17, 
    "inf_sentences_id": 1199143, 
    "line": "\" Will you promise not to press one question on me , if I beg you not to ask it ? \"", 
    "linenum": 4004, 
    "matchl": "\" Will you promise not to press one question on me , if I beg you not to ask it ? \"", 
    "out-dataset_counterfactual_shuffle_num": 31844, 
    "out-dataset_question_shuffle_num": 33262, 
    "out-dataset_request_shuffle_num": 55, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "counterfactual", 
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 1426723
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 5634, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "get", 
    "in-dataset_implicative_shuffle_num": 2248, 
    "in-dataset_question_shuffle_num": 1649, 
    "in-dataset_request_shuffle_num": 18, 
    "inf_sentences_id": 696082, 
    "line": "Where can I get a photograph of professor Randolph Quirk ?", 
    "linenum": 2634, 
    "matchl": "Where can I get a photograph of professor Randolph Quirk ?", 
    "out-dataset_implicative_shuffle_num": 8733, 
    "out-dataset_question_shuffle_num": 4994, 
    "out-dataset_request_shuffle_num": 56, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 923662
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 342962, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 38835, 
    "in-dataset_request_shuffle_num": 18, 
    "inf_sentences_id": 342981, 
    "line": "Can you teach me how to ride a horse ?", 
    "linenum": 342962, 
    "matchl": "Can you teach me how to ride a horse ?", 
    "out-dataset_question_shuffle_num": 92922, 
    "out-dataset_request_shuffle_num": 57, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 570240
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 251063, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2600-0.txt", 
    "implicative_pattern": "like", 
    "in-dataset_implicative_shuffle_num": 222713, 
    "in-dataset_question_shuffle_num": 51984, 
    "in-dataset_request_shuffle_num": 18, 
    "inf_sentences_id": 956965, 
    "line": "\" Would you like a little mash ? \" the first soldier asked , and handed Pierre a wooden spoon after licking it clean .", 
    "linenum": 21942, 
    "matchl": "\" Would you like a little mash ? \" the first soldier asked , and handed Pierre a wooden spoon after licking it clean .", 
    "out-dataset_implicative_shuffle_num": 451127, 
    "out-dataset_question_shuffle_num": 119221, 
    "out-dataset_request_shuffle_num": 58, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1184545
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 12583, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "read", 
    "in-dataset_implicative_shuffle_num": 2715, 
    "in-dataset_question_shuffle_num": 3850, 
    "in-dataset_request_shuffle_num": 19, 
    "inf_sentences_id": 703031, 
    "line": "What phenomenon would you expect to read about in the monthly publication The Bigfoot News ?", 
    "linenum": 2583, 
    "matchl": "What phenomenon would you expect to read about in the monthly publication The Bigfoot News ?", 
    "out-dataset_implicative_shuffle_num": 10134, 
    "out-dataset_question_shuffle_num": 11597, 
    "out-dataset_request_shuffle_num": 59, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 930611
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 511285, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "tell", 
    "in-dataset_implicative_shuffle_num": 100559, 
    "in-dataset_question_shuffle_num": 46192, 
    "in-dataset_request_shuffle_num": 19, 
    "inf_sentences_id": 511306, 
    "line": "Will you tell her ?", 
    "linenum": 511285, 
    "matchl": "Will you tell her ?", 
    "out-dataset_implicative_shuffle_num": 206818, 
    "out-dataset_question_shuffle_num": 107636, 
    "out-dataset_request_shuffle_num": 60, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 738563
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>if<mid>(was|were|had|<past>|<ppart>) .+", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 291326, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/28054-0.txt", 
    "implicative_pattern": "tell", 
    "in-dataset_counterfactual_shuffle_num": 10079, 
    "in-dataset_implicative_shuffle_num": 3649, 
    "in-dataset_question_shuffle_num": 12926, 
    "in-dataset_request_shuffle_num": 19, 
    "inf_sentences_id": 997228, 
    "line": "How could you tell that you would fall down the cellar stairs in a fit , if you did n't sham a fit on purpose ? \"", 
    "linenum": 18901, 
    "matchl": "How could you tell that you would fall down the cellar stairs in a fit , if you did n't sham a fit on purpose ? \"", 
    "out-dataset_counterfactual_shuffle_num": 20365, 
    "out-dataset_implicative_shuffle_num": 12938, 
    "out-dataset_question_shuffle_num": 38827, 
    "out-dataset_request_shuffle_num": 61, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "counterfactual", 
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1224808
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 8550, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "see", 
    "in-dataset_implicative_shuffle_num": 2205, 
    "in-dataset_question_shuffle_num": 6369, 
    "in-dataset_request_shuffle_num": 20, 
    "inf_sentences_id": 698998, 
    "line": "How far can you see ?", 
    "linenum": 2550, 
    "matchl": "How far can you see ?", 
    "out-dataset_implicative_shuffle_num": 8604, 
    "out-dataset_question_shuffle_num": 19154, 
    "out-dataset_request_shuffle_num": 62, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 926578
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 435976, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 68201, 
    "in-dataset_request_shuffle_num": 20, 
    "inf_sentences_id": 435996, 
    "line": "Can you shut the door on your way out ?", 
    "linenum": 435976, 
    "matchl": "Can you shut the door on your way out ?", 
    "out-dataset_question_shuffle_num": 141985, 
    "out-dataset_request_shuffle_num": 63, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 663254
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 221057, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2554-0.txt", 
    "implicative_pattern": "tell", 
    "in-dataset_implicative_shuffle_num": 218568, 
    "in-dataset_question_shuffle_num": 45754, 
    "in-dataset_request_shuffle_num": 20, 
    "inf_sentences_id": 926959, 
    "line": "But what can I tell you ?", 
    "linenum": 10623, 
    "matchl": "But what can I tell you ?", 
    "out-dataset_implicative_shuffle_num": 442837, 
    "out-dataset_question_shuffle_num": 106761, 
    "out-dataset_request_shuffle_num": 64, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1154539
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 6455, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 464, 
    "in-dataset_question_shuffle_num": 11353, 
    "in-dataset_request_shuffle_num": 21, 
    "inf_sentences_id": 696903, 
    "line": "Where can I find a person 's address from a telephone number ?", 
    "linenum": 455, 
    "matchl": "Where can I find a person 's address from a telephone number ?", 
    "out-dataset_implicative_shuffle_num": 1857, 
    "out-dataset_question_shuffle_num": 34106, 
    "out-dataset_request_shuffle_num": 65, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 924483
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 272279, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 15964, 
    "in-dataset_request_shuffle_num": 21, 
    "inf_sentences_id": 272297, 
    "line": "Why wo n't you play with me ?", 
    "linenum": 272279, 
    "matchl": "Why wo n't you play with me ?", 
    "out-dataset_question_shuffle_num": 47180, 
    "out-dataset_request_shuffle_num": 66, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) (n't|not) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 499557
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 416755, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/46.txt.utf-8", 
    "in-dataset_question_shuffle_num": 43486, 
    "in-dataset_request_shuffle_num": 21, 
    "inf_sentences_id": 1122659, 
    "line": "Will you do me that favour ? \"", 
    "linenum": 1706, 
    "matchl": "Will you do me that favour ? \"", 
    "out-dataset_question_shuffle_num": 102225, 
    "out-dataset_request_shuffle_num": 67, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 1350239
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 8343, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "add", 
    "in-dataset_implicative_shuffle_num": 1544, 
    "in-dataset_question_shuffle_num": 11459, 
    "in-dataset_request_shuffle_num": 22, 
    "inf_sentences_id": 698791, 
    "line": "What would you add to the clay mixture to produce bone china ?", 
    "linenum": 2343, 
    "matchl": "What would you add to the clay mixture to produce bone china ?", 
    "out-dataset_implicative_shuffle_num": 6177, 
    "out-dataset_question_shuffle_num": 34424, 
    "out-dataset_request_shuffle_num": 68, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 926371
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 22853, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 55758, 
    "in-dataset_request_shuffle_num": 22, 
    "inf_sentences_id": 22869, 
    "line": "Will you open the door ?", 
    "linenum": 22853, 
    "matchl": "Will you open the door ?", 
    "out-dataset_question_shuffle_num": 126768, 
    "out-dataset_request_shuffle_num": 69, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 250131
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 13015, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1184-0.txt", 
    "implicative_pattern": "see", 
    "in-dataset_counterfactual_shuffle_num": 7187, 
    "in-dataset_implicative_shuffle_num": 258333, 
    "in-dataset_question_shuffle_num": 33214, 
    "in-dataset_request_shuffle_num": 22, 
    "inf_sentences_id": 718915, 
    "line": "\" Valentine , will you not go and see if your grandpapa will have his dinner ? \"", 
    "linenum": 11492, 
    "matchl": "\" Valentine , will you not go and see if your grandpapa will have his dinner ? \"", 
    "out-dataset_counterfactual_shuffle_num": 14581, 
    "out-dataset_implicative_shuffle_num": 522367, 
    "out-dataset_question_shuffle_num": 81681, 
    "out-dataset_request_shuffle_num": 70, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "counterfactual", 
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 946495
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 237, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_1000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 990, 
    "in-dataset_question_shuffle_num": 14548, 
    "in-dataset_request_shuffle_num": 23, 
    "inf_sentences_id": 690685, 
    "line": "Where can I find a review of Nightmare on Elm Street in a film journal ?", 
    "linenum": 237, 
    "matchl": "Where can I find a review of Nightmare on Elm Street in a film journal ?", 
    "out-dataset_implicative_shuffle_num": 3961, 
    "out-dataset_question_shuffle_num": 43691, 
    "out-dataset_request_shuffle_num": 71, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 918265
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 328791, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "like", 
    "in-dataset_implicative_shuffle_num": 96787, 
    "in-dataset_question_shuffle_num": 23406, 
    "in-dataset_request_shuffle_num": 23, 
    "inf_sentences_id": 328810, 
    "line": "Would you like to grab a bite to eat somewhere ?", 
    "linenum": 328791, 
    "matchl": "Would you like to grab a bite to eat somewhere ?", 
    "out-dataset_implicative_shuffle_num": 199274, 
    "out-dataset_question_shuffle_num": 62064, 
    "out-dataset_request_shuffle_num": 72, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 556069
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 319051, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/30360.txt.utf-8", 
    "implicative_pattern": "get", 
    "in-dataset_counterfactual_shuffle_num": 26157, 
    "in-dataset_implicative_shuffle_num": 141166, 
    "in-dataset_question_shuffle_num": 35313, 
    "in-dataset_request_shuffle_num": 23, 
    "inf_sentences_id": 1024954, 
    "line": "Nor could I induce her. I incited her by talk , she kept on ejaculating \" oh ! \" to my baudy remarks , and blushing like a rose ; but I could get no more. \" If Missus comes home , and sees you through the area , what will she say ? --", 
    "linenum": 6780, 
    "matchl": "Nor could I induce her. I incited her by talk , she kept on ejaculating \" oh ! \" to my baudy remarks , and blushing like a rose ; but I could get no more. \" If Missus comes home , and sees you through the area , what will she say ? --", 
    "out-dataset_counterfactual_shuffle_num": 42013, 
    "out-dataset_implicative_shuffle_num": 288033, 
    "out-dataset_question_shuffle_num": 85879, 
    "out-dataset_request_shuffle_num": 73, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "counterfactual", 
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1252534
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 6342, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "in-dataset_question_shuffle_num": 13090, 
    "in-dataset_request_shuffle_num": 24, 
    "inf_sentences_id": 696790, 
    "line": "Where can I buy movies on videotape online ?", 
    "linenum": 342, 
    "matchl": "Where can I buy movies on videotape online ?", 
    "out-dataset_question_shuffle_num": 39317, 
    "out-dataset_request_shuffle_num": 74, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 924370
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 52638, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "show", 
    "in-dataset_implicative_shuffle_num": 84853, 
    "in-dataset_question_shuffle_num": 13250, 
    "in-dataset_request_shuffle_num": 24, 
    "inf_sentences_id": 52654, 
    "line": "Will you show me your album ?", 
    "linenum": 52638, 
    "matchl": "Will you show me your album ?", 
    "out-dataset_implicative_shuffle_num": 175406, 
    "out-dataset_question_shuffle_num": 39798, 
    "out-dataset_request_shuffle_num": 75, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 279916
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 288570, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/28054-0.txt", 
    "implicative_pattern": "tell", 
    "in-dataset_implicative_shuffle_num": 24556, 
    "in-dataset_question_shuffle_num": 36417, 
    "in-dataset_request_shuffle_num": 24, 
    "inf_sentences_id": 994472, 
    "line": "\" How could I tell I had hit on a clever one ?", 
    "linenum": 16145, 
    "matchl": "\" How could I tell I had hit on a clever one ?", 
    "out-dataset_implicative_shuffle_num": 54813, 
    "out-dataset_question_shuffle_num": 88087, 
    "out-dataset_request_shuffle_num": 76, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1222052
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 4955, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "in-dataset_question_shuffle_num": 3857, 
    "in-dataset_request_shuffle_num": 25, 
    "inf_sentences_id": 695403, 
    "line": "How can I easily remove red wine stains from t-shirts ?", 
    "linenum": 1955, 
    "matchl": "How can I easily remove red wine stains from t-shirts ?", 
    "out-dataset_question_shuffle_num": 11618, 
    "out-dataset_request_shuffle_num": 77, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 922983
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 435456, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "get", 
    "in-dataset_implicative_shuffle_num": 259916, 
    "in-dataset_question_shuffle_num": 23167, 
    "in-dataset_request_shuffle_num": 25, 
    "inf_sentences_id": 435476, 
    "line": "Can I get up now ?", 
    "linenum": 435456, 
    "matchl": "Can I get up now ?", 
    "out-dataset_implicative_shuffle_num": 525532, 
    "out-dataset_question_shuffle_num": 61586, 
    "out-dataset_request_shuffle_num": 78, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 662734
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 153769, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/174.txt.utf-8", 
    "implicative_pattern": "see", 
    "in-dataset_implicative_shuffle_num": 219288, 
    "in-dataset_question_shuffle_num": 2722, 
    "in-dataset_request_shuffle_num": 25, 
    "inf_sentences_id": 859670, 
    "line": "\" Ca n't you see your ideal in it ? \" said Dorian bitterly .", 
    "linenum": 4282, 
    "matchl": "\" Ca n't you see your ideal in it ? \" said Dorian bitterly .", 
    "out-dataset_implicative_shuffle_num": 444277, 
    "out-dataset_question_shuffle_num": 8215, 
    "out-dataset_request_shuffle_num": 79, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) (n't|not) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1087250
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 11168, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_question_shuffle_num": 10516, 
    "in-dataset_request_shuffle_num": 26, 
    "inf_sentences_id": 701616, 
    "line": "What phone number can I call to have a tree planted ?", 
    "linenum": 1168, 
    "matchl": "What phone number can I call to have a tree planted ?", 
    "out-dataset_question_shuffle_num": 31595, 
    "out-dataset_request_shuffle_num": 80, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 929196
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 596842, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 5123, 
    "in-dataset_request_shuffle_num": 26, 
    "inf_sentences_id": 596863, 
    "line": "Can you jump rope ?", 
    "linenum": 596842, 
    "matchl": "Can you jump rope ?", 
    "out-dataset_question_shuffle_num": 15417, 
    "out-dataset_request_shuffle_num": 81, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 824120
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 202142, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/236-0.txt", 
    "in-dataset_question_shuffle_num": 49840, 
    "in-dataset_request_shuffle_num": 26, 
    "inf_sentences_id": 908044, 
    "line": "\" Where will you be ? \"", 
    "linenum": 2992, 
    "matchl": "\" Where will you be ? \"", 
    "out-dataset_question_shuffle_num": 114933, 
    "out-dataset_request_shuffle_num": 82, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 1135624
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 1116, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 1563, 
    "in-dataset_question_shuffle_num": 4160, 
    "in-dataset_request_shuffle_num": 27, 
    "inf_sentences_id": 691564, 
    "line": "Where on the Internet can I find a song lyrics database similar to the International Lyrics Server ?", 
    "linenum": 116, 
    "matchl": "Where on the Internet can I find a song lyrics database similar to the International Lyrics Server ?", 
    "out-dataset_implicative_shuffle_num": 6253, 
    "out-dataset_question_shuffle_num": 12527, 
    "out-dataset_request_shuffle_num": 83, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 919144
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 600856, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "say", 
    "in-dataset_implicative_shuffle_num": 136679, 
    "in-dataset_question_shuffle_num": 32907, 
    "in-dataset_request_shuffle_num": 27, 
    "inf_sentences_id": 600878, 
    "line": "Why would you say such an awful thing ?", 
    "linenum": 600856, 
    "matchl": "Why would you say such an awful thing ?", 
    "out-dataset_implicative_shuffle_num": 279058, 
    "out-dataset_question_shuffle_num": 81066, 
    "out-dataset_request_shuffle_num": 84, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 828134
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 220652, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2554-0.txt", 
    "implicative_pattern": "note", 
    "in-dataset_implicative_shuffle_num": 152985, 
    "in-dataset_question_shuffle_num": 45695, 
    "in-dataset_request_shuffle_num": 27, 
    "inf_sentences_id": 926554, 
    "line": "\" What lies ! \" he cried impudently , \" why , how could you , standing by the window , see the note ?", 
    "linenum": 10218, 
    "matchl": "\" What lies ! \" he cried impudently , \" why , how could you , standing by the window , see the note ?", 
    "out-dataset_implicative_shuffle_num": 311671, 
    "out-dataset_question_shuffle_num": 106643, 
    "out-dataset_request_shuffle_num": 85, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1154134
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 6868, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 2873, 
    "in-dataset_question_shuffle_num": 9907, 
    "in-dataset_request_shuffle_num": 28, 
    "inf_sentences_id": 697316, 
    "line": "Where can I find the names of all the 15 Pokemon ?", 
    "linenum": 868, 
    "matchl": "Where can I find the names of all the 15 Pokemon ?", 
    "out-dataset_implicative_shuffle_num": 10608, 
    "out-dataset_question_shuffle_num": 29768, 
    "out-dataset_request_shuffle_num": 86, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 924896
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 93487, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 16860, 
    "in-dataset_request_shuffle_num": 28, 
    "inf_sentences_id": 93503, 
    "line": "Could you put your seat back up a little ?", 
    "linenum": 93487, 
    "matchl": "Could you put your seat back up a little ?", 
    "out-dataset_question_shuffle_num": 48972, 
    "out-dataset_request_shuffle_num": 87, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 320765
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 485391, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/863-0.txt", 
    "implicative_pattern": "help", 
    "in-dataset_implicative_shuffle_num": 110280, 
    "in-dataset_question_shuffle_num": 41325, 
    "in-dataset_request_shuffle_num": 28, 
    "inf_sentences_id": 1191295, 
    "line": "\" Can you give us no help in solving it , monsieur ? \" interposed Poirot , speaking for the first time since we had entered the room .", 
    "linenum": 1643, 
    "matchl": "\" Can you give us no help in solving it , monsieur ? \" interposed Poirot , speaking for the first time since we had entered the room .", 
    "out-dataset_implicative_shuffle_num": 226261, 
    "out-dataset_question_shuffle_num": 97903, 
    "out-dataset_request_shuffle_num": 88, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1418875
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 3953, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 1923, 
    "in-dataset_question_shuffle_num": 4663, 
    "in-dataset_request_shuffle_num": 29, 
    "inf_sentences_id": 694401, 
    "line": "Where can I find information on George Bush ?", 
    "linenum": 953, 
    "matchl": "Where can I find information on George Bush ?", 
    "out-dataset_implicative_shuffle_num": 7693, 
    "out-dataset_question_shuffle_num": 14036, 
    "out-dataset_request_shuffle_num": 89, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 921981
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 378467, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 37056, 
    "in-dataset_request_shuffle_num": 29, 
    "inf_sentences_id": 378486, 
    "line": "What would you suggest that I do ?", 
    "linenum": 378467, 
    "matchl": "What would you suggest that I do ?", 
    "out-dataset_question_shuffle_num": 89364, 
    "out-dataset_request_shuffle_num": 90, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 605745
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 15071, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1184-0.txt", 
    "in-dataset_request_shuffle_num": 29, 
    "inf_sentences_id": 720971, 
    "line": "\" Yes , \" replied Madame de Villefort ; \" and , would you believe it , count ---- \"", 
    "linenum": 13548, 
    "matchl": "\" Yes , \" replied Madame de Villefort ; \" and , would you believe it , count ---- \"", 
    "out-dataset_request_shuffle_num": 91, 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request"
    ], 
    "ulf_sentences_id": 948551
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 5325, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "learn", 
    "in-dataset_implicative_shuffle_num": 963, 
    "in-dataset_question_shuffle_num": 7171, 
    "in-dataset_request_shuffle_num": 30, 
    "inf_sentences_id": 695773, 
    "line": "Where can I learn about Samuel Gompers ?", 
    "linenum": 2325, 
    "matchl": "Where can I learn about Samuel Gompers ?", 
    "out-dataset_implicative_shuffle_num": 3853, 
    "out-dataset_question_shuffle_num": 21560, 
    "out-dataset_request_shuffle_num": 92, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 923353
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 413495, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 50148, 
    "in-dataset_request_shuffle_num": 30, 
    "inf_sentences_id": 413515, 
    "line": "Could you give me just a moment ?", 
    "linenum": 413495, 
    "matchl": "Could you give me just a moment ?", 
    "out-dataset_question_shuffle_num": 115548, 
    "out-dataset_request_shuffle_num": 93, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 640773
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 304954, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/30254-0.txt", 
    "implicative_pattern": "like", 
    "in-dataset_implicative_shuffle_num": 28485, 
    "in-dataset_question_shuffle_num": 13802, 
    "in-dataset_request_shuffle_num": 30, 
    "inf_sentences_id": 1010857, 
    "line": "Will you like that ? \"", 
    "linenum": 402, 
    "matchl": "Will you like that ? \"", 
    "out-dataset_implicative_shuffle_num": 62671, 
    "out-dataset_question_shuffle_num": 41455, 
    "out-dataset_request_shuffle_num": 94, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1238437
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 2773, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 2984, 
    "in-dataset_question_shuffle_num": 6146, 
    "in-dataset_request_shuffle_num": 31, 
    "inf_sentences_id": 693221, 
    "line": "How can I find a list of , fax and or email , addresses for human resource departments in Massachusetts ?", 
    "linenum": 1773, 
    "matchl": "How can I find a list of , fax and or email , addresses for human resource departments in Massachusetts ?", 
    "out-dataset_implicative_shuffle_num": 10941, 
    "out-dataset_question_shuffle_num": 18485, 
    "out-dataset_request_shuffle_num": 95, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 920801
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 272479, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "please", 
    "in-dataset_implicative_shuffle_num": 130832, 
    "in-dataset_question_shuffle_num": 58072, 
    "in-dataset_request_shuffle_num": 31, 
    "inf_sentences_id": 272497, 
    "line": "Could you lend me your pink pen , please ?", 
    "linenum": 272479, 
    "matchl": "Could you lend me your pink pen , please ?", 
    "out-dataset_implicative_shuffle_num": 267364, 
    "out-dataset_question_shuffle_num": 131396, 
    "out-dataset_request_shuffle_num": 96, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 499757
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 115514, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1497.txt.utf-8", 
    "implicative_pattern": "say", 
    "in-dataset_implicative_shuffle_num": 255696, 
    "in-dataset_question_shuffle_num": 45177, 
    "in-dataset_request_shuffle_num": 31, 
    "inf_sentences_id": 821415, 
    "line": "Would you say that knowledge is a faculty , or in what class would you place it ?", 
    "linenum": 6230, 
    "matchl": "Would you say that knowledge is a faculty , or in what class would you place it ?", 
    "out-dataset_implicative_shuffle_num": 517093, 
    "out-dataset_question_shuffle_num": 105607, 
    "out-dataset_request_shuffle_num": 97, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1048995
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 9919, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 545, 
    "in-dataset_question_shuffle_num": 12366, 
    "in-dataset_request_shuffle_num": 32, 
    "inf_sentences_id": 700367, 
    "line": "Where can I find the status of my tax return ?", 
    "linenum": 3919, 
    "matchl": "Where can I find the status of my tax return ?", 
    "out-dataset_implicative_shuffle_num": 2181, 
    "out-dataset_question_shuffle_num": 37145, 
    "out-dataset_request_shuffle_num": 98, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 927947
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 442288, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 81621, 
    "in-dataset_request_shuffle_num": 32, 
    "inf_sentences_id": 442308, 
    "line": "Can I chat with you outside for a second ?", 
    "linenum": 442288, 
    "matchl": "Can I chat with you outside for a second ?", 
    "out-dataset_question_shuffle_num": 155405, 
    "out-dataset_request_shuffle_num": 99, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 669566
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 386, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/11-0.txt", 
    "implicative_pattern": "learn", 
    "in-dataset_implicative_shuffle_num": 109964, 
    "in-dataset_question_shuffle_num": 55134, 
    "in-dataset_request_shuffle_num": 32, 
    "inf_sentences_id": 706286, 
    "line": "' How can you learn lessons in here ?", 
    "linenum": 317, 
    "matchl": "' How can you learn lessons in here ?", 
    "out-dataset_implicative_shuffle_num": 225629, 
    "out-dataset_question_shuffle_num": 125521, 
    "out-dataset_request_shuffle_num": 100, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 933866
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 1492, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 1629, 
    "in-dataset_question_shuffle_num": 14301, 
    "in-dataset_request_shuffle_num": 33, 
    "inf_sentences_id": 691940, 
    "line": "Where can I find out the top 1 singles ?", 
    "linenum": 492, 
    "matchl": "Where can I find out the top 1 singles ?", 
    "out-dataset_implicative_shuffle_num": 6517, 
    "out-dataset_question_shuffle_num": 42950, 
    "out-dataset_request_shuffle_num": 101, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 919520
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 358574, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "stay", 
    "in-dataset_implicative_shuffle_num": 246811, 
    "in-dataset_question_shuffle_num": 34594, 
    "in-dataset_request_shuffle_num": 33, 
    "inf_sentences_id": 358593, 
    "line": "How many months can you stay here ?", 
    "linenum": 358574, 
    "matchl": "How many months can you stay here ?", 
    "out-dataset_implicative_shuffle_num": 499322, 
    "out-dataset_question_shuffle_num": 84440, 
    "out-dataset_request_shuffle_num": 102, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 585852
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": ".+ (<wish>) .+", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 41926, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1260.txt.utf-8", 
    "implicative_pattern": "love", 
    "in-dataset_counterfactual_shuffle_num": 25604, 
    "in-dataset_implicative_shuffle_num": 192002, 
    "in-dataset_request_shuffle_num": 33, 
    "inf_sentences_id": 747826, 
    "line": "But if you wish me to love you , could you but see how much I _do_ love you , you would be proud and content .", 
    "linenum": 9634, 
    "matchl": "But if you wish me to love you , could you but see how much I _do_ love you , you would be proud and content .", 
    "out-dataset_counterfactual_shuffle_num": 41460, 
    "out-dataset_implicative_shuffle_num": 389705, 
    "out-dataset_request_shuffle_num": 103, 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "counterfactual", 
      "request", 
      "implicative"
    ], 
    "ulf_sentences_id": 975406
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 11179, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 1565, 
    "in-dataset_question_shuffle_num": 4097, 
    "in-dataset_request_shuffle_num": 34, 
    "inf_sentences_id": 701627, 
    "line": "Where can I find a list of all the companies in America that offer a direct stock purchase plan ?", 
    "linenum": 1179, 
    "matchl": "Where can I find a list of all the companies in America that offer a direct stock purchase plan ?", 
    "out-dataset_implicative_shuffle_num": 6261, 
    "out-dataset_question_shuffle_num": 12338, 
    "out-dataset_request_shuffle_num": 104, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 929207
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 565562, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "prove", 
    "in-dataset_implicative_shuffle_num": 277712, 
    "in-dataset_question_shuffle_num": 78243, 
    "in-dataset_request_shuffle_num": 34, 
    "inf_sentences_id": 565583, 
    "line": "Can you prove which was the original language of your holy writings ?", 
    "linenum": 565562, 
    "matchl": "Can you prove which was the original language of your holy writings ?", 
    "out-dataset_implicative_shuffle_num": 544058, 
    "out-dataset_question_shuffle_num": 152027, 
    "out-dataset_request_shuffle_num": 105, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 792840
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 226743, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2591-0.txt", 
    "implicative_pattern": "came", 
    "in-dataset_implicative_shuffle_num": 172632, 
    "in-dataset_question_shuffle_num": 21957, 
    "in-dataset_request_shuffle_num": 34, 
    "inf_sentences_id": 932645, 
    "line": "It was not long before the witch came striding up towards them , and said to the musician : ' Dear musician , may I pluck that beautiful flower for myself ? '", 
    "linenum": 1921, 
    "matchl": "It was not long before the witch came striding up towards them , and said to the musician : ' Dear musician , may I pluck that beautiful flower for myself ? '", 
    "out-dataset_implicative_shuffle_num": 350965, 
    "out-dataset_question_shuffle_num": 59167, 
    "out-dataset_request_shuffle_num": 106, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1160225
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 14176, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "get", 
    "in-dataset_implicative_shuffle_num": 580, 
    "in-dataset_question_shuffle_num": 8667, 
    "in-dataset_request_shuffle_num": 35, 
    "inf_sentences_id": 704624, 
    "line": "How can I get someone 's email address ?", 
    "linenum": 4176, 
    "matchl": "How can I get someone 's email address ?", 
    "out-dataset_implicative_shuffle_num": 2321, 
    "out-dataset_question_shuffle_num": 26048, 
    "out-dataset_request_shuffle_num": 107, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 932204
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 430953, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "forget", 
    "in-dataset_implicative_shuffle_num": 55105, 
    "in-dataset_question_shuffle_num": 19211, 
    "in-dataset_request_shuffle_num": 35, 
    "inf_sentences_id": 430973, 
    "line": "How could I forget something like that ?", 
    "linenum": 430953, 
    "matchl": "How could I forget something like that ?", 
    "out-dataset_implicative_shuffle_num": 115910, 
    "out-dataset_question_shuffle_num": 53674, 
    "out-dataset_request_shuffle_num": 108, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 658231
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 18679, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1184-0.txt", 
    "implicative_pattern": "tell", 
    "in-dataset_implicative_shuffle_num": 189289, 
    "in-dataset_question_shuffle_num": 49415, 
    "in-dataset_request_shuffle_num": 35, 
    "inf_sentences_id": 724579, 
    "line": "\" How can I tell you ? \"", 
    "linenum": 17156, 
    "matchl": "\" How can I tell you ? \"", 
    "out-dataset_implicative_shuffle_num": 384279, 
    "out-dataset_question_shuffle_num": 114083, 
    "out-dataset_request_shuffle_num": 109, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 952159
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 3116, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 2932, 
    "in-dataset_question_shuffle_num": 10610, 
    "in-dataset_request_shuffle_num": 36, 
    "inf_sentences_id": 693564, 
    "line": "Where on the Internet can I find a song lyrics database similar to the International Lyrics Server ?", 
    "linenum": 116, 
    "matchl": "Where on the Internet can I find a song lyrics database similar to the International Lyrics Server ?", 
    "out-dataset_implicative_shuffle_num": 10785, 
    "out-dataset_question_shuffle_num": 31877, 
    "out-dataset_request_shuffle_num": 110, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 921144
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 12487, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 66172, 
    "in-dataset_request_shuffle_num": 36, 
    "inf_sentences_id": 12503, 
    "line": "May I ask you to do me a favor ?", 
    "linenum": 12487, 
    "matchl": "May I ask you to do me a favor ?", 
    "out-dataset_question_shuffle_num": 139956, 
    "out-dataset_request_shuffle_num": 111, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 239765
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 137221, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/160-0.txt", 
    "in-dataset_request_shuffle_num": 36, 
    "inf_sentences_id": 843122, 
    "line": "\" Will you do me the favor , Octavie , \" requested the judge in the courteous tone which he never abandoned , \" to remove that veil which you wear .", 
    "linenum": 4339, 
    "matchl": "\" Will you do me the favor , Octavie , \" requested the judge in the courteous tone which he never abandoned , \" to remove that veil which you wear .", 
    "out-dataset_request_shuffle_num": 112, 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request"
    ], 
    "ulf_sentences_id": 1070702
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 12109, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "tell", 
    "in-dataset_counterfactual_shuffle_num": 0, 
    "in-dataset_implicative_shuffle_num": 2339, 
    "in-dataset_question_shuffle_num": 1405, 
    "in-dataset_request_shuffle_num": 37, 
    "inf_sentences_id": 702557, 
    "line": "How can you tell if someone is lying ?", 
    "linenum": 2109, 
    "matchl": "How can you tell if someone is lying ?", 
    "out-dataset_counterfactual_shuffle_num": 1, 
    "out-dataset_implicative_shuffle_num": 9006, 
    "out-dataset_question_shuffle_num": 4262, 
    "out-dataset_request_shuffle_num": 113, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "counterfactual", 
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 930137
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 470565, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 11413, 
    "in-dataset_request_shuffle_num": 37, 
    "inf_sentences_id": 470585, 
    "line": "May I have the menu and the wine list ?", 
    "linenum": 470565, 
    "matchl": "May I have the menu and the wine list ?", 
    "out-dataset_question_shuffle_num": 34287, 
    "out-dataset_request_shuffle_num": 114, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 697843
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 438309, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/730.txt.utf-8", 
    "implicative_pattern": "come", 
    "in-dataset_implicative_shuffle_num": 6573, 
    "in-dataset_question_shuffle_num": 9283, 
    "in-dataset_request_shuffle_num": 37, 
    "inf_sentences_id": 1144213, 
    "line": "' Will you promise me that you will have my secret strictly kept , and come alone , or with the only other person that knows it ; and that I shall not be watched or followed ? ' asked the girl .", 
    "linenum": 6225, 
    "matchl": "' Will you promise me that you will have my secret strictly kept , and come alone , or with the only other person that knows it ; and that I shall not be watched or followed ? ' asked the girl .", 
    "out-dataset_implicative_shuffle_num": 18847, 
    "out-dataset_question_shuffle_num": 27898, 
    "out-dataset_request_shuffle_num": 115, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1371793
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 9232, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 809, 
    "in-dataset_question_shuffle_num": 5401, 
    "in-dataset_request_shuffle_num": 38, 
    "inf_sentences_id": 699680, 
    "line": "Where can you find the Venus flytrap ?", 
    "linenum": 3232, 
    "matchl": "Where can you find the Venus flytrap ?", 
    "out-dataset_implicative_shuffle_num": 3237, 
    "out-dataset_question_shuffle_num": 16250, 
    "out-dataset_request_shuffle_num": 116, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 927260
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 39590, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 64023, 
    "in-dataset_request_shuffle_num": 38, 
    "inf_sentences_id": 39606, 
    "line": "May I borrow this book ?", 
    "linenum": 39590, 
    "matchl": "May I borrow this book ?", 
    "out-dataset_question_shuffle_num": 137807, 
    "out-dataset_request_shuffle_num": 117, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 266868
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 359786, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/3600-0.txt", 
    "implicative_pattern": "touch", 
    "in-dataset_counterfactual_shuffle_num": 30297, 
    "in-dataset_implicative_shuffle_num": 192965, 
    "in-dataset_question_shuffle_num": 20118, 
    "in-dataset_request_shuffle_num": 38, 
    "inf_sentences_id": 1065689, 
    "line": "A man must at least become wise at his own expense ; if I have often found myself betrayed under this colour ; if my touch proves commonly false , and my balance unequal and unjust , what assurance can I now have more than at other times ?", 
    "linenum": 7587, 
    "matchl": "A man must at least become wise at his own expense ; if I have often found myself betrayed under this colour ; if my touch proves commonly false , and my balance unequal and unjust , what assurance can I now have more than at other times ?", 
    "out-dataset_counterfactual_shuffle_num": 46153, 
    "out-dataset_implicative_shuffle_num": 391631, 
    "out-dataset_question_shuffle_num": 55489, 
    "out-dataset_request_shuffle_num": 118, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "counterfactual", 
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1293269
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 5438, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 2289, 
    "in-dataset_question_shuffle_num": 10857, 
    "in-dataset_request_shuffle_num": 39, 
    "inf_sentences_id": 695886, 
    "line": "How can I find out my biorhythm ?", 
    "linenum": 2438, 
    "matchl": "How can I find out my biorhythm ?", 
    "out-dataset_implicative_shuffle_num": 8856, 
    "out-dataset_question_shuffle_num": 32618, 
    "out-dataset_request_shuffle_num": 119, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 923466
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 173211, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "stay", 
    "in-dataset_implicative_shuffle_num": 272098, 
    "in-dataset_question_shuffle_num": 89678, 
    "in-dataset_request_shuffle_num": 39, 
    "inf_sentences_id": 173228, 
    "line": "Can I stay with you ? I was kicked out of my house because I did n't pay the rent .", 
    "linenum": 173211, 
    "matchl": "Can I stay with you ? I was kicked out of my house because I did n't pay the rent .", 
    "out-dataset_implicative_shuffle_num": 538444, 
    "out-dataset_question_shuffle_num": 163462, 
    "out-dataset_request_shuffle_num": 120, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 400489
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 304136, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2852-0.txt", 
    "implicative_pattern": "tell", 
    "in-dataset_implicative_shuffle_num": 170045, 
    "in-dataset_question_shuffle_num": 5045, 
    "in-dataset_request_shuffle_num": 39, 
    "inf_sentences_id": 1010039, 
    "line": "Can you tell the position of the rooms ? What are those latticed windows at this end ? \"", 
    "linenum": 3415, 
    "matchl": "Can you tell the position of the rooms ? What are those latticed windows at this end ? \"", 
    "out-dataset_implicative_shuffle_num": 345791, 
    "out-dataset_question_shuffle_num": 15184, 
    "out-dataset_request_shuffle_num": 121, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1237619
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 15249, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_question_shuffle_num": 9173, 
    "in-dataset_request_shuffle_num": 40, 
    "inf_sentences_id": 705697, 
    "line": "Where can I buy a pony on the Big Island for my daughter ?", 
    "linenum": 5249, 
    "matchl": "Where can I buy a pony on the Big Island for my daughter ?", 
    "out-dataset_question_shuffle_num": 27566, 
    "out-dataset_request_shuffle_num": 122, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 933277
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 82334, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 67424, 
    "in-dataset_request_shuffle_num": 40, 
    "inf_sentences_id": 82350, 
    "line": "Ca n't you just picture Ed in woman 's disguise ?", 
    "linenum": 82334, 
    "matchl": "Ca n't you just picture Ed in woman 's disguise ?", 
    "out-dataset_question_shuffle_num": 141208, 
    "out-dataset_request_shuffle_num": 123, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) (n't|not) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 309612
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 274797, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/28054-0.txt", 
    "implicative_pattern": "explain", 
    "in-dataset_implicative_shuffle_num": 70377, 
    "in-dataset_request_shuffle_num": 40, 
    "inf_sentences_id": 980699, 
    "line": "But how can I explain to him before every one that I did this and that ... well , you understand what--sometimes it would not be proper to talk about it--so it is really a scandal !", 
    "linenum": 2372, 
    "matchl": "But how can I explain to him before every one that I did this and that ... well , you understand what--sometimes it would not be proper to talk about it--so it is really a scandal !", 
    "out-dataset_implicative_shuffle_num": 146455, 
    "out-dataset_request_shuffle_num": 124, 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "implicative"
    ], 
    "ulf_sentences_id": 1208279
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 1766, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 717, 
    "in-dataset_question_shuffle_num": 5604, 
    "in-dataset_request_shuffle_num": 41, 
    "inf_sentences_id": 692214, 
    "line": "Where can I find correct tabs for Third Eye Blind songs ?", 
    "linenum": 766, 
    "matchl": "Where can I find correct tabs for Third Eye Blind songs ?", 
    "out-dataset_implicative_shuffle_num": 2869, 
    "out-dataset_question_shuffle_num": 16859, 
    "out-dataset_request_shuffle_num": 125, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 919794
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 596821, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "explain", 
    "in-dataset_implicative_shuffle_num": 154239, 
    "in-dataset_question_shuffle_num": 63089, 
    "in-dataset_request_shuffle_num": 41, 
    "inf_sentences_id": 596842, 
    "line": "Can you explain how Tom died ?", 
    "linenum": 596821, 
    "matchl": "Can you explain how Tom died ?", 
    "out-dataset_implicative_shuffle_num": 314178, 
    "out-dataset_question_shuffle_num": 136873, 
    "out-dataset_request_shuffle_num": 126, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 824099
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 279102, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/28054-0.txt", 
    "implicative_pattern": "come", 
    "in-dataset_implicative_shuffle_num": 60282, 
    "in-dataset_question_shuffle_num": 4821, 
    "in-dataset_request_shuffle_num": 41, 
    "inf_sentences_id": 985004, 
    "line": "What will you wear when you come out of the monastery ?", 
    "linenum": 6677, 
    "matchl": "What will you wear when you come out of the monastery ?", 
    "out-dataset_implicative_shuffle_num": 126265, 
    "out-dataset_question_shuffle_num": 14512, 
    "out-dataset_request_shuffle_num": 127, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1212584
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 9217, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "in-dataset_question_shuffle_num": 1777, 
    "in-dataset_request_shuffle_num": 42, 
    "inf_sentences_id": 699665, 
    "line": "What country would you visit to ski in the Dolomites ?", 
    "linenum": 3217, 
    "matchl": "What country would you visit to ski in the Dolomites ?", 
    "out-dataset_question_shuffle_num": 5378, 
    "out-dataset_request_shuffle_num": 128, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 927245
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 524710, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "tell", 
    "in-dataset_implicative_shuffle_num": 41210, 
    "in-dataset_question_shuffle_num": 22717, 
    "in-dataset_request_shuffle_num": 42, 
    "inf_sentences_id": 524731, 
    "line": "Would you tell Tom I 'm here ?", 
    "linenum": 524710, 
    "matchl": "Would you tell Tom I 'm here ?", 
    "out-dataset_implicative_shuffle_num": 88120, 
    "out-dataset_question_shuffle_num": 60686, 
    "out-dataset_request_shuffle_num": 129, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 751988
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 17867, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1184-0.txt", 
    "implicative_pattern": "see", 
    "in-dataset_implicative_shuffle_num": 206816, 
    "in-dataset_question_shuffle_num": 6039, 
    "in-dataset_request_shuffle_num": 42, 
    "inf_sentences_id": 723767, 
    "line": "But , doctor , you see me already so grieved--how can I introduce into my house so much scandal , after so much sorrow ?", 
    "linenum": 16344, 
    "matchl": "But , doctor , you see me already so grieved--how can I introduce into my house so much scandal , after so much sorrow ?", 
    "out-dataset_implicative_shuffle_num": 419333, 
    "out-dataset_question_shuffle_num": 18166, 
    "out-dataset_request_shuffle_num": 130, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 951347
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 11273, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_question_shuffle_num": 9292, 
    "in-dataset_request_shuffle_num": 43, 
    "inf_sentences_id": 701721, 
    "line": "Where can I look at a perpetual calendar ?", 
    "linenum": 1273, 
    "matchl": "Where can I look at a perpetual calendar ?", 
    "out-dataset_question_shuffle_num": 27923, 
    "out-dataset_request_shuffle_num": 131, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 929301
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 498319, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 62951, 
    "in-dataset_request_shuffle_num": 43, 
    "inf_sentences_id": 498339, 
    "line": "Why wo n't you look at me ?", 
    "linenum": 498319, 
    "matchl": "Why wo n't you look at me ?", 
    "out-dataset_question_shuffle_num": 136735, 
    "out-dataset_request_shuffle_num": 132, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) (n't|not) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 725597
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 273269, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/28054-0.txt", 
    "implicative_pattern": "tell", 
    "in-dataset_implicative_shuffle_num": 50920, 
    "in-dataset_question_shuffle_num": 19524, 
    "in-dataset_request_shuffle_num": 43, 
    "inf_sentences_id": 979171, 
    "line": "\" Am I ? Would you believe it , I was aware of that , too , Pyotr Alexandrovitch , and let me tell you , indeed , I foresaw I should as soon as I began to speak .", 
    "linenum": 844, 
    "matchl": "\" Am I ? Would you believe it , I was aware of that , too , Pyotr Alexandrovitch , and let me tell you , indeed , I foresaw I should as soon as I began to speak .", 
    "out-dataset_implicative_shuffle_num": 107541, 
    "out-dataset_question_shuffle_num": 54301, 
    "out-dataset_request_shuffle_num": 133, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1206751
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 10002, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 3326, 
    "in-dataset_question_shuffle_num": 10249, 
    "in-dataset_request_shuffle_num": 44, 
    "inf_sentences_id": 700450, 
    "line": "How can I find a list of celebrities ' real names ?", 
    "linenum": 2, 
    "matchl": "How can I find a list of celebrities ' real names ?", 
    "out-dataset_implicative_shuffle_num": 11967, 
    "out-dataset_question_shuffle_num": 30794, 
    "out-dataset_request_shuffle_num": 134, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 928030
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 37869, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "like", 
    "in-dataset_implicative_shuffle_num": 258435, 
    "in-dataset_question_shuffle_num": 4858, 
    "in-dataset_request_shuffle_num": 44, 
    "inf_sentences_id": 37885, 
    "line": "Where would you like me to put this ?", 
    "linenum": 37869, 
    "matchl": "Where would you like me to put this ?", 
    "out-dataset_implicative_shuffle_num": 522570, 
    "out-dataset_question_shuffle_num": 14622, 
    "out-dataset_request_shuffle_num": 135, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 265147
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 303458, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2852-0.txt", 
    "implicative_pattern": "discover", 
    "in-dataset_implicative_shuffle_num": 260182, 
    "in-dataset_request_shuffle_num": 44, 
    "inf_sentences_id": 1009361, 
    "line": "There was no trace , however , of anything of the kind , nor could I discover any sign which might indicate the character or intentions of the man who lived in this singular place , save that he must be of Spartan habits and cared little for the comforts of life .", 
    "linenum": 2737, 
    "matchl": "There was no trace , however , of anything of the kind , nor could I discover any sign which might indicate the character or intentions of the man who lived in this singular place , save that he must be of Spartan habits and cared little for the comforts of life .", 
    "out-dataset_implicative_shuffle_num": 526065, 
    "out-dataset_request_shuffle_num": 136, 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "implicative"
    ], 
    "ulf_sentences_id": 1236941
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 9421, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "get", 
    "in-dataset_implicative_shuffle_num": 1088, 
    "in-dataset_question_shuffle_num": 459, 
    "in-dataset_request_shuffle_num": 45, 
    "inf_sentences_id": 699869, 
    "line": "How can I get my product licensed by the NBA ?", 
    "linenum": 3421, 
    "matchl": "How can I get my product licensed by the NBA ?", 
    "out-dataset_implicative_shuffle_num": 4353, 
    "out-dataset_question_shuffle_num": 1424, 
    "out-dataset_request_shuffle_num": 137, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 927449
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 556276, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "help", 
    "in-dataset_implicative_shuffle_num": 216241, 
    "in-dataset_question_shuffle_num": 29022, 
    "in-dataset_request_shuffle_num": 45, 
    "inf_sentences_id": 556297, 
    "line": "Can you help out ?", 
    "linenum": 556276, 
    "matchl": "Can you help out ?", 
    "out-dataset_implicative_shuffle_num": 438182, 
    "out-dataset_question_shuffle_num": 73296, 
    "out-dataset_request_shuffle_num": 138, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 783554
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 340952, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/345.txt.utf-8", 
    "implicative_pattern": "tell", 
    "in-dataset_implicative_shuffle_num": 136505, 
    "in-dataset_question_shuffle_num": 12112, 
    "in-dataset_request_shuffle_num": 45, 
    "inf_sentences_id": 1046855, 
    "line": "Can you tell me why , when other spiders die small and soon , that one great spider lived for centuries in the tower of the old Spanish church and grew and grew , till , on descending , he could drink the oil of all the church lamps ?", 
    "linenum": 4650, 
    "matchl": "Can you tell me why , when other spiders die small and soon , that one great spider lived for centuries in the tower of the old Spanish church and grew and grew , till , on descending , he could drink the oil of all the church lamps ?", 
    "out-dataset_implicative_shuffle_num": 278711, 
    "out-dataset_question_shuffle_num": 36385, 
    "out-dataset_request_shuffle_num": 139, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1274435
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 12899, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 267, 
    "in-dataset_question_shuffle_num": 13781, 
    "in-dataset_request_shuffle_num": 46, 
    "inf_sentences_id": 703347, 
    "line": "Where can I find a lesson plan for teaching the metric system conversion to American standard ?", 
    "linenum": 2899, 
    "matchl": "Where can I find a lesson plan for teaching the metric system conversion to American standard ?", 
    "out-dataset_implicative_shuffle_num": 1069, 
    "out-dataset_question_shuffle_num": 41390, 
    "out-dataset_request_shuffle_num": 140, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 930927
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 435508, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "help", 
    "in-dataset_implicative_shuffle_num": 158715, 
    "in-dataset_question_shuffle_num": 78954, 
    "in-dataset_request_shuffle_num": 46, 
    "inf_sentences_id": 435528, 
    "line": "Can you help me down ?", 
    "linenum": 435508, 
    "matchl": "Can you help me down ?", 
    "out-dataset_implicative_shuffle_num": 323130, 
    "out-dataset_question_shuffle_num": 152738, 
    "out-dataset_request_shuffle_num": 141, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 662786
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 222186, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2554-0.txt", 
    "implicative_pattern": "know", 
    "in-dataset_implicative_shuffle_num": 124663, 
    "in-dataset_question_shuffle_num": 36221, 
    "in-dataset_request_shuffle_num": 46, 
    "inf_sentences_id": 928088, 
    "line": "To return to Nikolay , would you like to know what sort of a type he is , how I understand him , that is ?", 
    "linenum": 11752, 
    "matchl": "To return to Nikolay , would you like to know what sort of a type he is , how I understand him , that is ?", 
    "out-dataset_implicative_shuffle_num": 255027, 
    "out-dataset_question_shuffle_num": 87695, 
    "out-dataset_request_shuffle_num": 142, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1155668
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 560, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_1000.raw", 
    "implicative_pattern": "get", 
    "in-dataset_implicative_shuffle_num": 788, 
    "in-dataset_question_shuffle_num": 7581, 
    "in-dataset_request_shuffle_num": 47, 
    "inf_sentences_id": 691008, 
    "line": "Where on the Internet can I get information about the Fifth Amendment on the American Bill of Rights ?", 
    "linenum": 560, 
    "matchl": "Where on the Internet can I get information about the Fifth Amendment on the American Bill of Rights ?", 
    "out-dataset_implicative_shuffle_num": 3153, 
    "out-dataset_question_shuffle_num": 22790, 
    "out-dataset_request_shuffle_num": 143, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 918588
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 435723, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 13695, 
    "in-dataset_request_shuffle_num": 47, 
    "inf_sentences_id": 435743, 
    "line": "Can you excuse me a second ?", 
    "linenum": 435723, 
    "matchl": "Can you excuse me a second ?", 
    "out-dataset_question_shuffle_num": 41133, 
    "out-dataset_request_shuffle_num": 144, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 663001
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 480177, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/84-0.txt", 
    "implicative_pattern": "make", 
    "in-dataset_implicative_shuffle_num": 100328, 
    "in-dataset_question_shuffle_num": 40405, 
    "in-dataset_request_shuffle_num": 47, 
    "inf_sentences_id": 1186081, 
    "line": "Margaret , what comment can I make on the untimely extinction of this glorious spirit ?", 
    "linenum": 3261, 
    "matchl": "Margaret , what comment can I make on the untimely extinction of this glorious spirit ?", 
    "out-dataset_implicative_shuffle_num": 206357, 
    "out-dataset_question_shuffle_num": 96063, 
    "out-dataset_request_shuffle_num": 145, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1413661
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 13843, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_question_shuffle_num": 6574, 
    "in-dataset_request_shuffle_num": 48, 
    "inf_sentences_id": 704291, 
    "line": "Where could I go to take a ride on a steam locomotive ?", 
    "linenum": 3843, 
    "matchl": "Where could I go to take a ride on a steam locomotive ?", 
    "out-dataset_question_shuffle_num": 19769, 
    "out-dataset_request_shuffle_num": 146, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 931871
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 515518, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "make", 
    "in-dataset_implicative_shuffle_num": 92219, 
    "in-dataset_question_shuffle_num": 79385, 
    "in-dataset_request_shuffle_num": 48, 
    "inf_sentences_id": 515539, 
    "line": "Can you make them smile ?", 
    "linenum": 515518, 
    "matchl": "Can you make them smile ?", 
    "out-dataset_implicative_shuffle_num": 190138, 
    "out-dataset_question_shuffle_num": 153169, 
    "out-dataset_request_shuffle_num": 147, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 742796
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 453812, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/768.txt.utf-8", 
    "in-dataset_question_shuffle_num": 3356, 
    "in-dataset_request_shuffle_num": 48, 
    "inf_sentences_id": 1159716, 
    "line": "There is himself , Earnshaw , Zillah , Joseph and I.  Which would you have ? '", 
    "linenum": 239, 
    "matchl": "There is himself , Earnshaw , Zillah , Joseph and I.  Which would you have ? '", 
    "out-dataset_question_shuffle_num": 10117, 
    "out-dataset_request_shuffle_num": 148, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 1387296
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 1913, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 3260, 
    "in-dataset_question_shuffle_num": 6510, 
    "in-dataset_request_shuffle_num": 49, 
    "inf_sentences_id": 692361, 
    "line": "How can I find online spelling , and punctuation drills for my 6th grader ?", 
    "linenum": 913, 
    "matchl": "How can I find online spelling , and punctuation drills for my 6th grader ?", 
    "out-dataset_implicative_shuffle_num": 11769, 
    "out-dataset_question_shuffle_num": 19577, 
    "out-dataset_request_shuffle_num": 149, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 919941
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 52462, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 55399, 
    "in-dataset_request_shuffle_num": 49, 
    "inf_sentences_id": 52478, 
    "line": "Will you lend me your pencil ?", 
    "linenum": 52462, 
    "matchl": "Will you lend me your pencil ?", 
    "out-dataset_question_shuffle_num": 126050, 
    "out-dataset_request_shuffle_num": 150, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 279740
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 410726, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/4517-0.txt", 
    "implicative_pattern": "tell", 
    "in-dataset_implicative_shuffle_num": 98030, 
    "in-dataset_question_shuffle_num": 28994, 
    "in-dataset_request_shuffle_num": 49, 
    "inf_sentences_id": 1116630, 
    "line": "\" How could I tell you before I started ?", 
    "linenum": 990, 
    "matchl": "\" How could I tell you before I started ?", 
    "out-dataset_implicative_shuffle_num": 201761, 
    "out-dataset_question_shuffle_num": 73241, 
    "out-dataset_request_shuffle_num": 151, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1344210
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 2869, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 2931, 
    "in-dataset_question_shuffle_num": 3855, 
    "in-dataset_request_shuffle_num": 50, 
    "inf_sentences_id": 693317, 
    "line": "Where can I find the lyrics for the song ` Getting Married Today ' from the musical ` Company ' ?", 
    "linenum": 1869, 
    "matchl": "Where can I find the lyrics for the song ` Getting Married Today ' from the musical ` Company ' ?", 
    "out-dataset_implicative_shuffle_num": 10782, 
    "out-dataset_question_shuffle_num": 11612, 
    "out-dataset_request_shuffle_num": 152, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 920897
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 193424, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "help", 
    "in-dataset_implicative_shuffle_num": 175940, 
    "in-dataset_question_shuffle_num": 19656, 
    "in-dataset_request_shuffle_num": 50, 
    "inf_sentences_id": 193441, 
    "line": "Could you help me wash the dishes ?", 
    "linenum": 193424, 
    "matchl": "Could you help me wash the dishes ?", 
    "out-dataset_implicative_shuffle_num": 357580, 
    "out-dataset_question_shuffle_num": 54564, 
    "out-dataset_request_shuffle_num": 153, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 420702
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 37544, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1260.txt.utf-8", 
    "implicative_pattern": "tell", 
    "in-dataset_implicative_shuffle_num": 153153, 
    "in-dataset_question_shuffle_num": 56600, 
    "in-dataset_request_shuffle_num": 50, 
    "inf_sentences_id": 743444, 
    "line": "Now , can you tell me whether it is actually true that Mr. Rochester has asked you to marry him ?", 
    "linenum": 5252, 
    "matchl": "Now , can you tell me whether it is actually true that Mr. Rochester has asked you to marry him ?", 
    "out-dataset_implicative_shuffle_num": 312007, 
    "out-dataset_question_shuffle_num": 128453, 
    "out-dataset_request_shuffle_num": 154, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 971024
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 8289, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 2453, 
    "in-dataset_question_shuffle_num": 9488, 
    "in-dataset_request_shuffle_num": 51, 
    "inf_sentences_id": 698737, 
    "line": "What is the all-time stock high of Apple Computer , and where can I find this information ?", 
    "linenum": 2289, 
    "matchl": "What is the all-time stock high of Apple Computer , and where can I find this information ?", 
    "out-dataset_implicative_shuffle_num": 9348, 
    "out-dataset_question_shuffle_num": 28511, 
    "out-dataset_request_shuffle_num": 155, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 926317
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 423523, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "tell", 
    "in-dataset_implicative_shuffle_num": 261134, 
    "in-dataset_question_shuffle_num": 82679, 
    "in-dataset_request_shuffle_num": 51, 
    "inf_sentences_id": 423543, 
    "line": "Could you tell us more about yourself ?", 
    "linenum": 423523, 
    "matchl": "Could you tell us more about yourself ?", 
    "out-dataset_implicative_shuffle_num": 527480, 
    "out-dataset_question_shuffle_num": 156463, 
    "out-dataset_request_shuffle_num": 156, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 650801
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 405164, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/45-0.txt", 
    "implicative_pattern": "see", 
    "in-dataset_implicative_shuffle_num": 90679, 
    "in-dataset_question_shuffle_num": 38857, 
    "in-dataset_request_shuffle_num": 51, 
    "inf_sentences_id": 1111068, 
    "line": "Oh , Marilla , ca n't you just imagine you see them ?", 
    "linenum": 2599, 
    "matchl": "Oh , Marilla , ca n't you just imagine you see them ?", 
    "out-dataset_implicative_shuffle_num": 187059, 
    "out-dataset_question_shuffle_num": 92967, 
    "out-dataset_request_shuffle_num": 157, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) (n't|not) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1338648
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 13784, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_question_shuffle_num": 14584, 
    "in-dataset_request_shuffle_num": 52, 
    "inf_sentences_id": 704232, 
    "line": "How can you define time ?", 
    "linenum": 3784, 
    "matchl": "How can you define time ?", 
    "out-dataset_question_shuffle_num": 43799, 
    "out-dataset_request_shuffle_num": 158, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 931812
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 12418, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 54923, 
    "in-dataset_request_shuffle_num": 52, 
    "inf_sentences_id": 12434, 
    "line": "Can I have a bite ?", 
    "linenum": 12418, 
    "matchl": "Can I have a bite ?", 
    "out-dataset_question_shuffle_num": 125098, 
    "out-dataset_request_shuffle_num": 159, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 239696
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 23738, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1184-0.txt", 
    "implicative_pattern": "know", 
    "in-dataset_counterfactual_shuffle_num": 24595, 
    "in-dataset_implicative_shuffle_num": 213368, 
    "in-dataset_question_shuffle_num": 26114, 
    "in-dataset_request_shuffle_num": 52, 
    "inf_sentences_id": 729638, 
    "line": "\" If they should arrest him ( I know that sometimes prisons afford means of escape ), will you leave him in prison ? \"", 
    "linenum": 22215, 
    "matchl": "\" If they should arrest him ( I know that sometimes prisons afford means of escape ), will you leave him in prison ? \"", 
    "out-dataset_counterfactual_shuffle_num": 40451, 
    "out-dataset_implicative_shuffle_num": 432437, 
    "out-dataset_question_shuffle_num": 67481, 
    "out-dataset_request_shuffle_num": 160, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "counterfactual", 
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 957218
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 13978, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "get", 
    "in-dataset_implicative_shuffle_num": 3443, 
    "in-dataset_question_shuffle_num": 4370, 
    "in-dataset_request_shuffle_num": 53, 
    "inf_sentences_id": 704426, 
    "line": "Where can I get piano music for the Jamiroquai song Everyday for the midi ?", 
    "linenum": 3978, 
    "matchl": "Where can I get piano music for the Jamiroquai song Everyday for the midi ?", 
    "out-dataset_implicative_shuffle_num": 12318, 
    "out-dataset_question_shuffle_num": 13157, 
    "out-dataset_request_shuffle_num": 161, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 932006
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 648559, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "like", 
    "in-dataset_implicative_shuffle_num": 245058, 
    "in-dataset_question_shuffle_num": 2248, 
    "in-dataset_request_shuffle_num": 53, 
    "inf_sentences_id": 648581, 
    "line": "Would you like to play with us , Jim ?", 
    "linenum": 648559, 
    "matchl": "Would you like to play with us , Jim ?", 
    "out-dataset_implicative_shuffle_num": 495816, 
    "out-dataset_question_shuffle_num": 6792, 
    "out-dataset_request_shuffle_num": 162, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 875837
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 241351, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2600-0.txt", 
    "implicative_pattern": "know", 
    "in-dataset_implicative_shuffle_num": 234078, 
    "in-dataset_question_shuffle_num": 33009, 
    "in-dataset_request_shuffle_num": 53, 
    "inf_sentences_id": 947253, 
    "line": "\" How can you know ?", 
    "linenum": 12230, 
    "matchl": "\" How can you know ?", 
    "out-dataset_implicative_shuffle_num": 473857, 
    "out-dataset_question_shuffle_num": 81271, 
    "out-dataset_request_shuffle_num": 163, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1174833
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 9357, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 652, 
    "in-dataset_question_shuffle_num": 10351, 
    "in-dataset_request_shuffle_num": 54, 
    "inf_sentences_id": 699805, 
    "line": "Where can I find lyrics for R&B ?", 
    "linenum": 3357, 
    "matchl": "Where can I find lyrics for R&B ?", 
    "out-dataset_implicative_shuffle_num": 2609, 
    "out-dataset_question_shuffle_num": 31100, 
    "out-dataset_request_shuffle_num": 164, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 927385
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 436039, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "come", 
    "in-dataset_implicative_shuffle_num": 15036, 
    "in-dataset_question_shuffle_num": 13561, 
    "in-dataset_request_shuffle_num": 54, 
    "inf_sentences_id": 436059, 
    "line": "Can you ask Tom to come on in ?", 
    "linenum": 436039, 
    "matchl": "Can you ask Tom to come on in ?", 
    "out-dataset_implicative_shuffle_num": 35772, 
    "out-dataset_question_shuffle_num": 40731, 
    "out-dataset_request_shuffle_num": 165, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 663317
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 50442, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/135-0.txt", 
    "implicative_pattern": "read", 
    "in-dataset_implicative_shuffle_num": 26639, 
    "in-dataset_question_shuffle_num": 13861, 
    "in-dataset_request_shuffle_num": 54, 
    "inf_sentences_id": 756342, 
    "line": "Can you read ? \"", 
    "linenum": 2015, 
    "matchl": "Can you read ? \"", 
    "out-dataset_implicative_shuffle_num": 58979, 
    "out-dataset_question_shuffle_num": 41632, 
    "out-dataset_request_shuffle_num": 166, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 983922
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 8634, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "get", 
    "in-dataset_implicative_shuffle_num": 3534, 
    "in-dataset_question_shuffle_num": 9896, 
    "in-dataset_request_shuffle_num": 55, 
    "inf_sentences_id": 699082, 
    "line": "Where can I get a photograph of professor Randolph Quirk ?", 
    "linenum": 2634, 
    "matchl": "Where can I get a photograph of professor Randolph Quirk ?", 
    "out-dataset_implicative_shuffle_num": 12591, 
    "out-dataset_question_shuffle_num": 29735, 
    "out-dataset_request_shuffle_num": 167, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 926662
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 500865, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "get", 
    "in-dataset_implicative_shuffle_num": 104882, 
    "in-dataset_question_shuffle_num": 33919, 
    "in-dataset_request_shuffle_num": 55, 
    "inf_sentences_id": 500886, 
    "line": "How soon can you get that done ?", 
    "linenum": 500865, 
    "matchl": "How soon can you get that done ?", 
    "out-dataset_implicative_shuffle_num": 215464, 
    "out-dataset_question_shuffle_num": 83090, 
    "out-dataset_request_shuffle_num": 168, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 728143
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 298504, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2814-0.txt", 
    "implicative_pattern": "come", 
    "in-dataset_implicative_shuffle_num": 248874, 
    "in-dataset_question_shuffle_num": 32732, 
    "in-dataset_request_shuffle_num": 55, 
    "inf_sentences_id": 1004406, 
    "line": "\" Wo n't you come in and sit down ? \"", 
    "linenum": 2520, 
    "matchl": "\" Wo n't you come in and sit down ? \"", 
    "out-dataset_implicative_shuffle_num": 503449, 
    "out-dataset_question_shuffle_num": 80717, 
    "out-dataset_request_shuffle_num": 169, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) (n't|not) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1231986
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 7163, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "stop", 
    "in-dataset_implicative_shuffle_num": 643, 
    "in-dataset_question_shuffle_num": 988, 
    "in-dataset_request_shuffle_num": 56, 
    "inf_sentences_id": 697611, 
    "line": "How can you stop the itch from poison ivy ?", 
    "linenum": 1163, 
    "matchl": "How can you stop the itch from poison ivy ?", 
    "out-dataset_implicative_shuffle_num": 2573, 
    "out-dataset_question_shuffle_num": 3011, 
    "out-dataset_request_shuffle_num": 170, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 925191
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 435480, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 98547, 
    "in-dataset_request_shuffle_num": 56, 
    "inf_sentences_id": 435500, 
    "line": "Can you freeze it ?", 
    "linenum": 435480, 
    "matchl": "Can you freeze it ?", 
    "out-dataset_question_shuffle_num": 172331, 
    "out-dataset_request_shuffle_num": 171, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 662758
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 424636, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/514.txt.utf-8", 
    "in-dataset_question_shuffle_num": 51945, 
    "in-dataset_request_shuffle_num": 56, 
    "inf_sentences_id": 1130540, 
    "line": "How will you have me , full length or three-quarters , on my head or my heels ?", 
    "linenum": 7797, 
    "matchl": "How will you have me , full length or three-quarters , on my head or my heels ?", 
    "out-dataset_question_shuffle_num": 119143, 
    "out-dataset_request_shuffle_num": 172, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 1358120
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 13217, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_question_shuffle_num": 4461, 
    "in-dataset_request_shuffle_num": 57, 
    "inf_sentences_id": 703665, 
    "line": "What country would you visit to ski in the Dolomites ?", 
    "linenum": 3217, 
    "matchl": "What country would you visit to ski in the Dolomites ?", 
    "out-dataset_question_shuffle_num": 13430, 
    "out-dataset_request_shuffle_num": 173, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 931245
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>if<mid>(was|were|had|<past>|<ppart>) .+", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 504936, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "mind", 
    "in-dataset_counterfactual_shuffle_num": 10820, 
    "in-dataset_implicative_shuffle_num": 111001, 
    "in-dataset_question_shuffle_num": 56028, 
    "in-dataset_request_shuffle_num": 57, 
    "inf_sentences_id": 504957, 
    "line": "Would you mind if I helped ?", 
    "linenum": 504936, 
    "matchl": "Would you mind if I helped ?", 
    "out-dataset_counterfactual_shuffle_num": 21846, 
    "out-dataset_implicative_shuffle_num": 227702, 
    "out-dataset_question_shuffle_num": 127308, 
    "out-dataset_request_shuffle_num": 174, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "counterfactual", 
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 732214
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 456345, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/768.txt.utf-8", 
    "implicative_pattern": "respecting", 
    "in-dataset_implicative_shuffle_num": 9762, 
    "in-dataset_question_shuffle_num": 48004, 
    "in-dataset_request_shuffle_num": 57, 
    "inf_sentences_id": 1162249, 
    "line": "But do you imagine that I shall leave Catherine to his _duty_ and _humanity_ ? and can you compare my feelings respecting Catherine to his ?", 
    "linenum": 2772, 
    "matchl": "But do you imagine that I shall leave Catherine to his _duty_ and _humanity_ ? and can you compare my feelings respecting Catherine to his ?", 
    "out-dataset_implicative_shuffle_num": 25225, 
    "out-dataset_question_shuffle_num": 111261, 
    "out-dataset_request_shuffle_num": 175, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1389829
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 7049, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 1128, 
    "in-dataset_question_shuffle_num": 4226, 
    "in-dataset_request_shuffle_num": 58, 
    "inf_sentences_id": 697497, 
    "line": "How can I find out how much income tax is paid on Social Security income on the 1998 income tax ?", 
    "linenum": 1049, 
    "matchl": "How can I find out how much income tax is paid on Social Security income on the 1998 income tax ?", 
    "out-dataset_implicative_shuffle_num": 4513, 
    "out-dataset_question_shuffle_num": 12725, 
    "out-dataset_request_shuffle_num": 176, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 925077
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 17882, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 98982, 
    "in-dataset_request_shuffle_num": 58, 
    "inf_sentences_id": 17898, 
    "line": "Can I bring you anything else ?", 
    "linenum": 17882, 
    "matchl": "Can I bring you anything else ?", 
    "out-dataset_question_shuffle_num": 172766, 
    "out-dataset_request_shuffle_num": 177, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 245160
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 49028, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/135-0.txt", 
    "implicative_pattern": "said", 
    "in-dataset_implicative_shuffle_num": 62078, 
    "in-dataset_question_shuffle_num": 41898, 
    "in-dataset_request_shuffle_num": 58, 
    "inf_sentences_id": 754928, 
    "line": "\" What would you have , Monseigneur ? \" said the director .", 
    "linenum": 601, 
    "matchl": "\" What would you have , Monseigneur ? \" said the director .", 
    "out-dataset_implicative_shuffle_num": 129857, 
    "out-dataset_question_shuffle_num": 99049, 
    "out-dataset_request_shuffle_num": 178, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 982508
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 7212, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 1956, 
    "in-dataset_question_shuffle_num": 6715, 
    "in-dataset_request_shuffle_num": 59, 
    "inf_sentences_id": 697660, 
    "line": "Where can I find information about touring the Philippines ?", 
    "linenum": 1212, 
    "matchl": "Where can I find information about touring the Philippines ?", 
    "out-dataset_implicative_shuffle_num": 7825, 
    "out-dataset_question_shuffle_num": 20192, 
    "out-dataset_request_shuffle_num": 179, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 925240
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 387663, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 65819, 
    "in-dataset_request_shuffle_num": 59, 
    "inf_sentences_id": 387682, 
    "line": "Can you protect me ?", 
    "linenum": 387663, 
    "matchl": "Can you protect me ?", 
    "out-dataset_question_shuffle_num": 139603, 
    "out-dataset_request_shuffle_num": 180, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 614941
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 248467, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2600-0.txt", 
    "in-dataset_question_shuffle_num": 16168, 
    "in-dataset_request_shuffle_num": 59, 
    "inf_sentences_id": 954369, 
    "line": "What could I have lost ?", 
    "linenum": 19346, 
    "matchl": "What could I have lost ?", 
    "out-dataset_question_shuffle_num": 47589, 
    "out-dataset_request_shuffle_num": 181, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 1181949
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 14917, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "get", 
    "in-dataset_implicative_shuffle_num": 778, 
    "in-dataset_question_shuffle_num": 5996, 
    "in-dataset_request_shuffle_num": 60, 
    "inf_sentences_id": 705365, 
    "line": "Where can I get information on the original 13 US colonies ?", 
    "linenum": 4917, 
    "matchl": "Where can I get information on the original 13 US colonies ?", 
    "out-dataset_implicative_shuffle_num": 3113, 
    "out-dataset_question_shuffle_num": 18035, 
    "out-dataset_request_shuffle_num": 182, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 932945
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 406104, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "miss", 
    "in-dataset_implicative_shuffle_num": 131568, 
    "in-dataset_question_shuffle_num": 25310, 
    "in-dataset_request_shuffle_num": 60, 
    "inf_sentences_id": 406124, 
    "line": "Can you miss the present moment ?", 
    "linenum": 406104, 
    "matchl": "Can you miss the present moment ?", 
    "out-dataset_implicative_shuffle_num": 268836, 
    "out-dataset_question_shuffle_num": 65872, 
    "out-dataset_request_shuffle_num": 183, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 633382
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 180227, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/209-0.txt", 
    "implicative_pattern": "like", 
    "in-dataset_implicative_shuffle_num": 251137, 
    "in-dataset_request_shuffle_num": 60, 
    "inf_sentences_id": 886128, 
    "line": "My charming work was just my life with Miles and Flora , and through nothing could I so like it as through feeling that I could throw myself into it in trouble .", 
    "linenum": 486, 
    "matchl": "My charming work was just my life with Miles and Flora , and through nothing could I so like it as through feeling that I could throw myself into it in trouble .", 
    "out-dataset_implicative_shuffle_num": 507975, 
    "out-dataset_request_shuffle_num": 184, 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "implicative"
    ], 
    "ulf_sentences_id": 1113708
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 11936, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 536, 
    "in-dataset_question_shuffle_num": 5871, 
    "in-dataset_request_shuffle_num": 61, 
    "inf_sentences_id": 702384, 
    "line": "Where on the Internet can I find information on laundry detergent ?", 
    "linenum": 1936, 
    "matchl": "Where on the Internet can I find information on laundry detergent ?", 
    "out-dataset_implicative_shuffle_num": 2145, 
    "out-dataset_question_shuffle_num": 17660, 
    "out-dataset_request_shuffle_num": 185, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 929964
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 240274, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 6391, 
    "in-dataset_request_shuffle_num": 61, 
    "inf_sentences_id": 240292, 
    "line": "When will you go to Germany ?", 
    "linenum": 240274, 
    "matchl": "When will you go to Germany ?", 
    "out-dataset_question_shuffle_num": 19221, 
    "out-dataset_request_shuffle_num": 186, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 467552
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 280037, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/28054-0.txt", 
    "in-dataset_question_shuffle_num": 2641, 
    "in-dataset_request_shuffle_num": 61, 
    "inf_sentences_id": 985939, 
    "line": "She beseeches Him , she will not desist , and when God points to the hands and feet of her Son , nailed to the Cross , and asks , ' How can I forgive His tormentors ? ' she bids all the saints , all the martyrs , all the angels and archangels to fall down with her and pray for mercy on all without distinction .", 
    "linenum": 7612, 
    "matchl": "She beseeches Him , she will not desist , and when God points to the hands and feet of her Son , nailed to the Cross , and asks , ' How can I forgive His tormentors ? ' she bids all the saints , all the martyrs , all the angels and archangels to fall down with her and pray for mercy on all without distinction .", 
    "out-dataset_question_shuffle_num": 7972, 
    "out-dataset_request_shuffle_num": 187, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 1213519
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 327, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_1000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_implicative_shuffle_num": 953, 
    "in-dataset_question_shuffle_num": 6775, 
    "in-dataset_request_shuffle_num": 62, 
    "inf_sentences_id": 690775, 
    "line": "Where can I find a `` Fifth Element '' screensaver ?", 
    "linenum": 327, 
    "matchl": "Where can I find a `` Fifth Element '' screensaver ?", 
    "out-dataset_implicative_shuffle_num": 3813, 
    "out-dataset_question_shuffle_num": 20372, 
    "out-dataset_request_shuffle_num": 188, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 918355
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 355481, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 52652, 
    "in-dataset_request_shuffle_num": 62, 
    "inf_sentences_id": 355500, 
    "line": "May I have the floor ?", 
    "linenum": 355481, 
    "matchl": "May I have the floor ?", 
    "out-dataset_question_shuffle_num": 120556, 
    "out-dataset_request_shuffle_num": 189, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 582759
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 20959, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1184-0.txt", 
    "in-dataset_request_shuffle_num": 62, 
    "inf_sentences_id": 726859, 
    "line": "\" The more must you fortify yourself , Albert .", 
    "linenum": 19436, 
    "matchl": "\" The more must you fortify yourself , Albert .", 
    "out-dataset_request_shuffle_num": 190, 
    "request_pattern": "<begin?>(must|Must) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request"
    ], 
    "ulf_sentences_id": 954439
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 10677, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_question_shuffle_num": 5215, 
    "in-dataset_request_shuffle_num": 63, 
    "inf_sentences_id": 701125, 
    "line": "How can you contact play producers and promoters on-line ?", 
    "linenum": 677, 
    "matchl": "How can you contact play producers and promoters on-line ?", 
    "out-dataset_question_shuffle_num": 15692, 
    "out-dataset_request_shuffle_num": 191, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 928705
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 91216, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 60255, 
    "in-dataset_request_shuffle_num": 63, 
    "inf_sentences_id": 91232, 
    "line": "Can you give me directions to the subway station ?", 
    "linenum": 91216, 
    "matchl": "Can you give me directions to the subway station ?", 
    "out-dataset_question_shuffle_num": 134039, 
    "out-dataset_request_shuffle_num": 192, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 318494
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 89510, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/140-0.txt", 
    "implicative_pattern": "please", 
    "in-dataset_implicative_shuffle_num": 54900, 
    "in-dataset_question_shuffle_num": 40213, 
    "in-dataset_request_shuffle_num": 63, 
    "inf_sentences_id": 795410, 
    "line": "\" Please , ma'am , \" he began , \" could you lend me the price of a night 's lodging ?", 
    "linenum": 5328, 
    "matchl": "\" Please , ma'am , \" he began , \" could you lend me the price of a night 's lodging ?", 
    "out-dataset_implicative_shuffle_num": 115501, 
    "out-dataset_question_shuffle_num": 95679, 
    "out-dataset_request_shuffle_num": 193, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1022990
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 429867, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_question_shuffle_num": 19226, 
    "in-dataset_request_shuffle_num": 64, 
    "inf_sentences_id": 429887, 
    "line": "Can you loan him some money ?", 
    "linenum": 429867, 
    "matchl": "Can you loan him some money ?", 
    "out-dataset_question_shuffle_num": 53704, 
    "out-dataset_request_shuffle_num": 195, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 657145
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 220866, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2554-0.txt", 
    "in-dataset_question_shuffle_num": 9000, 
    "in-dataset_request_shuffle_num": 64, 
    "inf_sentences_id": 926768, 
    "line": "How would you decide which of them was to die ? I ask you ? \"", 
    "linenum": 10432, 
    "matchl": "How would you decide which of them was to die ? I ask you ? \"", 
    "out-dataset_question_shuffle_num": 27049, 
    "out-dataset_request_shuffle_num": 196, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 1154348
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 13999, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "read", 
    "in-dataset_implicative_shuffle_num": 570, 
    "in-dataset_question_shuffle_num": 4866, 
    "in-dataset_request_shuffle_num": 65, 
    "inf_sentences_id": 704447, 
    "line": "Where can I read about Abraham Lincoln ?", 
    "linenum": 3999, 
    "matchl": "Where can I read about Abraham Lincoln ?", 
    "out-dataset_implicative_shuffle_num": 2281, 
    "out-dataset_question_shuffle_num": 14645, 
    "out-dataset_request_shuffle_num": 197, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 932027
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 52858, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "seen", 
    "in-dataset_implicative_shuffle_num": 35270, 
    "in-dataset_question_shuffle_num": 45661, 
    "in-dataset_request_shuffle_num": 65, 
    "inf_sentences_id": 52874, 
    "line": "I 've never seen you cook. Can you cook anything at all ?", 
    "linenum": 52858, 
    "matchl": "I 've never seen you cook. Can you cook anything at all ?", 
    "out-dataset_implicative_shuffle_num": 76240, 
    "out-dataset_question_shuffle_num": 106574, 
    "out-dataset_request_shuffle_num": 198, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 280136
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 161508, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1998-0.txt", 
    "implicative_pattern": "fail", 
    "in-dataset_implicative_shuffle_num": 29578, 
    "in-dataset_request_shuffle_num": 65, 
    "inf_sentences_id": 867409, 
    "line": "Oh , how could I fail to divine all the modesty of thy soul !", 
    "linenum": 3446, 
    "matchl": "Oh , how could I fail to divine all the modesty of thy soul !", 
    "out-dataset_implicative_shuffle_num": 64857, 
    "out-dataset_request_shuffle_num": 199, 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "implicative"
    ], 
    "ulf_sentences_id": 1094989
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 8886, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "get", 
    "in-dataset_implicative_shuffle_num": 1424, 
    "in-dataset_question_shuffle_num": 6848, 
    "in-dataset_request_shuffle_num": 66, 
    "inf_sentences_id": 699334, 
    "line": "Where can I get cotton textiles importer details ?", 
    "linenum": 2886, 
    "matchl": "Where can I get cotton textiles importer details ?", 
    "out-dataset_implicative_shuffle_num": 5697, 
    "out-dataset_question_shuffle_num": 20591, 
    "out-dataset_request_shuffle_num": 200, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 926914
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 130762, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "please", 
    "in-dataset_implicative_shuffle_num": 199536, 
    "in-dataset_question_shuffle_num": 48603, 
    "in-dataset_request_shuffle_num": 66, 
    "inf_sentences_id": 130779, 
    "line": "Could you show me another one , please ?", 
    "linenum": 130762, 
    "matchl": "Could you show me another one , please ?", 
    "out-dataset_implicative_shuffle_num": 404772, 
    "out-dataset_question_shuffle_num": 112458, 
    "out-dataset_request_shuffle_num": 201, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 358040
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 287137, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/28054-0.txt", 
    "in-dataset_question_shuffle_num": 8008, 
    "in-dataset_request_shuffle_num": 66, 
    "inf_sentences_id": 993039, 
    "line": "Undress ? Ugh ! Damn it ! Wo n't you search me as I am ! Ca n't you ? \"", 
    "linenum": 14712, 
    "matchl": "Undress ? Ugh ! Damn it ! Wo n't you search me as I am ! Ca n't you ? \"", 
    "out-dataset_question_shuffle_num": 24073, 
    "out-dataset_request_shuffle_num": 202, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) (n't|not) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 1220619
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 1676, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_counterfactual_shuffle_num": 18, 
    "in-dataset_implicative_shuffle_num": 1711, 
    "in-dataset_question_shuffle_num": 794, 
    "in-dataset_request_shuffle_num": 67, 
    "inf_sentences_id": 692124, 
    "line": "How can I find a phone number of someone if I only know their email address ?", 
    "linenum": 676, 
    "matchl": "How can I find a phone number of someone if I only know their email address ?", 
    "out-dataset_counterfactual_shuffle_num": 73, 
    "out-dataset_implicative_shuffle_num": 6845, 
    "out-dataset_question_shuffle_num": 2429, 
    "out-dataset_request_shuffle_num": 203, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "counterfactual", 
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 919704
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 322263, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "come", 
    "in-dataset_implicative_shuffle_num": 229955, 
    "in-dataset_question_shuffle_num": 47251, 
    "in-dataset_request_shuffle_num": 67, 
    "inf_sentences_id": 322282, 
    "line": "Can you come tomorrow ?", 
    "linenum": 322263, 
    "matchl": "Can you come tomorrow ?", 
    "out-dataset_implicative_shuffle_num": 465610, 
    "out-dataset_question_shuffle_num": 109754, 
    "out-dataset_request_shuffle_num": 204, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 549541
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 46, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/10", 
    "implicative_pattern": "like", 
    "in-dataset_counterfactual_shuffle_num": 0, 
    "in-dataset_implicative_shuffle_num": 544, 
    "inf_sentences_id": 687342, 
    "line": "If the economy turns sour in the wake of his administration 's record budget and trade deficits , Reagan may go down in history like Calvin Coolidge as a president who failed to take action to stave off coming disaster .", 
    "linenum": 6, 
    "matchl": "If the economy turns sour in the wake of his administration 's record budget and trade deficits , Reagan may go down in history like Calvin Coolidge as a president who failed to take action to stave off coming disaster .", 
    "out-dataset_counterfactual_shuffle_num": 0, 
    "out-dataset_implicative_shuffle_num": 2176, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 914922
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If)<mid>(was|were|had|<past>|<ppart>)<mid?>(<futr>) .+", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 163479, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "helped", 
    "in-dataset_counterfactual_shuffle_num": 0, 
    "in-dataset_implicative_shuffle_num": 15342, 
    "inf_sentences_id": 163496, 
    "line": "If my mother had still been alive , she would have helped me at that time .", 
    "linenum": 163479, 
    "matchl": "If my mother had still been alive , she would have helped me at that time .", 
    "out-dataset_counterfactual_shuffle_num": 2, 
    "out-dataset_implicative_shuffle_num": 36384, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 390757
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>if<mid>(was|were|had|<past>|<ppart>) .+", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 104660, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1404.txt.utf-8", 
    "implicative_pattern": "get", 
    "in-dataset_counterfactual_shuffle_num": 0, 
    "in-dataset_implicative_shuffle_num": 128402, 
    "in-dataset_question_shuffle_num": 24199, 
    "inf_sentences_id": 810561, 
    "line": "Others suspect that two thirds will oppress the remaining third , and ask whether those gentlemen are made sufficiently responsible for their conduct ; whether , if they act corruptly , they can be punished ; and if they make disadvantageous treaties , how are we to get rid of those treaties ?", 
    "linenum": 4574, 
    "matchl": "Others suspect that two thirds will oppress the remaining third , and ask whether those gentlemen are made sufficiently responsible for their conduct ; whether , if they act corruptly , they can be punished ; and if they make disadvantageous treaties , how are we to get rid of those treaties ?", 
    "out-dataset_counterfactual_shuffle_num": 3, 
    "out-dataset_implicative_shuffle_num": 262505, 
    "out-dataset_question_shuffle_num": 63651, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1038141
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 762, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/123", 
    "implicative_pattern": "continue", 
    "in-dataset_counterfactual_shuffle_num": 1, 
    "in-dataset_implicative_shuffle_num": 619, 
    "inf_sentences_id": 688058, 
    "line": "Saturday , he amended his remarks to say that he would continue to abide by the cease-fire if the U.S. ends its financial support for the Contras .", 
    "linenum": 7, 
    "matchl": "Saturday , he amended his remarks to say that he would continue to abide by the cease-fire if the U.S. ends its financial support for the Contras .", 
    "out-dataset_counterfactual_shuffle_num": 4, 
    "out-dataset_implicative_shuffle_num": 2476, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 915638
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 12039, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "find", 
    "in-dataset_counterfactual_shuffle_num": 1, 
    "in-dataset_implicative_shuffle_num": 3144, 
    "in-dataset_question_shuffle_num": 8581, 
    "inf_sentences_id": 702487, 
    "line": "How do I find a city if I have the area code ?", 
    "linenum": 2039, 
    "matchl": "How do I find a city if I have the area code ?", 
    "out-dataset_counterfactual_shuffle_num": 5, 
    "out-dataset_implicative_shuffle_num": 11421, 
    "out-dataset_question_shuffle_num": 25790, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 930067
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>if<mid>(was|were|had|<past>|<ppart>) .+", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 467435, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "known", 
    "in-dataset_counterfactual_shuffle_num": 1, 
    "in-dataset_implicative_shuffle_num": 51654, 
    "inf_sentences_id": 467455, 
    "line": "Tom would n't have married Mary if he 'd known she had spent time in prison .", 
    "linenum": 467435, 
    "matchl": "Tom would n't have married Mary if he 'd known she had spent time in prison .", 
    "out-dataset_counterfactual_shuffle_num": 6, 
    "out-dataset_implicative_shuffle_num": 109008, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 694713
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 295942, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/28054-0.txt", 
    "in-dataset_counterfactual_shuffle_num": 1, 
    "in-dataset_question_shuffle_num": 21699, 
    "inf_sentences_id": 1001844, 
    "line": "Who , if not Ilusha , the good boy , the dear boy , precious to us for ever !", 
    "linenum": 23517, 
    "matchl": "Who , if not Ilusha , the good boy , the dear boy , precious to us for ever !", 
    "out-dataset_counterfactual_shuffle_num": 7, 
    "out-dataset_question_shuffle_num": 58651, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question"
    ], 
    "ulf_sentences_id": 1229424
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If)<mid>(was|were|had|<past>|<ppart>)<mid?>(<futr>) .+", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1658, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/39", 
    "implicative_pattern": "said", 
    "in-dataset_counterfactual_shuffle_num": 2, 
    "in-dataset_implicative_shuffle_num": 235, 
    "inf_sentences_id": 688954, 
    "line": "`` Both the Congress and the president , if those projections were way off , will face the same consequences , '' new House Budget Committee Chairman Leon Panetta , D-Calif. , said of the administration 's more optimistic forecast .", 
    "linenum": 8, 
    "matchl": "`` Both the Congress and the president , if those projections were way off , will face the same consequences , '' new House Budget Committee Chairman Leon Panetta , D-Calif. , said of the administration 's more optimistic forecast .", 
    "out-dataset_counterfactual_shuffle_num": 8, 
    "out-dataset_implicative_shuffle_num": 940, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 916534
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 9862, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "tell", 
    "in-dataset_counterfactual_shuffle_num": 2, 
    "in-dataset_implicative_shuffle_num": 1722, 
    "in-dataset_question_shuffle_num": 14573, 
    "inf_sentences_id": 700310, 
    "line": "How do vending machines tell if your dollar is a 1 or a 5 ?", 
    "linenum": 3862, 
    "matchl": "How do vending machines tell if your dollar is a 1 or a 5 ?", 
    "out-dataset_counterfactual_shuffle_num": 9, 
    "out-dataset_implicative_shuffle_num": 6889, 
    "out-dataset_question_shuffle_num": 43766, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 927890
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 387328, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_counterfactual_shuffle_num": 2, 
    "in-dataset_question_shuffle_num": 89818, 
    "inf_sentences_id": 387347, 
    "line": "And what if he rejects me ?", 
    "linenum": 387328, 
    "matchl": "And what if he rejects me ?", 
    "out-dataset_counterfactual_shuffle_num": 10, 
    "out-dataset_question_shuffle_num": 163602, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "counterfactual", 
      "question"
    ], 
    "ulf_sentences_id": 614606
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": ".+ (<wish>) .+", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 245782, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2600-0.txt", 
    "in-dataset_counterfactual_shuffle_num": 2, 
    "inf_sentences_id": 951684, 
    "line": "I wish success to your mission , \" and with his embroidered red mantle , his flowing feathers , and his glittering ornaments , he rejoined his suite who were respectfully awaiting him .", 
    "linenum": 16661, 
    "matchl": "I wish success to your mission , \" and with his embroidered red mantle , his flowing feathers , and his glittering ornaments , he rejoined his suite who were respectfully awaiting him .", 
    "out-dataset_counterfactual_shuffle_num": 11, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 1179264
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 945, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/132", 
    "implicative_pattern": "attempt", 
    "in-dataset_counterfactual_shuffle_num": 3, 
    "in-dataset_implicative_shuffle_num": 445, 
    "inf_sentences_id": 688241, 
    "line": "\" That means that if the offense deals with one part of the business , you do n't attempt to seize the whole business ; you attempt to seize assets related to the crime , \" he explained .", 
    "linenum": 9, 
    "matchl": "\" That means that if the offense deals with one part of the business , you do n't attempt to seize the whole business ; you attempt to seize assets related to the crime , \" he explained .", 
    "out-dataset_counterfactual_shuffle_num": 12, 
    "out-dataset_implicative_shuffle_num": 1780, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 915821
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 2579, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "implicative_pattern": "tell", 
    "in-dataset_counterfactual_shuffle_num": 3, 
    "in-dataset_implicative_shuffle_num": 2726, 
    "in-dataset_question_shuffle_num": 8899, 
    "inf_sentences_id": 693027, 
    "line": "How can anyone tell if a female had sexual intercourse ?", 
    "linenum": 1579, 
    "matchl": "How can anyone tell if a female had sexual intercourse ?", 
    "out-dataset_counterfactual_shuffle_num": 13, 
    "out-dataset_implicative_shuffle_num": 10167, 
    "out-dataset_question_shuffle_num": 26744, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 920607
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 150017, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_counterfactual_shuffle_num": 3, 
    "inf_sentences_id": 150034, 
    "line": "If he 's fluent in English , I 'll hire him .", 
    "linenum": 150017, 
    "matchl": "If he 's fluent in English , I 'll hire him .", 
    "out-dataset_counterfactual_shuffle_num": 14, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 377295
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>(were|had) .+", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 424377, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/514.txt.utf-8", 
    "implicative_pattern": "know", 
    "in-dataset_counterfactual_shuffle_num": 3, 
    "in-dataset_implicative_shuffle_num": 220362, 
    "inf_sentences_id": 1130281, 
    "line": "She would not ask him to stay at home , but felt injured because he did not know that she wanted him without being told , entirely forgetting the many evenings he had waited for her in vain .", 
    "linenum": 7538, 
    "matchl": "She would not ask him to stay at home , but felt injured because he did not know that she wanted him without being told , entirely forgetting the many evenings he had waited for her in vain .", 
    "out-dataset_counterfactual_shuffle_num": 15, 
    "out-dataset_implicative_shuffle_num": 446425, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1357861
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If)<mid>(was|were|had|<past>|<ppart>)<mid?>(<futr>) .+", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 3123, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/98", 
    "implicative_pattern": "make", 
    "in-dataset_counterfactual_shuffle_num": 4, 
    "in-dataset_implicative_shuffle_num": 597, 
    "inf_sentences_id": 690419, 
    "line": "`` If I thought this would make it difficult for the family , I would n't do it , '' he said .", 
    "linenum": 11, 
    "matchl": "`` If I thought this would make it difficult for the family , I would n't do it , '' he said .", 
    "out-dataset_counterfactual_shuffle_num": 16, 
    "out-dataset_implicative_shuffle_num": 2388, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 917999
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 5871, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "in-dataset_counterfactual_shuffle_num": 4, 
    "in-dataset_question_shuffle_num": 12958, 
    "inf_sentences_id": 696319, 
    "line": "What Broadway musical featured the song , `` If I were a rich man ? ''", 
    "linenum": 2871, 
    "matchl": "What Broadway musical featured the song , `` If I were a rich man ? ''", 
    "out-dataset_counterfactual_shuffle_num": 17, 
    "out-dataset_question_shuffle_num": 38921, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question"
    ], 
    "ulf_sentences_id": 923899
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 168445, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "touch", 
    "in-dataset_counterfactual_shuffle_num": 4, 
    "in-dataset_implicative_shuffle_num": 212755, 
    "inf_sentences_id": 168462, 
    "line": "My printer 's black ink is defective ; it bleeds across the page if I touch it with my finger .", 
    "linenum": 168445, 
    "matchl": "My printer 's black ink is defective ; it bleeds across the page if I touch it with my finger .", 
    "out-dataset_counterfactual_shuffle_num": 18, 
    "out-dataset_implicative_shuffle_num": 431210, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 395723
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>if<mid>(was|were|had|<past>|<ppart>) .+", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 51382, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/135-0.txt", 
    "in-dataset_counterfactual_shuffle_num": 4, 
    "inf_sentences_id": 757282, 
    "line": "It is true that he would have earned more if \" the _administration_ had not _robbed him_ . \"", 
    "linenum": 2955, 
    "matchl": "It is true that he would have earned more if \" the _administration_ had not _robbed him_ . \"", 
    "out-dataset_counterfactual_shuffle_num": 19, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 984862
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>if<mid>(was|were|had|<past>|<ppart>) .+", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 252, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/106", 
    "in-dataset_counterfactual_shuffle_num": 5, 
    "inf_sentences_id": 687548, 
    "line": "A 1985 DHEC study estimated that cleanup costs would approach $1 billion if all of the landfill 's holding cells were breached .", 
    "linenum": 36, 
    "matchl": "A 1985 DHEC study estimated that cleanup costs would approach $1 billion if all of the landfill 's holding cells were breached .", 
    "out-dataset_counterfactual_shuffle_num": 20, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 915128
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 4579, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "tell", 
    "in-dataset_counterfactual_shuffle_num": 5, 
    "in-dataset_implicative_shuffle_num": 1778, 
    "in-dataset_question_shuffle_num": 3035, 
    "inf_sentences_id": 695027, 
    "line": "How can anyone tell if a female had sexual intercourse ?", 
    "linenum": 1579, 
    "matchl": "How can anyone tell if a female had sexual intercourse ?", 
    "out-dataset_counterfactual_shuffle_num": 21, 
    "out-dataset_implicative_shuffle_num": 7113, 
    "out-dataset_question_shuffle_num": 9152, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 922607
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": ".+ (<wish>) .+", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 594487, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "finding", 
    "in-dataset_counterfactual_shuffle_num": 5, 
    "in-dataset_implicative_shuffle_num": 126655, 
    "inf_sentences_id": 594508, 
    "line": "I wish you luck in finding what you 're looking for .", 
    "linenum": 594487, 
    "matchl": "I wish you luck in finding what you 're looking for .", 
    "out-dataset_counterfactual_shuffle_num": 22, 
    "out-dataset_implicative_shuffle_num": 259010, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 821765
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 282865, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/28054-0.txt", 
    "implicative_pattern": "knew", 
    "in-dataset_counterfactual_shuffle_num": 5, 
    "in-dataset_implicative_shuffle_num": 84160, 
    "inf_sentences_id": 988767, 
    "line": "You knew nothing about it , Alyosha , you turned away from me ; if you passed me , you dropped your eyes .", 
    "linenum": 10440, 
    "matchl": "You knew nothing about it , Alyosha , you turned away from me ; if you passed me , you dropped your eyes .", 
    "out-dataset_counterfactual_shuffle_num": 23, 
    "out-dataset_implicative_shuffle_num": 174021, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1216347
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 14091, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "said", 
    "in-dataset_counterfactual_shuffle_num": 6, 
    "in-dataset_implicative_shuffle_num": 889, 
    "in-dataset_question_shuffle_num": 4073, 
    "inf_sentences_id": 704539, 
    "line": "What famous coach said `` if you can 't beat 'em in the alley , you can 't beat 'em on the ice '' ?", 
    "linenum": 4091, 
    "matchl": "What famous coach said `` if you can 't beat 'em in the alley , you can 't beat 'em on the ice '' ?", 
    "out-dataset_counterfactual_shuffle_num": 25, 
    "out-dataset_implicative_shuffle_num": 3557, 
    "out-dataset_question_shuffle_num": 12266, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 932119
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If)<mid>(was|were|had|<past>|<ppart>)<mid?>(<futr>) .+", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 456015, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_counterfactual_shuffle_num": 6, 
    "inf_sentences_id": 456035, 
    "line": "If the opposition were to win , it would not entail a radical departure from current policies .", 
    "linenum": 456015, 
    "matchl": "If the opposition were to win , it would not entail a radical departure from current policies .", 
    "out-dataset_counterfactual_shuffle_num": 26, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 683293
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 234144, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2600-0.txt", 
    "implicative_pattern": "said", 
    "in-dataset_counterfactual_shuffle_num": 6, 
    "in-dataset_implicative_shuffle_num": 142187, 
    "inf_sentences_id": 940046, 
    "line": "\" However , there will hardly be an engagement today , \" said Bagration as if to reassure Prince Andrew .", 
    "linenum": 5023, 
    "matchl": "\" However , there will hardly be an engagement today , \" said Bagration as if to reassure Prince Andrew .", 
    "out-dataset_counterfactual_shuffle_num": 27, 
    "out-dataset_implicative_shuffle_num": 290075, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1167626
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1960, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/51", 
    "in-dataset_counterfactual_shuffle_num": 7, 
    "inf_sentences_id": 689256, 
    "line": "But it does call into profound question his judgment , in particular his willingness to turn a blind eye to the background and beliefs of notorious colleagues if they share his anti-communism . ''", 
    "linenum": 15, 
    "matchl": "But it does call into profound question his judgment , in particular his willingness to turn a blind eye to the background and beliefs of notorious colleagues if they share his anti-communism . ''", 
    "out-dataset_counterfactual_shuffle_num": 28, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 916836
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 5468, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "seen", 
    "in-dataset_counterfactual_shuffle_num": 7, 
    "in-dataset_implicative_shuffle_num": 3709, 
    "in-dataset_question_shuffle_num": 1504, 
    "inf_sentences_id": 695916, 
    "line": "What U.S. vice-president once declared : `` If you 've seen one slum , you 've seen them all '' ?", 
    "linenum": 2468, 
    "matchl": "What U.S. vice-president once declared : `` If you 've seen one slum , you 've seen them all '' ?", 
    "out-dataset_counterfactual_shuffle_num": 29, 
    "out-dataset_implicative_shuffle_num": 13116, 
    "out-dataset_question_shuffle_num": 4559, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 923496
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": ".+ (<wish>) .+", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 189399, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "like", 
    "in-dataset_counterfactual_shuffle_num": 7, 
    "in-dataset_implicative_shuffle_num": 29836, 
    "inf_sentences_id": 189416, 
    "line": "I wish I had a butler like Tom .", 
    "linenum": 189399, 
    "matchl": "I wish I had a butler like Tom .", 
    "out-dataset_counterfactual_shuffle_num": 30, 
    "out-dataset_implicative_shuffle_num": 65372, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 416677
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If)<mid>(was|were|had|<past>|<ppart>)<mid?>(<futr>) .+", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 99965, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1400-0.txt", 
    "implicative_pattern": "said", 
    "in-dataset_counterfactual_shuffle_num": 7, 
    "in-dataset_implicative_shuffle_num": 243018, 
    "inf_sentences_id": 805865, 
    "line": "\" Dear Biddy , \" said I , \" you have the best husband in the whole world , and if you could have seen him by my bed you would have --", 
    "linenum": 9315, 
    "matchl": "\" Dear Biddy , \" said I , \" you have the best husband in the whole world , and if you could have seen him by my bed you would have --", 
    "out-dataset_counterfactual_shuffle_num": 31, 
    "out-dataset_implicative_shuffle_num": 491737, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1033445
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2657, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/8", 
    "in-dataset_counterfactual_shuffle_num": 8, 
    "inf_sentences_id": 689953, 
    "line": "If the debts are repaid , it could clear the way for Soviet bonds to be sold in the U.S .", 
    "linenum": 1, 
    "matchl": "If the debts are repaid , it could clear the way for Soviet bonds to be sold in the U.S .", 
    "out-dataset_counterfactual_shuffle_num": 32, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 917533
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 5830, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "determine", 
    "in-dataset_counterfactual_shuffle_num": 8, 
    "in-dataset_implicative_shuffle_num": 1807, 
    "in-dataset_question_shuffle_num": 835, 
    "inf_sentences_id": 696278, 
    "line": "How do you determine if a computer monitor has an SVGA adapter ?", 
    "linenum": 2830, 
    "matchl": "How do you determine if a computer monitor has an SVGA adapter ?", 
    "out-dataset_counterfactual_shuffle_num": 33, 
    "out-dataset_implicative_shuffle_num": 7229, 
    "out-dataset_question_shuffle_num": 2552, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 923858
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>if<mid>(was|were|had|<past>|<ppart>) .+", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 389077, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_counterfactual_shuffle_num": 8, 
    "inf_sentences_id": 389096, 
    "line": "It would be good if Tom did a little more exercise .", 
    "linenum": 389077, 
    "matchl": "It would be good if Tom did a little more exercise .", 
    "out-dataset_counterfactual_shuffle_num": 34, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 616355
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "(were|had|Were|Had)<end?>", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 285050, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/28054-0.txt", 
    "in-dataset_counterfactual_shuffle_num": 8, 
    "in-dataset_question_shuffle_num": 27472, 
    "inf_sentences_id": 990952, 
    "line": "Were you a cavalry officer ? \" put in Kalganov at once .", 
    "linenum": 12625, 
    "matchl": "Were you a cavalry officer ? \" put in Kalganov at once .", 
    "out-dataset_counterfactual_shuffle_num": 35, 
    "out-dataset_question_shuffle_num": 70197, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question"
    ], 
    "ulf_sentences_id": 1218532
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1774, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/45", 
    "implicative_pattern": "revealed", 
    "in-dataset_counterfactual_shuffle_num": 9, 
    "in-dataset_implicative_shuffle_num": 1588, 
    "inf_sentences_id": 689070, 
    "line": "Dibbley also kept mum about if and when any plea bargaining arrangements might be revealed .", 
    "linenum": 4, 
    "matchl": "Dibbley also kept mum about if and when any plea bargaining arrangements might be revealed .", 
    "out-dataset_counterfactual_shuffle_num": 36, 
    "out-dataset_implicative_shuffle_num": 6352, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 916650
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 2953, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "in-dataset_counterfactual_shuffle_num": 9, 
    "in-dataset_question_shuffle_num": 3791, 
    "inf_sentences_id": 693401, 
    "line": "How does light travel through the void of space if there is no medium for it to ` wave ' or ` pulse ' .", 
    "linenum": 1953, 
    "matchl": "How does light travel through the void of space if there is no medium for it to ` wave ' or ` pulse ' .", 
    "out-dataset_counterfactual_shuffle_num": 37, 
    "out-dataset_question_shuffle_num": 11420, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question"
    ], 
    "ulf_sentences_id": 920981
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 226779, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "drive", 
    "in-dataset_counterfactual_shuffle_num": 9, 
    "in-dataset_implicative_shuffle_num": 162046, 
    "inf_sentences_id": 226797, 
    "line": "You can use my car if you drive carefully .", 
    "linenum": 226779, 
    "matchl": "You can use my car if you drive carefully .", 
    "out-dataset_counterfactual_shuffle_num": 38, 
    "out-dataset_implicative_shuffle_num": 329792, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 454057
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If)<mid>(was|were|had|<past>|<ppart>)<mid?>(<futr>) .+", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 184813, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2097.txt.utf-8", 
    "in-dataset_counterfactual_shuffle_num": 9, 
    "inf_sentences_id": 890714, 
    "line": "Thus , if the rebels won he would have his money , but if the Company conquered his jewels would be saved to him .", 
    "linenum": 2506, 
    "matchl": "Thus , if the rebels won he would have his money , but if the Company conquered his jewels would be saved to him .", 
    "out-dataset_counterfactual_shuffle_num": 39, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 1118294
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 983, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/135", 
    "in-dataset_counterfactual_shuffle_num": 10, 
    "inf_sentences_id": 688279, 
    "line": "If I sell now , I 'll take a big loss . \"", 
    "linenum": 5, 
    "matchl": "If I sell now , I 'll take a big loss . \"", 
    "out-dataset_counterfactual_shuffle_num": 40, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 915859
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 12400, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "says", 
    "in-dataset_counterfactual_shuffle_num": 10, 
    "in-dataset_implicative_shuffle_num": 502, 
    "in-dataset_question_shuffle_num": 2941, 
    "inf_sentences_id": 702848, 
    "line": "Who says , `` If you don 't look good , we don 't look good '' ?", 
    "linenum": 2400, 
    "matchl": "Who says , `` If you don 't look good , we don 't look good '' ?", 
    "out-dataset_counterfactual_shuffle_num": 41, 
    "out-dataset_implicative_shuffle_num": 2009, 
    "out-dataset_question_shuffle_num": 8870, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 930428
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 407611, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "bored", 
    "in-dataset_counterfactual_shuffle_num": 10, 
    "in-dataset_implicative_shuffle_num": 190774, 
    "inf_sentences_id": 407631, 
    "line": "You 're going to be bored if you go .", 
    "linenum": 407611, 
    "matchl": "You 're going to be bored if you go .", 
    "out-dataset_counterfactual_shuffle_num": 42, 
    "out-dataset_implicative_shuffle_num": 387248, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 634889
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>(were|had) .+", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 106177, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1404.txt.utf-8", 
    "implicative_pattern": "claim", 
    "in-dataset_counterfactual_shuffle_num": 10, 
    "in-dataset_implicative_shuffle_num": 222365, 
    "inf_sentences_id": 812078, 
    "line": "They would contain various exceptions to powers not granted ; and , on this very account , would afford a colorable pretext to claim more than were granted .", 
    "linenum": 6091, 
    "matchl": "They would contain various exceptions to powers not granted ; and , on this very account , would afford a colorable pretext to claim more than were granted .", 
    "out-dataset_counterfactual_shuffle_num": 43, 
    "out-dataset_implicative_shuffle_num": 450431, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1039658
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>(were|had) .+", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 863, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/128", 
    "implicative_pattern": "like", 
    "in-dataset_counterfactual_shuffle_num": 11, 
    "in-dataset_implicative_shuffle_num": 591, 
    "inf_sentences_id": 688159, 
    "line": "\" I would like to have had them , \" he said .", 
    "linenum": 9, 
    "matchl": "\" I would like to have had them , \" he said .", 
    "out-dataset_counterfactual_shuffle_num": 44, 
    "out-dataset_implicative_shuffle_num": 2364, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 915739
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 9542, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "started", 
    "in-dataset_counterfactual_shuffle_num": 11, 
    "in-dataset_implicative_shuffle_num": 180, 
    "in-dataset_question_shuffle_num": 1349, 
    "inf_sentences_id": 699990, 
    "line": "Why is the universe flat , if it started by an explosion , shouldn 't it be a sphere ?", 
    "linenum": 3542, 
    "matchl": "Why is the universe flat , if it started by an explosion , shouldn 't it be a sphere ?", 
    "out-dataset_counterfactual_shuffle_num": 45, 
    "out-dataset_implicative_shuffle_num": 721, 
    "out-dataset_question_shuffle_num": 4094, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 927570
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 542071, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_counterfactual_shuffle_num": 11, 
    "inf_sentences_id": 542092, 
    "line": "If your wife cheated on you , thank God she only cheated on you and did not betray the country .", 
    "linenum": 542071, 
    "matchl": "If your wife cheated on you , thank God she only cheated on you and did not betray the country .", 
    "out-dataset_counterfactual_shuffle_num": 46, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 769349
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 55305, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/135-0.txt", 
    "implicative_pattern": "please", 
    "in-dataset_counterfactual_shuffle_num": 11, 
    "in-dataset_implicative_shuffle_num": 89236, 
    "inf_sentences_id": 761205, 
    "line": "\" Monsieur , \" said he , \" where is the court-house , if you please . \"", 
    "linenum": 6878, 
    "matchl": "\" Monsieur , \" said he , \" where is the court-house , if you please . \"", 
    "out-dataset_counterfactual_shuffle_num": 47, 
    "out-dataset_implicative_shuffle_num": 184173, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 988785
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1653, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/39", 
    "implicative_pattern": "make", 
    "in-dataset_counterfactual_shuffle_num": 12, 
    "in-dataset_implicative_shuffle_num": 1381, 
    "inf_sentences_id": 688949, 
    "line": "The numbers presented by the non-partisan congressional agency , if accurate , would make it even more difficult for Bush and Congress to meet the Gramm-Rudman balanced budget law 's 1990 deficit target of $100 billion .", 
    "linenum": 3, 
    "matchl": "The numbers presented by the non-partisan congressional agency , if accurate , would make it even more difficult for Bush and Congress to meet the Gramm-Rudman balanced budget law 's 1990 deficit target of $100 billion .", 
    "out-dataset_counterfactual_shuffle_num": 48, 
    "out-dataset_implicative_shuffle_num": 5524, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 916529
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": ".+ (<wish>) .+", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 8999, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "like", 
    "in-dataset_counterfactual_shuffle_num": 12, 
    "in-dataset_implicative_shuffle_num": 3517, 
    "in-dataset_question_shuffle_num": 6841, 
    "inf_sentences_id": 699447, 
    "line": "Who is the actress Bette Davis once said she wished she looked like ?", 
    "linenum": 2999, 
    "matchl": "Who is the actress Bette Davis once said she wished she looked like ?", 
    "out-dataset_counterfactual_shuffle_num": 49, 
    "out-dataset_implicative_shuffle_num": 12540, 
    "out-dataset_question_shuffle_num": 20570, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 927027
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 368194, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "want", 
    "in-dataset_counterfactual_shuffle_num": 12, 
    "in-dataset_implicative_shuffle_num": 10136, 
    "inf_sentences_id": 368213, 
    "line": "If you want it , you can have it .", 
    "linenum": 368194, 
    "matchl": "If you want it , you can have it .", 
    "out-dataset_counterfactual_shuffle_num": 50, 
    "out-dataset_implicative_shuffle_num": 25972, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 595472
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 104015, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1404.txt.utf-8", 
    "implicative_pattern": "doubted", 
    "in-dataset_counterfactual_shuffle_num": 12, 
    "in-dataset_implicative_shuffle_num": 103160, 
    "inf_sentences_id": 809916, 
    "line": "Estimating the negroes in the proportion of three fifths , it can scarcely be doubted that the population of the United States will by that time , if it does not already , amount to three millions .", 
    "linenum": 3929, 
    "matchl": "Estimating the negroes in the proportion of three fifths , it can scarcely be doubted that the population of the United States will by that time , if it does not already , amount to three millions .", 
    "out-dataset_counterfactual_shuffle_num": 51, 
    "out-dataset_implicative_shuffle_num": 212021, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1037496
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 725, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/122", 
    "implicative_pattern": "argue", 
    "in-dataset_counterfactual_shuffle_num": 13, 
    "in-dataset_implicative_shuffle_num": 545, 
    "inf_sentences_id": 688021, 
    "line": "Catching up with commercial competitors in retail banking and financial services , they argue , will be difficult , particularly if market conditions turn sour .", 
    "linenum": 5, 
    "matchl": "Catching up with commercial competitors in retail banking and financial services , they argue , will be difficult , particularly if market conditions turn sour .", 
    "out-dataset_counterfactual_shuffle_num": 52, 
    "out-dataset_implicative_shuffle_num": 2180, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 915601
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": ".+ (<wish>) .+", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 5999, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "like", 
    "in-dataset_counterfactual_shuffle_num": 13, 
    "in-dataset_implicative_shuffle_num": 1123, 
    "in-dataset_question_shuffle_num": 11034, 
    "inf_sentences_id": 696447, 
    "line": "Who is the actress Bette Davis once said she wished she looked like ?", 
    "linenum": 2999, 
    "matchl": "Who is the actress Bette Davis once said she wished she looked like ?", 
    "out-dataset_counterfactual_shuffle_num": 53, 
    "out-dataset_implicative_shuffle_num": 4493, 
    "out-dataset_question_shuffle_num": 33149, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 924027
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 566843, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "wants", 
    "in-dataset_counterfactual_shuffle_num": 13, 
    "in-dataset_implicative_shuffle_num": 105548, 
    "inf_sentences_id": 566864, 
    "line": "Tom can study in my office if he wants to .", 
    "linenum": 566843, 
    "matchl": "Tom can study in my office if he wants to .", 
    "out-dataset_counterfactual_shuffle_num": 54, 
    "out-dataset_implicative_shuffle_num": 216796, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 794121
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 355049, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/3600-0.txt", 
    "implicative_pattern": "stay", 
    "in-dataset_counterfactual_shuffle_num": 13, 
    "in-dataset_implicative_shuffle_num": 146188, 
    "in-dataset_question_shuffle_num": 55941, 
    "inf_sentences_id": 1060952, 
    "line": "[\" If that half of my soul were snatch away from me by an untimely stroke , why should the other stay ?", 
    "linenum": 2850, 
    "matchl": "[\" If that half of my soul were snatch away from me by an untimely stroke , why should the other stay ?", 
    "out-dataset_counterfactual_shuffle_num": 55, 
    "out-dataset_implicative_shuffle_num": 298077, 
    "out-dataset_question_shuffle_num": 127135, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1288532
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 3049, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/94", 
    "implicative_pattern": "fact", 
    "in-dataset_counterfactual_shuffle_num": 14, 
    "in-dataset_implicative_shuffle_num": 947, 
    "inf_sentences_id": 690345, 
    "line": "`` The fact is he never asked me to serve in his Cabinet and I do n't know if I would have or could have .", 
    "linenum": 28, 
    "matchl": "`` The fact is he never asked me to serve in his Cabinet and I do n't know if I would have or could have .", 
    "out-dataset_counterfactual_shuffle_num": 56, 
    "out-dataset_implicative_shuffle_num": 3788, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 917925
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 4953, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "in-dataset_counterfactual_shuffle_num": 14, 
    "in-dataset_question_shuffle_num": 13701, 
    "inf_sentences_id": 695401, 
    "line": "How does light travel through the void of space if there is no medium for it to ` wave ' or ` pulse ' .", 
    "linenum": 1953, 
    "matchl": "How does light travel through the void of space if there is no medium for it to ` wave ' or ` pulse ' .", 
    "out-dataset_counterfactual_shuffle_num": 57, 
    "out-dataset_question_shuffle_num": 41150, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question"
    ], 
    "ulf_sentences_id": 922981
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>if<mid>(was|were|had|<past>|<ppart>) .+", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 480668, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "make", 
    "in-dataset_counterfactual_shuffle_num": 14, 
    "in-dataset_implicative_shuffle_num": 50573, 
    "inf_sentences_id": 480688, 
    "line": "You 'd make her the happiest woman on earth if you did that .", 
    "linenum": 480668, 
    "matchl": "You 'd make her the happiest woman on earth if you did that .", 
    "out-dataset_counterfactual_shuffle_num": 58, 
    "out-dataset_implicative_shuffle_num": 106846, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 707946
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 491521, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/98-0.txt", 
    "in-dataset_counterfactual_shuffle_num": 14, 
    "inf_sentences_id": 1197425, 
    "line": "If it passed to me from you , to-morrow -- \"", 
    "linenum": 2286, 
    "matchl": "If it passed to me from you , to-morrow -- \"", 
    "out-dataset_counterfactual_shuffle_num": 59, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 1425005
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1355, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/25", 
    "implicative_pattern": "claim", 
    "in-dataset_counterfactual_shuffle_num": 15, 
    "in-dataset_implicative_shuffle_num": 191, 
    "inf_sentences_id": 688651, 
    "line": "Some of the more controversial and less-enforceable rules govern parking , including a requirement that the first car in a line of autos circling for a free space has claim to the next open spot - even if the driver has already passed it by .", 
    "linenum": 21, 
    "matchl": "Some of the more controversial and less-enforceable rules govern parking , including a requirement that the first car in a line of autos circling for a free space has claim to the next open spot - even if the driver has already passed it by .", 
    "out-dataset_counterfactual_shuffle_num": 60, 
    "out-dataset_implicative_shuffle_num": 764, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 916231
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 6700, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "in-dataset_counterfactual_shuffle_num": 15, 
    "in-dataset_question_shuffle_num": 13574, 
    "inf_sentences_id": 697148, 
    "line": "How far do you have to run if you hit a home run ?", 
    "linenum": 700, 
    "matchl": "How far do you have to run if you hit a home run ?", 
    "out-dataset_counterfactual_shuffle_num": 61, 
    "out-dataset_question_shuffle_num": 40769, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question"
    ], 
    "ulf_sentences_id": 924728
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 612475, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_counterfactual_shuffle_num": 15, 
    "inf_sentences_id": 612497, 
    "line": "If the devil is powerless , he sends his wife .", 
    "linenum": 612475, 
    "matchl": "If the devil is powerless , he sends his wife .", 
    "out-dataset_counterfactual_shuffle_num": 62, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 839753
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 17419, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1184-0.txt", 
    "implicative_pattern": "saw", 
    "in-dataset_counterfactual_shuffle_num": 15, 
    "in-dataset_implicative_shuffle_num": 78781, 
    "inf_sentences_id": 723319, 
    "line": "I saw a white figure , and as if to prevent my discrediting the testimony of only one of my senses , I heard my glass removed--the same which is there now on the table . \"", 
    "linenum": 15896, 
    "matchl": "I saw a white figure , and as if to prevent my discrediting the testimony of only one of my senses , I heard my glass removed--the same which is there now on the table . \"", 
    "out-dataset_counterfactual_shuffle_num": 63, 
    "out-dataset_implicative_shuffle_num": 163263, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 950899
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1326, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/24", 
    "implicative_pattern": "decline", 
    "in-dataset_counterfactual_shuffle_num": 16, 
    "in-dataset_implicative_shuffle_num": 644, 
    "inf_sentences_id": 688622, 
    "line": "Hull said that if 1989 corn production is at the low side of these projections farmers probably would see some decline in market prices in the 1989-90 season .", 
    "linenum": 13, 
    "matchl": "Hull said that if 1989 corn production is at the low side of these projections farmers probably would see some decline in market prices in the 1989-90 season .", 
    "out-dataset_counterfactual_shuffle_num": 64, 
    "out-dataset_implicative_shuffle_num": 2576, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 916202
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 12871, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_counterfactual_shuffle_num": 16, 
    "in-dataset_question_shuffle_num": 1814, 
    "inf_sentences_id": 703319, 
    "line": "What Broadway musical featured the song , `` If I were a rich man ? ''", 
    "linenum": 2871, 
    "matchl": "What Broadway musical featured the song , `` If I were a rich man ? ''", 
    "out-dataset_counterfactual_shuffle_num": 65, 
    "out-dataset_question_shuffle_num": 5489, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question"
    ], 
    "ulf_sentences_id": 930899
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>if<mid>(was|were|had|<past>|<ppart>) .+", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 335350, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "know", 
    "in-dataset_counterfactual_shuffle_num": 16, 
    "in-dataset_implicative_shuffle_num": 119573, 
    "inf_sentences_id": 335369, 
    "line": "I 'd know if you were lying .", 
    "linenum": 335350, 
    "matchl": "I 'd know if you were lying .", 
    "out-dataset_counterfactual_shuffle_num": 66, 
    "out-dataset_implicative_shuffle_num": 244846, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 562628
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 432565, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/730.txt.utf-8", 
    "implicative_pattern": "get", 
    "in-dataset_counterfactual_shuffle_num": 16, 
    "in-dataset_implicative_shuffle_num": 153281, 
    "inf_sentences_id": 1138469, 
    "line": "' Well , ' replied the undertaker , ' I was thinking that if I pay so much towards ' em , I 've a right to get as much out of ' em as I can , Mr. Bumble ; and so--I think I 'll take the boy myself . '", 
    "linenum": 481, 
    "matchl": "' Well , ' replied the undertaker , ' I was thinking that if I pay so much towards ' em , I 've a right to get as much out of ' em as I can , Mr. Bumble ; and so--I think I 'll take the boy myself . '", 
    "out-dataset_counterfactual_shuffle_num": 67, 
    "out-dataset_implicative_shuffle_num": 312263, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1366049
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 5109, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "tell", 
    "in-dataset_counterfactual_shuffle_num": 17, 
    "in-dataset_implicative_shuffle_num": 1726, 
    "in-dataset_question_shuffle_num": 13824, 
    "in-dataset_request_shuffle_num": 353, 
    "inf_sentences_id": 695557, 
    "line": "How can you tell if someone is lying ?", 
    "linenum": 2109, 
    "matchl": "How can you tell if someone is lying ?", 
    "out-dataset_counterfactual_shuffle_num": 69, 
    "out-dataset_implicative_shuffle_num": 6905, 
    "out-dataset_question_shuffle_num": 41519, 
    "out-dataset_request_shuffle_num": 1061, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "counterfactual", 
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 923137
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 436396, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_counterfactual_shuffle_num": 17, 
    "inf_sentences_id": 436416, 
    "line": "I 'm not sure if I 'm going to be able to be there on time .", 
    "linenum": 436396, 
    "matchl": "I 'm not sure if I 'm going to be able to be there on time .", 
    "out-dataset_counterfactual_shuffle_num": 70, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 663674
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>(were|had) .+", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 105498, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1404.txt.utf-8", 
    "implicative_pattern": "determine", 
    "in-dataset_counterfactual_shuffle_num": 17, 
    "in-dataset_implicative_shuffle_num": 200021, 
    "inf_sentences_id": 811399, 
    "line": "And as there would be a necessity for submitting each nomination to the judgment of an entire branch of the legislature , the circumstances attending an appointment , from the mode of conducting it , would naturally become matters of notoriety ; and the public would be at no loss to determine what part had been performed by the different actors .", 
    "linenum": 5412, 
    "matchl": "And as there would be a necessity for submitting each nomination to the judgment of an entire branch of the legislature , the circumstances attending an appointment , from the mode of conducting it , would naturally become matters of notoriety ; and the public would be at no loss to determine what part had been performed by the different actors .", 
    "out-dataset_counterfactual_shuffle_num": 71, 
    "out-dataset_implicative_shuffle_num": 405743, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1038979
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1332, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/24", 
    "implicative_pattern": "continue", 
    "in-dataset_counterfactual_shuffle_num": 18, 
    "in-dataset_implicative_shuffle_num": 1162, 
    "inf_sentences_id": 688628, 
    "line": "Soghum output `` is likely to rebound '' this year if yields are normal , although total use may continue to exceed production , Hull said .", 
    "linenum": 19, 
    "matchl": "Soghum output `` is likely to rebound '' this year if yields are normal , although total use may continue to exceed production , Hull said .", 
    "out-dataset_counterfactual_shuffle_num": 72, 
    "out-dataset_implicative_shuffle_num": 4648, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 916208
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "(were|had|Were|Had)<end?>", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 439496, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "see", 
    "in-dataset_counterfactual_shuffle_num": 18, 
    "in-dataset_implicative_shuffle_num": 59878, 
    "in-dataset_question_shuffle_num": 46934, 
    "inf_sentences_id": 439516, 
    "line": "Were you surprised to see Tom ?", 
    "linenum": 439496, 
    "matchl": "Were you surprised to see Tom ?", 
    "out-dataset_counterfactual_shuffle_num": 74, 
    "out-dataset_implicative_shuffle_num": 125456, 
    "out-dataset_question_shuffle_num": 109120, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 666774
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>(were|had) .+", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 228160, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2591-0.txt", 
    "implicative_pattern": "make", 
    "in-dataset_counterfactual_shuffle_num": 18, 
    "in-dataset_implicative_shuffle_num": 79258, 
    "inf_sentences_id": 934062, 
    "line": "The time soon came , when the eldest brother thought that he would make haste to go to the princess , and say that he was the one who had set her free , and that he should have her for his wife , and the kingdom with her .", 
    "linenum": 3338, 
    "matchl": "The time soon came , when the eldest brother thought that he would make haste to go to the princess , and say that he was the one who had set her free , and that he should have her for his wife , and the kingdom with her .", 
    "out-dataset_counterfactual_shuffle_num": 75, 
    "out-dataset_implicative_shuffle_num": 164217, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1161642
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1687, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/40", 
    "implicative_pattern": "forget", 
    "in-dataset_counterfactual_shuffle_num": 19, 
    "in-dataset_implicative_shuffle_num": 1941, 
    "inf_sentences_id": 688983, 
    "line": "`` If we forget , the world forgets , '' said his sister , Brenda Gillham , who stood outside the city hall with three other family members during Wednesday 's vigil .", 
    "linenum": 2, 
    "matchl": "`` If we forget , the world forgets , '' said his sister , Brenda Gillham , who stood outside the city hall with three other family members during Wednesday 's vigil .", 
    "out-dataset_counterfactual_shuffle_num": 76, 
    "out-dataset_implicative_shuffle_num": 7764, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 916563
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 7953, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "in-dataset_counterfactual_shuffle_num": 19, 
    "in-dataset_question_shuffle_num": 406, 
    "inf_sentences_id": 698401, 
    "line": "How does light travel through the void of space if there is no medium for it to ` wave ' or ` pulse ' .", 
    "linenum": 1953, 
    "matchl": "How does light travel through the void of space if there is no medium for it to ` wave ' or ` pulse ' .", 
    "out-dataset_counterfactual_shuffle_num": 77, 
    "out-dataset_question_shuffle_num": 1265, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question"
    ], 
    "ulf_sentences_id": 925981
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 533507, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "mind", 
    "in-dataset_counterfactual_shuffle_num": 19, 
    "in-dataset_implicative_shuffle_num": 188868, 
    "in-dataset_question_shuffle_num": 39130, 
    "in-dataset_request_shuffle_num": 7757, 
    "inf_sentences_id": 533528, 
    "line": "Would you mind if I ask why not ?", 
    "linenum": 533507, 
    "matchl": "Would you mind if I ask why not ?", 
    "out-dataset_counterfactual_shuffle_num": 78, 
    "out-dataset_implicative_shuffle_num": 383436, 
    "out-dataset_question_shuffle_num": 93512, 
    "out-dataset_request_shuffle_num": 11098, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "counterfactual", 
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 760785
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 177859, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/205-0.txt", 
    "implicative_pattern": "find", 
    "in-dataset_counterfactual_shuffle_num": 19, 
    "in-dataset_implicative_shuffle_num": 173587, 
    "inf_sentences_id": 883760, 
    "line": "I find that even so long ago as 1792 , in a \" Topographical Description of the Town of Concord , \" by one of its citizens , in the Collections of the Massachusetts Historical Society , the author , after speaking of Walden and White Ponds , adds , \" In the middle of the latter may be seen , when the water is very low , a tree which appears as if it grew in the place where it now stands , although the roots are fifty feet below the surface of the water ; the top of this tree is broken off , and at that place measures fourteen inches in diameter . \"", 
    "linenum": 2243, 
    "matchl": "I find that even so long ago as 1792 , in a \" Topographical Description of the Town of Concord , \" by one of its citizens , in the Collections of the Massachusetts Historical Society , the author , after speaking of Walden and White Ponds , adds , \" In the middle of the latter may be seen , when the water is very low , a tree which appears as if it grew in the place where it now stands , although the roots are fifty feet below the surface of the water ; the top of this tree is broken off , and at that place measures fourteen inches in diameter . \"", 
    "out-dataset_counterfactual_shuffle_num": 79, 
    "out-dataset_implicative_shuffle_num": 352875, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1111340
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1813, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/46", 
    "implicative_pattern": "refuse", 
    "in-dataset_counterfactual_shuffle_num": 20, 
    "in-dataset_implicative_shuffle_num": 1444, 
    "inf_sentences_id": 689109, 
    "line": "`` If we refuse and reject negotiations with the Russians , we will be blamed by the world , '' Mojaddidi said .", 
    "linenum": 12, 
    "matchl": "`` If we refuse and reject negotiations with the Russians , we will be blamed by the world , '' Mojaddidi said .", 
    "out-dataset_counterfactual_shuffle_num": 80, 
    "out-dataset_implicative_shuffle_num": 5776, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 916689
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 8734, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "in-dataset_counterfactual_shuffle_num": 20, 
    "in-dataset_question_shuffle_num": 9116, 
    "inf_sentences_id": 699182, 
    "line": "What month were you born in if your birthstone is sardonyx ?", 
    "linenum": 2734, 
    "matchl": "What month were you born in if your birthstone is sardonyx ?", 
    "out-dataset_counterfactual_shuffle_num": 81, 
    "out-dataset_question_shuffle_num": 27395, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question"
    ], 
    "ulf_sentences_id": 926762
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 221008, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "succeeded", 
    "in-dataset_counterfactual_shuffle_num": 20, 
    "in-dataset_implicative_shuffle_num": 137848, 
    "inf_sentences_id": 221026, 
    "line": "If he had worked harder , he could have succeeded .", 
    "linenum": 221008, 
    "matchl": "If he had worked harder , he could have succeeded .", 
    "out-dataset_counterfactual_shuffle_num": 82, 
    "out-dataset_implicative_shuffle_num": 281396, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 448286
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If)<mid>(was|were|had|<past>|<ppart>)<mid?>(<futr>) .+", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 473255, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/815.txt.utf-8", 
    "implicative_pattern": "like", 
    "in-dataset_counterfactual_shuffle_num": 20, 
    "in-dataset_implicative_shuffle_num": 164407, 
    "inf_sentences_id": 1179159, 
    "line": "[ Footnote u : This last regulation was laid down by the founders of the settlement ; they apprehended that a state of things might arise in Africa similar to that which exists on the frontiers of the United States , and that if the negroes , like the Indians , were brought into collision with a people more enlightened than themselves , they would be destroyed before they could be civilized .]", 
    "linenum": 5377, 
    "matchl": "[ Footnote u : This last regulation was laid down by the founders of the settlement ; they apprehended that a state of things might arise in Africa similar to that which exists on the frontiers of the United States , and that if the negroes , like the Indians , were brought into collision with a people more enlightened than themselves , they would be destroyed before they could be civilized .]", 
    "out-dataset_counterfactual_shuffle_num": 83, 
    "out-dataset_implicative_shuffle_num": 334515, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1406739
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>if<mid>(was|were|had|<past>|<ppart>) .+", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2197, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/63", 
    "implicative_pattern": "claiming", 
    "in-dataset_counterfactual_shuffle_num": 21, 
    "in-dataset_implicative_shuffle_num": 797, 
    "inf_sentences_id": 689493, 
    "line": "His whereabouts were unknown until he applied for refugee status in Montreal sometime before Jan. 1 , claiming that his life would be in danger if he was forced to return to the Soviet Union , the Canadian Broadcast Corp. reported .", 
    "linenum": 2, 
    "matchl": "His whereabouts were unknown until he applied for refugee status in Montreal sometime before Jan. 1 , claiming that his life would be in danger if he was forced to return to the Soviet Union , the Canadian Broadcast Corp. reported .", 
    "out-dataset_counterfactual_shuffle_num": 84, 
    "out-dataset_implicative_shuffle_num": 3188, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 917073
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 8830, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "determine", 
    "in-dataset_counterfactual_shuffle_num": 21, 
    "in-dataset_implicative_shuffle_num": 77, 
    "in-dataset_question_shuffle_num": 5181, 
    "inf_sentences_id": 699278, 
    "line": "How do you determine if a computer monitor has an SVGA adapter ?", 
    "linenum": 2830, 
    "matchl": "How do you determine if a computer monitor has an SVGA adapter ?", 
    "out-dataset_counterfactual_shuffle_num": 85, 
    "out-dataset_implicative_shuffle_num": 309, 
    "out-dataset_question_shuffle_num": 15590, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 926858
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If)<mid>(was|were|had|<past>|<ppart>)<mid?>(<futr>) .+", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 96858, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_counterfactual_shuffle_num": 21, 
    "inf_sentences_id": 96874, 
    "line": "If you were to hear him speak French , you would take him for a Frenchman .", 
    "linenum": 96858, 
    "matchl": "If you were to hear him speak French , you would take him for a Frenchman .", 
    "out-dataset_counterfactual_shuffle_num": 86, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 324136
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 121632, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/158-0.txt", 
    "in-dataset_counterfactual_shuffle_num": 21, 
    "inf_sentences_id": 827533, 
    "line": "He will connect himself well if he can . \"", 
    "linenum": 785, 
    "matchl": "He will connect himself well if he can . \"", 
    "out-dataset_counterfactual_shuffle_num": 87, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 1055113
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>if<mid>(was|were|had|<past>|<ppart>) .+", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2714, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/81", 
    "in-dataset_counterfactual_shuffle_num": 22, 
    "inf_sentences_id": 690010, 
    "line": "`` ... He threatened that he would kill John Holmes ' family and he would kill him if he did n't take him to the home of the people who robbed him . ''", 
    "linenum": 11, 
    "matchl": "`` ... He threatened that he would kill John Holmes ' family and he would kill him if he did n't take him to the home of the people who robbed him . ''", 
    "out-dataset_counterfactual_shuffle_num": 88, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 917590
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 7659, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_counterfactual_shuffle_num": 22, 
    "in-dataset_implicative_shuffle_num": 2913, 
    "in-dataset_question_shuffle_num": 13577, 
    "inf_sentences_id": 698107, 
    "line": "How long after intercourse does it take to find out if you are pregnant ?", 
    "linenum": 1659, 
    "matchl": "How long after intercourse does it take to find out if you are pregnant ?", 
    "out-dataset_counterfactual_shuffle_num": 89, 
    "out-dataset_implicative_shuffle_num": 10728, 
    "out-dataset_question_shuffle_num": 40778, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 925687
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 15427, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "make", 
    "in-dataset_counterfactual_shuffle_num": 22, 
    "in-dataset_implicative_shuffle_num": 279680, 
    "inf_sentences_id": 15443, 
    "line": "If you are to do it , you must make a good start .", 
    "linenum": 15427, 
    "matchl": "If you are to do it , you must make a good start .", 
    "out-dataset_counterfactual_shuffle_num": 90, 
    "out-dataset_implicative_shuffle_num": 546026, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 242705
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 426628, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/5200.txt.utf-8", 
    "implicative_pattern": "stay", 
    "in-dataset_counterfactual_shuffle_num": 22, 
    "in-dataset_implicative_shuffle_num": 100156, 
    "inf_sentences_id": 1132532, 
    "line": "So now Gregor was shut out from his mother , who , because of him , might be near to death ; he could not open the door if he did not want to chase his sister away , and she had to stay with his mother ; there was nothing for him to do but wait ; and , oppressed with anxiety and self-reproach , he began to crawl about , he crawled over everything , walls , furniture , ceiling , and finally in his confusion as the whole room began to spin around him he fell down into the middle of the dinner table .", 
    "linenum": 477, 
    "matchl": "So now Gregor was shut out from his mother , who , because of him , might be near to death ; he could not open the door if he did not want to chase his sister away , and she had to stay with his mother ; there was nothing for him to do but wait ; and , oppressed with anxiety and self-reproach , he began to crawl about , he crawled over everything , walls , furniture , ceiling , and finally in his confusion as the whole room began to spin around him he fell down into the middle of the dinner table .", 
    "out-dataset_counterfactual_shuffle_num": 91, 
    "out-dataset_implicative_shuffle_num": 206013, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1360112
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1750, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/44", 
    "implicative_pattern": "added", 
    "in-dataset_counterfactual_shuffle_num": 23, 
    "in-dataset_implicative_shuffle_num": 1098, 
    "inf_sentences_id": 689046, 
    "line": "The information is useful as an indicator of trends , even if `` it is not a measure of actual consumption or the quantity ingested '' by consumers , the report added .", 
    "linenum": 6, 
    "matchl": "The information is useful as an indicator of trends , even if `` it is not a measure of actual consumption or the quantity ingested '' by consumers , the report added .", 
    "out-dataset_counterfactual_shuffle_num": 92, 
    "out-dataset_implicative_shuffle_num": 4392, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 916626
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 11953, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_counterfactual_shuffle_num": 23, 
    "in-dataset_question_shuffle_num": 10706, 
    "inf_sentences_id": 702401, 
    "line": "How does light travel through the void of space if there is no medium for it to ` wave ' or ` pulse ' .", 
    "linenum": 1953, 
    "matchl": "How does light travel through the void of space if there is no medium for it to ` wave ' or ` pulse ' .", 
    "out-dataset_counterfactual_shuffle_num": 93, 
    "out-dataset_question_shuffle_num": 32165, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question"
    ], 
    "ulf_sentences_id": 929981
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 216210, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_counterfactual_shuffle_num": 23, 
    "in-dataset_question_shuffle_num": 99311, 
    "in-dataset_request_shuffle_num": 4305, 
    "inf_sentences_id": 216228, 
    "line": "Where would you go if you could time travel ?", 
    "linenum": 216210, 
    "matchl": "Where would you go if you could time travel ?", 
    "out-dataset_counterfactual_shuffle_num": 94, 
    "out-dataset_question_shuffle_num": 173095, 
    "out-dataset_request_shuffle_num": 7646, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "counterfactual", 
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 443488
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If)<mid>(was|were|had|<past>|<ppart>)<mid?>(<futr>) .+", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 360298, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/3600-0.txt", 
    "implicative_pattern": "make", 
    "in-dataset_counterfactual_shuffle_num": 23, 
    "in-dataset_implicative_shuffle_num": 87639, 
    "inf_sentences_id": 1066201, 
    "line": "That cruel Roman Emperor would say of his prisoners , that he would make them feel death , and if any one killed himself in prison , \" That fellow has made an escape from me \"; he would prolong death and make it felt by torments :", 
    "linenum": 8099, 
    "matchl": "That cruel Roman Emperor would say of his prisoners , that he would make them feel death , and if any one killed himself in prison , \" That fellow has made an escape from me \"; he would prolong death and make it felt by torments :", 
    "out-dataset_counterfactual_shuffle_num": 95, 
    "out-dataset_implicative_shuffle_num": 180979, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1293781
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 3016, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/93", 
    "implicative_pattern": "said", 
    "in-dataset_counterfactual_shuffle_num": 24, 
    "in-dataset_implicative_shuffle_num": 553, 
    "inf_sentences_id": 690312, 
    "line": "One investigator , speaking on condition of anonymity , said it was not clear if the Mafia targeted Contorno 's relatives out of pure revenge or because they were suspected of being his own informers .", 
    "linenum": 7, 
    "matchl": "One investigator , speaking on condition of anonymity , said it was not clear if the Mafia targeted Contorno 's relatives out of pure revenge or because they were suspected of being his own informers .", 
    "out-dataset_counterfactual_shuffle_num": 96, 
    "out-dataset_implicative_shuffle_num": 2212, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 917892
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 5400, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "says", 
    "in-dataset_counterfactual_shuffle_num": 24, 
    "in-dataset_implicative_shuffle_num": 2355, 
    "in-dataset_question_shuffle_num": 14785, 
    "inf_sentences_id": 695848, 
    "line": "Who says , `` If you don 't look good , we don 't look good '' ?", 
    "linenum": 2400, 
    "matchl": "Who says , `` If you don 't look good , we don 't look good '' ?", 
    "out-dataset_counterfactual_shuffle_num": 97, 
    "out-dataset_implicative_shuffle_num": 9054, 
    "out-dataset_question_shuffle_num": 44402, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 923428
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 203295, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_counterfactual_shuffle_num": 24, 
    "inf_sentences_id": 203313, 
    "line": "If you go too close , you run the risk of being electrocuted .", 
    "linenum": 203295, 
    "matchl": "If you go too close , you run the risk of being electrocuted .", 
    "out-dataset_counterfactual_shuffle_num": 98, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 430573
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 274486, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/28054-0.txt", 
    "in-dataset_counterfactual_shuffle_num": 24, 
    "inf_sentences_id": 980388, 
    "line": "If that 's all , you 've reassured me .", 
    "linenum": 2061, 
    "matchl": "If that 's all , you 've reassured me .", 
    "out-dataset_counterfactual_shuffle_num": 99, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 1207968
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 3150, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/99", 
    "implicative_pattern": "said", 
    "in-dataset_counterfactual_shuffle_num": 25, 
    "in-dataset_implicative_shuffle_num": 1122, 
    "inf_sentences_id": 690446, 
    "line": "`` If the president-elect and Congress ca n't solve this problem , then we probably would be brought back into action , '' Lewis said .", 
    "linenum": 16, 
    "matchl": "`` If the president-elect and Congress ca n't solve this problem , then we probably would be brought back into action , '' Lewis said .", 
    "out-dataset_counterfactual_shuffle_num": 100, 
    "out-dataset_implicative_shuffle_num": 4488, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 918026
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>if<mid>(was|were|had|<past>|<ppart>) .+", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 5310, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "truth", 
    "in-dataset_counterfactual_shuffle_num": 25, 
    "in-dataset_implicative_shuffle_num": 3550, 
    "in-dataset_question_shuffle_num": 10328, 
    "inf_sentences_id": 695758, 
    "line": "Who said : `` The victor will never be asked if he told the truth '' ?", 
    "linenum": 2310, 
    "matchl": "Who said : `` The victor will never be asked if he told the truth '' ?", 
    "out-dataset_counterfactual_shuffle_num": 101, 
    "out-dataset_implicative_shuffle_num": 12639, 
    "out-dataset_question_shuffle_num": 31031, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 923338
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 385508, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_counterfactual_shuffle_num": 25, 
    "inf_sentences_id": 385527, 
    "line": "If we did n't satisfy your expectations , that 's your problem .", 
    "linenum": 385508, 
    "matchl": "If we did n't satisfy your expectations , that 's your problem .", 
    "out-dataset_counterfactual_shuffle_num": 102, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 612786
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If)<mid>(was|were|had|<past>|<ppart>)<mid?>(<futr>) .+", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 400812, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/4363.txt.utf-8", 
    "in-dataset_counterfactual_shuffle_num": 25, 
    "inf_sentences_id": 1106716, 
    "line": "Since in the majority of cases there has only been exercise of will when the effect of the command--consequently obedience , and therefore action--was to be EXPECTED , the APPEARANCE has translated itself into the sentiment , as if there were a NECESSITY OF EFFECT ; in a word , he who wills believes with a fair amount of certainty that will and action are somehow one ; he ascribes the success , the carrying out of the willing , to the will itself , and thereby enjoys an increase of the sensation of power which accompanies all success .", 
    "linenum": 202, 
    "matchl": "Since in the majority of cases there has only been exercise of will when the effect of the command--consequently obedience , and therefore action--was to be EXPECTED , the APPEARANCE has translated itself into the sentiment , as if there were a NECESSITY OF EFFECT ; in a word , he who wills believes with a fair amount of certainty that will and action are somehow one ; he ascribes the success , the carrying out of the willing , to the will itself , and thereby enjoys an increase of the sensation of power which accompanies all success .", 
    "out-dataset_counterfactual_shuffle_num": 103, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 1334296
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1881, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/49", 
    "implicative_pattern": "got", 
    "in-dataset_counterfactual_shuffle_num": 26, 
    "in-dataset_implicative_shuffle_num": 1570, 
    "inf_sentences_id": 689177, 
    "line": "At one time , U.S. diplomats got into hot water if they clinked teacups with members of the PLO , but now the State Department has switched signals .", 
    "linenum": 0, 
    "matchl": "At one time , U.S. diplomats got into hot water if they clinked teacups with members of the PLO , but now the State Department has switched signals .", 
    "out-dataset_counterfactual_shuffle_num": 104, 
    "out-dataset_implicative_shuffle_num": 6280, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 916757
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 12897, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_counterfactual_shuffle_num": 26, 
    "in-dataset_question_shuffle_num": 11948, 
    "inf_sentences_id": 703345, 
    "line": "What are the chances of pregnacy if the penis does not penetrate the vagina ?", 
    "linenum": 2897, 
    "matchl": "What are the chances of pregnacy if the penis does not penetrate the vagina ?", 
    "out-dataset_counterfactual_shuffle_num": 105, 
    "out-dataset_question_shuffle_num": 35891, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question"
    ], 
    "ulf_sentences_id": 930925
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 406880, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "attack", 
    "in-dataset_counterfactual_shuffle_num": 26, 
    "in-dataset_implicative_shuffle_num": 121826, 
    "inf_sentences_id": 406900, 
    "line": "Zelda , everyone is under attack by the evil forces of the birds ! I 'm going to Gamelon to attack. If you do n't hear from me in a month , send Link .", 
    "linenum": 406880, 
    "matchl": "Zelda , everyone is under attack by the evil forces of the birds ! I 'm going to Gamelon to attack. If you do n't hear from me in a month , send Link .", 
    "out-dataset_counterfactual_shuffle_num": 106, 
    "out-dataset_implicative_shuffle_num": 249352, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 634158
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 102437, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1404.txt.utf-8", 
    "implicative_pattern": "respecting", 
    "in-dataset_counterfactual_shuffle_num": 26, 
    "in-dataset_implicative_shuffle_num": 197633, 
    "in-dataset_question_shuffle_num": 10049, 
    "inf_sentences_id": 808338, 
    "line": "If any question is depending in a State legislature respecting one of the counties , which demands a knowledge of local details , how is it acquired ?", 
    "linenum": 2351, 
    "matchl": "If any question is depending in a State legislature respecting one of the counties , which demands a knowledge of local details , how is it acquired ?", 
    "out-dataset_counterfactual_shuffle_num": 107, 
    "out-dataset_implicative_shuffle_num": 400967, 
    "out-dataset_question_shuffle_num": 30196, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 1035918
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 3676, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_counterfactual_shuffle_num": 27, 
    "in-dataset_implicative_shuffle_num": 1059, 
    "in-dataset_question_shuffle_num": 13132, 
    "in-dataset_request_shuffle_num": 241, 
    "inf_sentences_id": 694124, 
    "line": "How can I find a phone number of someone if I only know their email address ?", 
    "linenum": 676, 
    "matchl": "How can I find a phone number of someone if I only know their email address ?", 
    "out-dataset_counterfactual_shuffle_num": 109, 
    "out-dataset_implicative_shuffle_num": 4237, 
    "out-dataset_question_shuffle_num": 39443, 
    "out-dataset_request_shuffle_num": 725, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "counterfactual", 
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 921704
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 265977, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "know", 
    "in-dataset_counterfactual_shuffle_num": 27, 
    "in-dataset_implicative_shuffle_num": 159956, 
    "inf_sentences_id": 265995, 
    "line": "Tom wants to know if it hurts .", 
    "linenum": 265977, 
    "matchl": "Tom wants to know if it hurts .", 
    "out-dataset_counterfactual_shuffle_num": 110, 
    "out-dataset_implicative_shuffle_num": 325612, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 493255
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 321694, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/30360.txt.utf-8", 
    "in-dataset_counterfactual_shuffle_num": 27, 
    "inf_sentences_id": 1027597, 
    "line": "\" Well I might if I liked,\"--but I did not .", 
    "linenum": 9423, 
    "matchl": "\" Well I might if I liked,\"--but I did not .", 
    "out-dataset_counterfactual_shuffle_num": 111, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 1255177
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>if<mid>(was|were|had|<past>|<ppart>) .+", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 815, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/125", 
    "implicative_pattern": "make", 
    "in-dataset_counterfactual_shuffle_num": 28, 
    "in-dataset_implicative_shuffle_num": 1737, 
    "inf_sentences_id": 688111, 
    "line": "Lodestar Group said it will make a $6-a-share offer for the remaining Kinder-Care Learning Center common stock if it acquires a majority of the company 's shares in a pending rights offering by Kinder-Care Learning Center 's parent , Kinder-Care Inc .", 
    "linenum": 25, 
    "matchl": "Lodestar Group said it will make a $6-a-share offer for the remaining Kinder-Care Learning Center common stock if it acquires a majority of the company 's shares in a pending rights offering by Kinder-Care Learning Center 's parent , Kinder-Care Inc .", 
    "out-dataset_counterfactual_shuffle_num": 112, 
    "out-dataset_implicative_shuffle_num": 6948, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 915691
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 12468, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "seen", 
    "in-dataset_counterfactual_shuffle_num": 28, 
    "in-dataset_implicative_shuffle_num": 1736, 
    "in-dataset_question_shuffle_num": 6132, 
    "inf_sentences_id": 702916, 
    "line": "What U.S. vice-president once declared : `` If you 've seen one slum , you 've seen them all '' ?", 
    "linenum": 2468, 
    "matchl": "What U.S. vice-president once declared : `` If you 've seen one slum , you 've seen them all '' ?", 
    "out-dataset_counterfactual_shuffle_num": 113, 
    "out-dataset_implicative_shuffle_num": 6945, 
    "out-dataset_question_shuffle_num": 18443, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 930496
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>(were|had) .+", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 143794, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "daring", 
    "in-dataset_counterfactual_shuffle_num": 28, 
    "in-dataset_implicative_shuffle_num": 37966, 
    "inf_sentences_id": 143811, 
    "line": "The same energy of character which renders a man a daring villain would have rendered him useful to society , had that society been well organized .", 
    "linenum": 143794, 
    "matchl": "The same energy of character which renders a man a daring villain would have rendered him useful to society , had that society been well organized .", 
    "out-dataset_counterfactual_shuffle_num": 114, 
    "out-dataset_implicative_shuffle_num": 81632, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 371072
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>if<mid>(was|were|had|<past>|<ppart>) .+", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 90791, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1400-0.txt", 
    "implicative_pattern": "tell", 
    "in-dataset_counterfactual_shuffle_num": 28, 
    "in-dataset_implicative_shuffle_num": 149234, 
    "inf_sentences_id": 796691, 
    "line": "\" Tell me directly what you 've been doing to wear me away with fret and fright and worrit , or I 'd have you out of that corner if you was fifty Pips , and he was five hundred Gargerys . \"", 
    "linenum": 141, 
    "matchl": "\" Tell me directly what you 've been doing to wear me away with fret and fright and worrit , or I 'd have you out of that corner if you was fifty Pips , and he was five hundred Gargerys . \"", 
    "out-dataset_counterfactual_shuffle_num": 115, 
    "out-dataset_implicative_shuffle_num": 304169, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1024271
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If)<mid>(was|were|had|<past>|<ppart>)<mid?>(<futr>) .+", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1660, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/39", 
    "implicative_pattern": "make", 
    "in-dataset_counterfactual_shuffle_num": 29, 
    "in-dataset_implicative_shuffle_num": 1618, 
    "inf_sentences_id": 688956, 
    "line": "Even if the administration 's forecast is accurate , many legislators have said that Bush 's repeated campaign promises to forego new taxes will make it hard to avoid Gramm-Rudman 's automatic cuts .", 
    "linenum": 10, 
    "matchl": "Even if the administration 's forecast is accurate , many legislators have said that Bush 's repeated campaign promises to forego new taxes will make it hard to avoid Gramm-Rudman 's automatic cuts .", 
    "out-dataset_counterfactual_shuffle_num": 116, 
    "out-dataset_implicative_shuffle_num": 6472, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 916536
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 8254, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "in-dataset_counterfactual_shuffle_num": 29, 
    "in-dataset_question_shuffle_num": 12394, 
    "inf_sentences_id": 698702, 
    "line": "Why is it called `` hamburger '' if there is no ham in it ?", 
    "linenum": 2254, 
    "matchl": "Why is it called `` hamburger '' if there is no ham in it ?", 
    "out-dataset_counterfactual_shuffle_num": 117, 
    "out-dataset_question_shuffle_num": 37229, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question"
    ], 
    "ulf_sentences_id": 926282
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If)<mid>(was|were|had|<past>|<ppart>)<mid?>(<futr>) .+", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 136773, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "surprise", 
    "in-dataset_counterfactual_shuffle_num": 29, 
    "in-dataset_implicative_shuffle_num": 186649, 
    "in-dataset_question_shuffle_num": 90835, 
    "inf_sentences_id": 136790, 
    "line": "If you cut class or something...it would n't surprise you if it showed up on your report card , would it ?", 
    "linenum": 136773, 
    "matchl": "If you cut class or something...it would n't surprise you if it showed up on your report card , would it ?", 
    "out-dataset_counterfactual_shuffle_num": 118, 
    "out-dataset_implicative_shuffle_num": 378998, 
    "out-dataset_question_shuffle_num": 164619, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 364051
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 295384, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/28054-0.txt", 
    "implicative_pattern": "told", 
    "in-dataset_counterfactual_shuffle_num": 29, 
    "in-dataset_implicative_shuffle_num": 223753, 
    "inf_sentences_id": 1001286, 
    "line": "He told me that the envelope contained the details of the escape , and that if he died or was taken dangerously ill , I was to save Mitya alone .", 
    "linenum": 22959, 
    "matchl": "He told me that the envelope contained the details of the escape , and that if he died or was taken dangerously ill , I was to save Mitya alone .", 
    "out-dataset_counterfactual_shuffle_num": 119, 
    "out-dataset_implicative_shuffle_num": 453207, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1228866
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2299, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/68", 
    "implicative_pattern": "fail", 
    "in-dataset_counterfactual_shuffle_num": 30, 
    "in-dataset_implicative_shuffle_num": 1145, 
    "inf_sentences_id": 689595, 
    "line": "Official trade unions have pledged to strike and mount other protests if wage and social reforms fail to offset price increases planned by the government , a union newspaper said Saturday .", 
    "linenum": 0, 
    "matchl": "Official trade unions have pledged to strike and mount other protests if wage and social reforms fail to offset price increases planned by the government , a union newspaper said Saturday .", 
    "out-dataset_counterfactual_shuffle_num": 120, 
    "out-dataset_implicative_shuffle_num": 4580, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 917175
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 10676, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "find", 
    "in-dataset_counterfactual_shuffle_num": 30, 
    "in-dataset_implicative_shuffle_num": 888, 
    "in-dataset_question_shuffle_num": 4806, 
    "in-dataset_request_shuffle_num": 99, 
    "inf_sentences_id": 701124, 
    "line": "How can I find a phone number of someone if I only know their email address ?", 
    "linenum": 676, 
    "matchl": "How can I find a phone number of someone if I only know their email address ?", 
    "out-dataset_counterfactual_shuffle_num": 121, 
    "out-dataset_implicative_shuffle_num": 3553, 
    "out-dataset_question_shuffle_num": 14465, 
    "out-dataset_request_shuffle_num": 299, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "counterfactual", 
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 928704
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 119395, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "criticized", 
    "in-dataset_counterfactual_shuffle_num": 30, 
    "in-dataset_implicative_shuffle_num": 13992, 
    "inf_sentences_id": 119412, 
    "line": "It is inevitable even if he is criticized .", 
    "linenum": 119395, 
    "matchl": "It is inevitable even if he is criticized .", 
    "out-dataset_counterfactual_shuffle_num": 122, 
    "out-dataset_implicative_shuffle_num": 33684, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 346673
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>if<mid>(was|were|had|<past>|<ppart>) .+", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 321489, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/30360.txt.utf-8", 
    "in-dataset_counterfactual_shuffle_num": 30, 
    "inf_sentences_id": 1027392, 
    "line": "\" I 'd be damned if I would,--nor pay , nor anything else unless she took her gown off .", 
    "linenum": 9218, 
    "matchl": "\" I 'd be damned if I would,--nor pay , nor anything else unless she took her gown off .", 
    "out-dataset_counterfactual_shuffle_num": 123, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 1254972
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 484, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/113", 
    "in-dataset_counterfactual_shuffle_num": 31, 
    "inf_sentences_id": 687780, 
    "line": "`` If there is no political solution now , Vietnam will withdraw all its troops in 1990 .", 
    "linenum": 51, 
    "matchl": "`` If there is no political solution now , Vietnam will withdraw all its troops in 1990 .", 
    "out-dataset_counterfactual_shuffle_num": 124, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 915360
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>if<mid>(was|were|had|<past>|<ppart>) .+", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 14952, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_counterfactual_shuffle_num": 31, 
    "in-dataset_question_shuffle_num": 1875, 
    "in-dataset_request_shuffle_num": 294, 
    "inf_sentences_id": 705400, 
    "line": "What city would you be in if you were feeding the pigeons in the Piazza San Marco ?", 
    "linenum": 4952, 
    "matchl": "What city would you be in if you were feeding the pigeons in the Piazza San Marco ?", 
    "out-dataset_counterfactual_shuffle_num": 125, 
    "out-dataset_question_shuffle_num": 5672, 
    "out-dataset_request_shuffle_num": 884, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "counterfactual", 
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 932980
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If)<mid>(was|were|had|<past>|<ppart>)<mid?>(<futr>) .+", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 374689, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "truth", 
    "in-dataset_counterfactual_shuffle_num": 31, 
    "in-dataset_implicative_shuffle_num": 175489, 
    "inf_sentences_id": 374708, 
    "line": "If I 'd known the truth , I would 've told it to you .", 
    "linenum": 374689, 
    "matchl": "If I 'd known the truth , I would 've told it to you .", 
    "out-dataset_counterfactual_shuffle_num": 126, 
    "out-dataset_implicative_shuffle_num": 356678, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 601967
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 262707, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2680.txt.utf-8", 
    "implicative_pattern": "inform", 
    "in-dataset_counterfactual_shuffle_num": 31, 
    "in-dataset_implicative_shuffle_num": 215601, 
    "inf_sentences_id": 968609, 
    "line": "' We have summer heat here still , ' writes Marcus , ' but since my little girls are pretty well , if I may say so , it is like the bracing climate of spring to us.'(1 ) When little Faustina came back from the valley of the shadow of death , her father at once writes to inform Fronto.(2 ) The sympathy he asks he also gives , and as old age brings more and more infirmity , Marcus becomes even more solicitous for his beloved teacher .", 
    "linenum": 2795, 
    "matchl": "' We have summer heat here still , ' writes Marcus , ' but since my little girls are pretty well , if I may say so , it is like the bracing climate of spring to us.'(1 ) When little Faustina came back from the valley of the shadow of death , her father at once writes to inform Fronto.(2 ) The sympathy he asks he also gives , and as old age brings more and more infirmity , Marcus becomes even more solicitous for his beloved teacher .", 
    "out-dataset_counterfactual_shuffle_num": 127, 
    "out-dataset_implicative_shuffle_num": 436903, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1196189
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1331, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/24", 
    "implicative_pattern": "tend", 
    "in-dataset_counterfactual_shuffle_num": 32, 
    "in-dataset_implicative_shuffle_num": 693, 
    "inf_sentences_id": 688627, 
    "line": "`` Stocks of barley and oats would tend to build modestly if production returns to normal , and prices probably will fall . ''", 
    "linenum": 18, 
    "matchl": "`` Stocks of barley and oats would tend to build modestly if production returns to normal , and prices probably will fall . ''", 
    "out-dataset_counterfactual_shuffle_num": 128, 
    "out-dataset_implicative_shuffle_num": 2772, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 916207
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 6676, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_counterfactual_shuffle_num": 32, 
    "in-dataset_implicative_shuffle_num": 3075, 
    "in-dataset_question_shuffle_num": 2882, 
    "in-dataset_request_shuffle_num": 345, 
    "inf_sentences_id": 697124, 
    "line": "How can I find a phone number of someone if I only know their email address ?", 
    "linenum": 676, 
    "matchl": "How can I find a phone number of someone if I only know their email address ?", 
    "out-dataset_counterfactual_shuffle_num": 129, 
    "out-dataset_implicative_shuffle_num": 11214, 
    "out-dataset_question_shuffle_num": 8693, 
    "out-dataset_request_shuffle_num": 1037, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "request_pattern": "<begin?>(<permmodal>) I<mid?>(<pres>)<end?>", 
    "sampled": [
      "counterfactual", 
      "request", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 924704
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": ".+ (<wish>) .+", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 588309, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_counterfactual_shuffle_num": 32, 
    "inf_sentences_id": 588330, 
    "line": "It is shameful for you that any ( penalty ) whatever should be lacking which any one might wish to exact from these men .", 
    "linenum": 588309, 
    "matchl": "It is shameful for you that any ( penalty ) whatever should be lacking which any one might wish to exact from these men .", 
    "out-dataset_counterfactual_shuffle_num": 130, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 815587
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": ".+ (<wish>) .+", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 141530, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/161.txt.utf-8", 
    "implicative_pattern": "said", 
    "in-dataset_counterfactual_shuffle_num": 32, 
    "in-dataset_implicative_shuffle_num": 43555, 
    "inf_sentences_id": 847431, 
    "line": "Jennings told me , \" said he , \" that you wished to speak with me , at least I understood her so--or I certainly should not have intruded on you in such a manner ; though at the same time , I should have been extremely sorry to leave London without seeing you and your sister ; especially as it will most likely be some time--it is not probable that I should soon have the pleasure of meeting you again .", 
    "linenum": 4260, 
    "matchl": "Jennings told me , \" said he , \" that you wished to speak with me , at least I understood her so--or I certainly should not have intruded on you in such a manner ; though at the same time , I should have been extremely sorry to leave London without seeing you and your sister ; especially as it will most likely be some time--it is not probable that I should soon have the pleasure of meeting you again .", 
    "out-dataset_counterfactual_shuffle_num": 131, 
    "out-dataset_implicative_shuffle_num": 92811, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1075011
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 54, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/10", 
    "implicative_pattern": "think", 
    "in-dataset_counterfactual_shuffle_num": 33, 
    "in-dataset_implicative_shuffle_num": 1124, 
    "inf_sentences_id": 687350, 
    "line": "Austin Ranney , chairman of the Department of Political Science at the University of California at Berkeley , said , `` On just the externalities of it , I think Reagan 's presidency , with one huge ` if , ' will probably go down as one of the most successful ones certainly in this century and maybe ever . ''", 
    "linenum": 14, 
    "matchl": "Austin Ranney , chairman of the Department of Political Science at the University of California at Berkeley , said , `` On just the externalities of it , I think Reagan 's presidency , with one huge ` if , ' will probably go down as one of the most successful ones certainly in this century and maybe ever . ''", 
    "out-dataset_counterfactual_shuffle_num": 132, 
    "out-dataset_implicative_shuffle_num": 4496, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 914930
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 8400, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "says", 
    "in-dataset_counterfactual_shuffle_num": 33, 
    "in-dataset_implicative_shuffle_num": 3532, 
    "in-dataset_question_shuffle_num": 11690, 
    "inf_sentences_id": 698848, 
    "line": "Who says , `` If you don 't look good , we don 't look good '' ?", 
    "linenum": 2400, 
    "matchl": "Who says , `` If you don 't look good , we don 't look good '' ?", 
    "out-dataset_counterfactual_shuffle_num": 133, 
    "out-dataset_implicative_shuffle_num": 12585, 
    "out-dataset_question_shuffle_num": 35117, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 926428
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "(were|had|Were|Had)<end?>", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 666512, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "convince", 
    "in-dataset_counterfactual_shuffle_num": 33, 
    "in-dataset_implicative_shuffle_num": 105429, 
    "in-dataset_question_shuffle_num": 12129, 
    "inf_sentences_id": 666534, 
    "line": "Were you able to convince Tom to help us ?", 
    "linenum": 666512, 
    "matchl": "Were you able to convince Tom to help us ?", 
    "out-dataset_counterfactual_shuffle_num": 134, 
    "out-dataset_implicative_shuffle_num": 216558, 
    "out-dataset_question_shuffle_num": 36435, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<aux>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 893790
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": ".+ (<wish>) .+", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 417273, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/514.txt.utf-8", 
    "in-dataset_counterfactual_shuffle_num": 33, 
    "inf_sentences_id": 1123177, 
    "line": "Beth nestled up to her , and whispered softly , \" I wish I could send my bunch to Father .", 
    "linenum": 434, 
    "matchl": "Beth nestled up to her , and whispered softly , \" I wish I could send my bunch to Father .", 
    "out-dataset_counterfactual_shuffle_num": 135, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 1350757
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 3034, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/94", 
    "implicative_pattern": "meant", 
    "in-dataset_counterfactual_shuffle_num": 34, 
    "in-dataset_implicative_shuffle_num": 104, 
    "inf_sentences_id": 690330, 
    "line": "If by that he meant women , so far , he has fallen short .", 
    "linenum": 13, 
    "matchl": "If by that he meant women , so far , he has fallen short .", 
    "out-dataset_counterfactual_shuffle_num": 136, 
    "out-dataset_implicative_shuffle_num": 416, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 917910
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 5894, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "in-dataset_counterfactual_shuffle_num": 34, 
    "in-dataset_question_shuffle_num": 3024, 
    "inf_sentences_id": 696342, 
    "line": "What do goldfish lose if kept in dimly-lit or running water ?", 
    "linenum": 2894, 
    "matchl": "What do goldfish lose if kept in dimly-lit or running water ?", 
    "out-dataset_counterfactual_shuffle_num": 137, 
    "out-dataset_question_shuffle_num": 9119, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question"
    ], 
    "ulf_sentences_id": 923922
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 460418, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_counterfactual_shuffle_num": 34, 
    "inf_sentences_id": 460438, 
    "line": "People usually die if you kill them .", 
    "linenum": 460418, 
    "matchl": "People usually die if you kill them .", 
    "out-dataset_counterfactual_shuffle_num": 138, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 687696
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 236354, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2600-0.txt", 
    "in-dataset_counterfactual_shuffle_num": 34, 
    "inf_sentences_id": 942256, 
    "line": "If he is standing before Brunn ... \"", 
    "linenum": 7233, 
    "matchl": "If he is standing before Brunn ... \"", 
    "out-dataset_counterfactual_shuffle_num": 139, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 1169836
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 689, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/120", 
    "implicative_pattern": "make", 
    "in-dataset_counterfactual_shuffle_num": 35, 
    "in-dataset_implicative_shuffle_num": 708, 
    "inf_sentences_id": 687985, 
    "line": "If I have any confessions to make , I will make them to a priest .", 
    "linenum": 13, 
    "matchl": "If I have any confessions to make , I will make them to a priest .", 
    "out-dataset_counterfactual_shuffle_num": 140, 
    "out-dataset_implicative_shuffle_num": 2832, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 915565
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 11579, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "tell", 
    "in-dataset_counterfactual_shuffle_num": 35, 
    "in-dataset_implicative_shuffle_num": 3670, 
    "in-dataset_question_shuffle_num": 4800, 
    "inf_sentences_id": 702027, 
    "line": "How can anyone tell if a female had sexual intercourse ?", 
    "linenum": 1579, 
    "matchl": "How can anyone tell if a female had sexual intercourse ?", 
    "out-dataset_counterfactual_shuffle_num": 141, 
    "out-dataset_implicative_shuffle_num": 12999, 
    "out-dataset_question_shuffle_num": 14447, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 929607
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 539, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_counterfactual_shuffle_num": 35, 
    "inf_sentences_id": 555, 
    "line": "A schedule is an identity card for time , but , if you do n't have a schedule , the time is n't there .", 
    "linenum": 539, 
    "matchl": "A schedule is an identity card for time , but , if you do n't have a schedule , the time is n't there .", 
    "out-dataset_counterfactual_shuffle_num": 142, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 227817
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 478209, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/84-0.txt", 
    "in-dataset_counterfactual_shuffle_num": 35, 
    "inf_sentences_id": 1184113, 
    "line": "Even as she spoke I drew near to her , as if in terror , lest at that very moment the destroyer had been near to rob me of her .", 
    "linenum": 1293, 
    "matchl": "Even as she spoke I drew near to her , as if in terror , lest at that very moment the destroyer had been near to rob me of her .", 
    "out-dataset_counterfactual_shuffle_num": 143, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 1411693
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>(were|had) .+", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 597, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/117", 
    "in-dataset_counterfactual_shuffle_num": 36, 
    "inf_sentences_id": 687893, 
    "line": "Congressmen , teachers , and Saudi princes will no longer be invited by NASA to be passengers on the space shuttle under a new policy that emphasizes completing the recovery from the Challenger accident in which two non-astronauts were killed .", 
    "linenum": 0, 
    "matchl": "Congressmen , teachers , and Saudi princes will no longer be invited by NASA to be passengers on the space shuttle under a new policy that emphasizes completing the recovery from the Challenger accident in which two non-astronauts were killed .", 
    "out-dataset_counterfactual_shuffle_num": 144, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 915473
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>if<mid>(was|were|had|<past>|<ppart>) .+", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 12310, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "truth", 
    "in-dataset_counterfactual_shuffle_num": 36, 
    "in-dataset_implicative_shuffle_num": 3344, 
    "in-dataset_question_shuffle_num": 2289, 
    "inf_sentences_id": 702758, 
    "line": "Who said : `` The victor will never be asked if he told the truth '' ?", 
    "linenum": 2310, 
    "matchl": "Who said : `` The victor will never be asked if he told the truth '' ?", 
    "out-dataset_counterfactual_shuffle_num": 145, 
    "out-dataset_implicative_shuffle_num": 12021, 
    "out-dataset_question_shuffle_num": 6914, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 930338
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 603641, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "attempt", 
    "in-dataset_counterfactual_shuffle_num": 36, 
    "in-dataset_implicative_shuffle_num": 85345, 
    "inf_sentences_id": 603663, 
    "line": "If any blame or fault attaches to the attempt , it is mine alone .", 
    "linenum": 603641, 
    "matchl": "If any blame or fault attaches to the attempt , it is mine alone .", 
    "out-dataset_counterfactual_shuffle_num": 146, 
    "out-dataset_implicative_shuffle_num": 176390, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 830919
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 91952, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1400-0.txt", 
    "implicative_pattern": "mean", 
    "in-dataset_counterfactual_shuffle_num": 36, 
    "in-dataset_implicative_shuffle_num": 198823, 
    "inf_sentences_id": 797852, 
    "line": "I reflected for some time , and then answered as if I had discovered a new idea , \" I mean pretty well . \"", 
    "linenum": 1302, 
    "matchl": "I reflected for some time , and then answered as if I had discovered a new idea , \" I mean pretty well . \"", 
    "out-dataset_counterfactual_shuffle_num": 147, 
    "out-dataset_implicative_shuffle_num": 403347, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1025432
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If)<mid>(was|were|had|<past>|<ppart>)<mid?>(<futr>) .+", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 970, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/134", 
    "in-dataset_counterfactual_shuffle_num": 37, 
    "inf_sentences_id": 688266, 
    "line": "\" If true , \" the court wrote , \" this contention would justify dismissal of these actions on prudential grounds . \"", 
    "linenum": 9, 
    "matchl": "\" If true , \" the court wrote , \" this contention would justify dismissal of these actions on prudential grounds . \"", 
    "out-dataset_counterfactual_shuffle_num": 148, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 915846
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 5254, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "in-dataset_counterfactual_shuffle_num": 37, 
    "in-dataset_question_shuffle_num": 9070, 
    "inf_sentences_id": 695702, 
    "line": "Why is it called `` hamburger '' if there is no ham in it ?", 
    "linenum": 2254, 
    "matchl": "Why is it called `` hamburger '' if there is no ham in it ?", 
    "out-dataset_counterfactual_shuffle_num": 149, 
    "out-dataset_question_shuffle_num": 27257, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question"
    ], 
    "ulf_sentences_id": 923282
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 185741, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "comes", 
    "in-dataset_counterfactual_shuffle_num": 37, 
    "in-dataset_implicative_shuffle_num": 95365, 
    "in-dataset_question_shuffle_num": 34465, 
    "inf_sentences_id": 185758, 
    "line": "What am I supposed to do if Tom comes ?", 
    "linenum": 185741, 
    "matchl": "What am I supposed to do if Tom comes ?", 
    "out-dataset_counterfactual_shuffle_num": 150, 
    "out-dataset_implicative_shuffle_num": 196430, 
    "out-dataset_question_shuffle_num": 84182, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 413019
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 308830, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/30254-0.txt", 
    "in-dataset_counterfactual_shuffle_num": 37, 
    "inf_sentences_id": 1014733, 
    "line": "The doctor , taking hold of the youth 's now standing prick , asked if it had ever behaved so badly before the scene with his pretty young cousin .", 
    "linenum": 4278, 
    "matchl": "The doctor , taking hold of the youth 's now standing prick , asked if it had ever behaved so badly before the scene with his pretty young cousin .", 
    "out-dataset_counterfactual_shuffle_num": 151, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 1242313
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 3043, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/94", 
    "in-dataset_counterfactual_shuffle_num": 38, 
    "inf_sentences_id": 690339, 
    "line": "`` And to have two -- one and a half , if you will ( Hills would have Cabinet status but not run a full department ) that are that visible , that 's good . ''", 
    "linenum": 22, 
    "matchl": "`` And to have two -- one and a half , if you will ( Hills would have Cabinet status but not run a full department ) that are that visible , that 's good . ''", 
    "out-dataset_counterfactual_shuffle_num": 152, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 917919
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 13862, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "tell", 
    "in-dataset_counterfactual_shuffle_num": 38, 
    "in-dataset_implicative_shuffle_num": 3394, 
    "in-dataset_question_shuffle_num": 7640, 
    "inf_sentences_id": 704310, 
    "line": "How do vending machines tell if your dollar is a 1 or a 5 ?", 
    "linenum": 3862, 
    "matchl": "How do vending machines tell if your dollar is a 1 or a 5 ?", 
    "out-dataset_counterfactual_shuffle_num": 153, 
    "out-dataset_implicative_shuffle_num": 12171, 
    "out-dataset_question_shuffle_num": 22967, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 931890
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 204145, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_counterfactual_shuffle_num": 38, 
    "inf_sentences_id": 204163, 
    "line": "It 's OK with me if you take that book .", 
    "linenum": 204145, 
    "matchl": "It 's OK with me if you take that book .", 
    "out-dataset_counterfactual_shuffle_num": 154, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 431423
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 399214, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/4300-0.txt", 
    "implicative_pattern": "fact", 
    "in-dataset_counterfactual_shuffle_num": 38, 
    "in-dataset_implicative_shuffle_num": 19755, 
    "inf_sentences_id": 1105117, 
    "line": "Nevertheless , without going into the minutiae of the business , the eloquent fact remained that the sea was there in all its glory and in the natural course of things somebody or other had to sail on it and fly in the face of providence though it merely went to show how people usually contrived to load that sort of onus on to the other fellow like the hell idea and the lottery and insurance which were run on identically the same lines so that for that very reason if no other lifeboat Sunday was a highly laudable institution to which the public at large , no matter where living inland or seaside , as the case might be , having it brought home to them like that should extend its gratitude also to the harbourmasters and coastguard service who had to man the rigging and push off and out amid the elements whatever the season when duty called Ireland expects that every man and so on and sometimes had a terrible time of it in the wintertime not forgetting the Irish lights , Kish and others , liable to capsize at any moment , rounding which he once with his daughter had experienced some remarkably choppy , not to say stormy , weather .", 
    "linenum": 21443, 
    "matchl": "Nevertheless , without going into the minutiae of the business , the eloquent fact remained that the sea was there in all its glory and in the natural course of things somebody or other had to sail on it and fly in the face of providence though it merely went to show how people usually contrived to load that sort of onus on to the other fellow like the hell idea and the lottery and insurance which were run on identically the same lines so that for that very reason if no other lifeboat Sunday was a highly laudable institution to which the public at large , no matter where living inland or seaside , as the case might be , having it brought home to them like that should extend its gratitude also to the harbourmasters and coastguard service who had to man the rigging and push off and out amid the elements whatever the season when duty called Ireland expects that every man and so on and sometimes had a terrible time of it in the wintertime not forgetting the Irish lights , Kish and others , liable to capsize at any moment , rounding which he once with his daughter had experienced some remarkably choppy , not to say stormy , weather .", 
    "out-dataset_counterfactual_shuffle_num": 155, 
    "out-dataset_implicative_shuffle_num": 45211, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1332697
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>if<mid>(was|were|had|<past>|<ppart>) .+", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2585, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/77", 
    "implicative_pattern": "remain", 
    "in-dataset_counterfactual_shuffle_num": 39, 
    "in-dataset_implicative_shuffle_num": 1458, 
    "inf_sentences_id": 689881, 
    "line": "Another U.S. specialist said gas and biological agents would remain effective against `` inconvenient minorities '' even if nations could be kept from using them outside their borders .", 
    "linenum": 10, 
    "matchl": "Another U.S. specialist said gas and biological agents would remain effective against `` inconvenient minorities '' even if nations could be kept from using them outside their borders .", 
    "out-dataset_counterfactual_shuffle_num": 156, 
    "out-dataset_implicative_shuffle_num": 5832, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 917461
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 12094, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "implicative_pattern": "sees", 
    "in-dataset_counterfactual_shuffle_num": 39, 
    "in-dataset_implicative_shuffle_num": 1775, 
    "in-dataset_question_shuffle_num": 7231, 
    "inf_sentences_id": 702542, 
    "line": "How many more weeks of winter are there if a ground hog sees his shadow ?", 
    "linenum": 2094, 
    "matchl": "How many more weeks of winter are there if a ground hog sees his shadow ?", 
    "out-dataset_counterfactual_shuffle_num": 157, 
    "out-dataset_implicative_shuffle_num": 7101, 
    "out-dataset_question_shuffle_num": 21740, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 930122
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 461788, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "know", 
    "in-dataset_counterfactual_shuffle_num": 39, 
    "in-dataset_implicative_shuffle_num": 20198, 
    "inf_sentences_id": 461808, 
    "line": "Tom did n't know if it would be worth his while applying for the job .", 
    "linenum": 461788, 
    "matchl": "Tom did n't know if it would be worth his while applying for the job .", 
    "out-dataset_counterfactual_shuffle_num": 158, 
    "out-dataset_implicative_shuffle_num": 46096, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 689066
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 358928, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/3600-0.txt", 
    "in-dataset_counterfactual_shuffle_num": 39, 
    "inf_sentences_id": 1064831, 
    "line": "If thou art naked , present thy throat ; if covered with the arms of Vulcan , that is , fortitude , resist it . \"", 
    "linenum": 6729, 
    "matchl": "If thou art naked , present thy throat ; if covered with the arms of Vulcan , that is , fortitude , resist it . \"", 
    "out-dataset_counterfactual_shuffle_num": 159, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 1292411
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>if<mid>(was|were|had|<past>|<ppart>) .+", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1853, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/47", 
    "implicative_pattern": "confirm", 
    "in-dataset_counterfactual_shuffle_num": 40, 
    "in-dataset_implicative_shuffle_num": 89, 
    "inf_sentences_id": 689149, 
    "line": "The source of Legionnaires ' disease would be easier to find if the second custodian has the disease , but it would not confirm that the bacteria was at the school because the men could have been in a common place other than the school when they contracted the bacteria , Breiman said .", 
    "linenum": 15, 
    "matchl": "The source of Legionnaires ' disease would be easier to find if the second custodian has the disease , but it would not confirm that the bacteria was at the school because the men could have been in a common place other than the school when they contracted the bacteria , Breiman said .", 
    "out-dataset_counterfactual_shuffle_num": 160, 
    "out-dataset_implicative_shuffle_num": 356, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 916729
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 2779, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "in-dataset_counterfactual_shuffle_num": 40, 
    "in-dataset_question_shuffle_num": 1696, 
    "inf_sentences_id": 693227, 
    "line": "What country are you in if you woo in the Wu dialect ?", 
    "linenum": 1779, 
    "matchl": "What country are you in if you woo in the Wu dialect ?", 
    "out-dataset_counterfactual_shuffle_num": 161, 
    "out-dataset_question_shuffle_num": 5135, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question"
    ], 
    "ulf_sentences_id": 920807
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>(were|had) .+", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 331805, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "know", 
    "in-dataset_counterfactual_shuffle_num": 40, 
    "in-dataset_implicative_shuffle_num": 217549, 
    "inf_sentences_id": 331824, 
    "line": "Tom wo n't even know we were here .", 
    "linenum": 331805, 
    "matchl": "Tom wo n't even know we were here .", 
    "out-dataset_counterfactual_shuffle_num": 162, 
    "out-dataset_implicative_shuffle_num": 440798, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 559083
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 330916, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/3296.txt.utf-8", 
    "in-dataset_counterfactual_shuffle_num": 40, 
    "in-dataset_question_shuffle_num": 4745, 
    "inf_sentences_id": 1036819, 
    "line": "And who has any right to speak against it , if just punishment follow the sinner ?", 
    "linenum": 1488, 
    "matchl": "And who has any right to speak against it , if just punishment follow the sinner ?", 
    "out-dataset_counterfactual_shuffle_num": 163, 
    "out-dataset_question_shuffle_num": 14284, 
    "question_pattern": "^.*\\?.*$", 
    "sampled": [
      "counterfactual", 
      "question"
    ], 
    "ulf_sentences_id": 1264399
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If)<mid>(was|were|had|<past>|<ppart>)<mid?>(<futr>) .+", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1560, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/34", 
    "implicative_pattern": "attack", 
    "in-dataset_counterfactual_shuffle_num": 41, 
    "in-dataset_implicative_shuffle_num": 1540, 
    "inf_sentences_id": 688856, 
    "line": "`` If you were going to make an attack on the chemical plant , you would not position your carrier some 600 miles away .", 
    "linenum": 48, 
    "matchl": "`` If you were going to make an attack on the chemical plant , you would not position your carrier some 600 miles away .", 
    "out-dataset_counterfactual_shuffle_num": 164, 
    "out-dataset_implicative_shuffle_num": 6160, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 916436
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 6631, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "in-dataset_counterfactual_shuffle_num": 41, 
    "in-dataset_question_shuffle_num": 3572, 
    "inf_sentences_id": 697079, 
    "line": "What two colors are you blind to if you suffer from protanopia ?", 
    "linenum": 631, 
    "matchl": "What two colors are you blind to if you suffer from protanopia ?", 
    "out-dataset_counterfactual_shuffle_num": 165, 
    "out-dataset_question_shuffle_num": 10763, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question"
    ], 
    "ulf_sentences_id": 924659
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 606039, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "make", 
    "in-dataset_counterfactual_shuffle_num": 41, 
    "in-dataset_implicative_shuffle_num": 63508, 
    "inf_sentences_id": 606061, 
    "line": "If you do that , you 'll be sued so fast it 'll make your head spin .", 
    "linenum": 606039, 
    "matchl": "If you do that , you 'll be sued so fast it 'll make your head spin .", 
    "out-dataset_counterfactual_shuffle_num": 166, 
    "out-dataset_implicative_shuffle_num": 132716, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 833317
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 118353, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/15399.txt.utf-8", 
    "implicative_pattern": "saying", 
    "in-dataset_counterfactual_shuffle_num": 41, 
    "in-dataset_implicative_shuffle_num": 185462, 
    "inf_sentences_id": 824254, 
    "line": "We had a saying among us to any one of a cross temper , ' That if they were to be eaten , they should be eaten with bitter herbs . '", 
    "linenum": 391, 
    "matchl": "We had a saying among us to any one of a cross temper , ' That if they were to be eaten , they should be eaten with bitter herbs . '", 
    "out-dataset_counterfactual_shuffle_num": 167, 
    "out-dataset_implicative_shuffle_num": 376625, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1051834
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1325, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/24", 
    "implicative_pattern": "happens", 
    "in-dataset_counterfactual_shuffle_num": 42, 
    "in-dataset_implicative_shuffle_num": 1104, 
    "inf_sentences_id": 688621, 
    "line": "If that happens , he said , farmers could harvest between 7.7 billion and 8.3 billion bushels of corn next fall .", 
    "linenum": 12, 
    "matchl": "If that happens , he said , farmers could harvest between 7.7 billion and 8.3 billion bushels of corn next fall .", 
    "out-dataset_counterfactual_shuffle_num": 168, 
    "out-dataset_implicative_shuffle_num": 4416, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 916201
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 9493, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_counterfactual_shuffle_num": 42, 
    "in-dataset_implicative_shuffle_num": 3647, 
    "in-dataset_question_shuffle_num": 6801, 
    "inf_sentences_id": 699941, 
    "line": "How do I find if my relatives were on the Trail of Tears ?", 
    "linenum": 3493, 
    "matchl": "How do I find if my relatives were on the Trail of Tears ?", 
    "out-dataset_counterfactual_shuffle_num": 169, 
    "out-dataset_implicative_shuffle_num": 12930, 
    "out-dataset_question_shuffle_num": 20450, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 927521
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 154431, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "ensuring", 
    "in-dataset_counterfactual_shuffle_num": 42, 
    "in-dataset_implicative_shuffle_num": 101424, 
    "inf_sentences_id": 154448, 
    "line": "Everyone who works has the right to just and favourable remuneration ensuring for himself and his family an existence worthy of human dignity , and supplemented , if necessary , by other means of social protection .", 
    "linenum": 154431, 
    "matchl": "Everyone who works has the right to just and favourable remuneration ensuring for himself and his family an existence worthy of human dignity , and supplemented , if necessary , by other means of social protection .", 
    "out-dataset_counterfactual_shuffle_num": 170, 
    "out-dataset_implicative_shuffle_num": 208548, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 381709
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If)<mid>(was|were|had|<past>|<ppart>)<mid?>(<futr>) .+", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 80206, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/135-0.txt", 
    "implicative_pattern": "facts", 
    "in-dataset_counterfactual_shuffle_num": 42, 
    "in-dataset_implicative_shuffle_num": 63712, 
    "inf_sentences_id": 786106, 
    "line": "If facts did their duty , they would confine themselves to being proofs of the law ; facts--it is God who sends them .", 
    "linenum": 31779, 
    "matchl": "If facts did their duty , they would confine themselves to being proofs of the law ; facts--it is God who sends them .", 
    "out-dataset_counterfactual_shuffle_num": 171, 
    "out-dataset_implicative_shuffle_num": 133125, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1013686
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If)<mid>(was|were|had|<past>|<ppart>)<mid?>(<futr>) .+", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1663, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/39", 
    "implicative_pattern": "made", 
    "in-dataset_counterfactual_shuffle_num": 43, 
    "in-dataset_implicative_shuffle_num": 836, 
    "inf_sentences_id": 688959, 
    "line": "Reagan has said if his cuts are made , the budget will be balanced by 1993 , the same year the Gramm-Rudman law requires the elimination of the deficit .", 
    "linenum": 13, 
    "matchl": "Reagan has said if his cuts are made , the budget will be balanced by 1993 , the same year the Gramm-Rudman law requires the elimination of the deficit .", 
    "out-dataset_counterfactual_shuffle_num": 172, 
    "out-dataset_implicative_shuffle_num": 3344, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 916539
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 675924, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_counterfactual_shuffle_num": 43, 
    "inf_sentences_id": 675946, 
    "line": "If I do n't eat , I will die .", 
    "linenum": 675924, 
    "matchl": "If I do n't eat , I will die .", 
    "out-dataset_counterfactual_shuffle_num": 174, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 903202
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 200400, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/236-0.txt", 
    "implicative_pattern": "lies", 
    "in-dataset_counterfactual_shuffle_num": 43, 
    "in-dataset_implicative_shuffle_num": 44567, 
    "inf_sentences_id": 906302, 
    "line": "If there were but ten of us we might pull him down as he lies .", 
    "linenum": 1250, 
    "matchl": "If there were but ten of us we might pull him down as he lies .", 
    "out-dataset_counterfactual_shuffle_num": 175, 
    "out-dataset_implicative_shuffle_num": 94835, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1133882
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 3700, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "in-dataset_counterfactual_shuffle_num": 44, 
    "in-dataset_question_shuffle_num": 3569, 
    "inf_sentences_id": 694148, 
    "line": "How far do you have to run if you hit a home run ?", 
    "linenum": 700, 
    "matchl": "How far do you have to run if you hit a home run ?", 
    "out-dataset_counterfactual_shuffle_num": 177, 
    "out-dataset_question_shuffle_num": 10754, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question"
    ], 
    "ulf_sentences_id": 921728
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 151593, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_counterfactual_shuffle_num": 44, 
    "inf_sentences_id": 151610, 
    "line": "I 'll do it if they pay me .", 
    "linenum": 151593, 
    "matchl": "I 'll do it if they pay me .", 
    "out-dataset_counterfactual_shuffle_num": 178, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 378871
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>(were|had) .+", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 425477, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/514.txt.utf-8", 
    "implicative_pattern": "care", 
    "in-dataset_counterfactual_shuffle_num": 44, 
    "in-dataset_implicative_shuffle_num": 253778, 
    "inf_sentences_id": 1131381, 
    "line": "He could n't have got himself up with more care if he 'd been going a-wooing , \" said Jo to herself , and then a sudden thought born of the words made her blush so dreadfully that she had to drop her ball , and go down after it to hide her face .", 
    "linenum": 8638, 
    "matchl": "He could n't have got himself up with more care if he 'd been going a-wooing , \" said Jo to herself , and then a sudden thought born of the words made her blush so dreadfully that she had to drop her ball , and go down after it to hide her face .", 
    "out-dataset_counterfactual_shuffle_num": 179, 
    "out-dataset_implicative_shuffle_num": 513257, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1358961
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 756, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/123", 
    "implicative_pattern": "saying", 
    "in-dataset_counterfactual_shuffle_num": 45, 
    "in-dataset_implicative_shuffle_num": 1449, 
    "inf_sentences_id": 688052, 
    "line": "Lawmakers have n't publicly raised the possibility of renewing military aid to the Contras , and President Bush parried the question at a news conference here Saturday , saying only that \" if there 's an all-out military offensive , that 's going to change the equation 180 degrees . \"", 
    "linenum": 1, 
    "matchl": "Lawmakers have n't publicly raised the possibility of renewing military aid to the Contras , and President Bush parried the question at a news conference here Saturday , saying only that \" if there 's an all-out military offensive , that 's going to change the equation 180 degrees . \"", 
    "out-dataset_counterfactual_shuffle_num": 180, 
    "out-dataset_implicative_shuffle_num": 5796, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 915632
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 2659, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_counterfactual_shuffle_num": 45, 
    "in-dataset_implicative_shuffle_num": 96, 
    "in-dataset_question_shuffle_num": 14105, 
    "inf_sentences_id": 693107, 
    "line": "How long after intercourse does it take to find out if you are pregnant ?", 
    "linenum": 1659, 
    "matchl": "How long after intercourse does it take to find out if you are pregnant ?", 
    "out-dataset_counterfactual_shuffle_num": 181, 
    "out-dataset_implicative_shuffle_num": 385, 
    "out-dataset_question_shuffle_num": 42362, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 920687
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 449607, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_counterfactual_shuffle_num": 45, 
    "inf_sentences_id": 449627, 
    "line": "Tom asked me if he could borrow my car .", 
    "linenum": 449607, 
    "matchl": "Tom asked me if he could borrow my car .", 
    "out-dataset_counterfactual_shuffle_num": 182, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 676885
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If)<mid>(was|were|had|<past>|<ppart>)<mid?>(<futr>) .+", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 242789, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2600-0.txt", 
    "implicative_pattern": "show", 
    "in-dataset_counterfactual_shuffle_num": 45, 
    "in-dataset_implicative_shuffle_num": 148755, 
    "inf_sentences_id": 948691, 
    "line": "\" Yes , she 's fast enough , \" replied Nicholas , and thought : \" If only a full-grown hare would cross the field now I 'd show you what sort of borzoi she is , \" and turning to his groom , he said he would give a ruble to anyone who found a hare .", 
    "linenum": 13668, 
    "matchl": "\" Yes , she 's fast enough , \" replied Nicholas , and thought : \" If only a full-grown hare would cross the field now I 'd show you what sort of borzoi she is , \" and turning to his groom , he said he would give a ruble to anyone who found a hare .", 
    "out-dataset_counterfactual_shuffle_num": 183, 
    "out-dataset_implicative_shuffle_num": 303211, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1176271
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1977, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/52", 
    "implicative_pattern": "demonstrate", 
    "in-dataset_counterfactual_shuffle_num": 46, 
    "in-dataset_implicative_shuffle_num": 1415, 
    "inf_sentences_id": 689273, 
    "line": "Goddard said Bush could demonstrate a commitment to a partnership with cities if he consults local officials , sets up a mechanism to consider the impact of agencies ' actions and regulations on municipalities , evaluates approaches cities have found successful in dealing with their problems and does n't rule out spending new funds in critical areas .", 
    "linenum": 12, 
    "matchl": "Goddard said Bush could demonstrate a commitment to a partnership with cities if he consults local officials , sets up a mechanism to consider the impact of agencies ' actions and regulations on municipalities , evaluates approaches cities have found successful in dealing with their problems and does n't rule out spending new funds in critical areas .", 
    "out-dataset_counterfactual_shuffle_num": 184, 
    "out-dataset_implicative_shuffle_num": 5660, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 916853
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 9283, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "in-dataset_counterfactual_shuffle_num": 46, 
    "in-dataset_question_shuffle_num": 9286, 
    "inf_sentences_id": 699731, 
    "line": "What are you caught in if a haboob blows up ?", 
    "linenum": 3283, 
    "matchl": "What are you caught in if a haboob blows up ?", 
    "out-dataset_counterfactual_shuffle_num": 185, 
    "out-dataset_question_shuffle_num": 27905, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question"
    ], 
    "ulf_sentences_id": 927311
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 78889, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "want", 
    "in-dataset_counterfactual_shuffle_num": 46, 
    "in-dataset_implicative_shuffle_num": 162964, 
    "inf_sentences_id": 78905, 
    "line": "You 'll have to work hard if you want to pass the exam .", 
    "linenum": 78889, 
    "matchl": "You 'll have to work hard if you want to pass the exam .", 
    "out-dataset_counterfactual_shuffle_num": 186, 
    "out-dataset_implicative_shuffle_num": 331628, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 306167
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 98953, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1400-0.txt", 
    "implicative_pattern": "told", 
    "in-dataset_counterfactual_shuffle_num": 46, 
    "in-dataset_implicative_shuffle_num": 256833, 
    "inf_sentences_id": 804853, 
    "line": "If it was all your money twenty times told , to the last brass farden ! \"", 
    "linenum": 8303, 
    "matchl": "If it was all your money twenty times told , to the last brass farden ! \"", 
    "out-dataset_counterfactual_shuffle_num": 187, 
    "out-dataset_implicative_shuffle_num": 519367, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1032433
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1839, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/47", 
    "implicative_pattern": "determine", 
    "in-dataset_counterfactual_shuffle_num": 47, 
    "in-dataset_implicative_shuffle_num": 1484, 
    "inf_sentences_id": 689135, 
    "line": "Test results to determine if the second custodian at Hunterdon Central Regional High School has the disease should be available in about five days , said Marilyn Riley , state Health Department spokeswoman .", 
    "linenum": 1, 
    "matchl": "Test results to determine if the second custodian at Hunterdon Central Regional High School has the disease should be available in about five days , said Marilyn Riley , state Health Department spokeswoman .", 
    "out-dataset_counterfactual_shuffle_num": 188, 
    "out-dataset_implicative_shuffle_num": 5936, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 916715
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 9506, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "in-dataset_counterfactual_shuffle_num": 47, 
    "in-dataset_question_shuffle_num": 8267, 
    "inf_sentences_id": 699954, 
    "line": "What are the chances of pregnacy if the penis does not penetrate the vagina ?", 
    "linenum": 3506, 
    "matchl": "What are the chances of pregnacy if the penis does not penetrate the vagina ?", 
    "out-dataset_counterfactual_shuffle_num": 189, 
    "out-dataset_question_shuffle_num": 24848, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question"
    ], 
    "ulf_sentences_id": 927534
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 496563, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "tell", 
    "in-dataset_counterfactual_shuffle_num": 47, 
    "in-dataset_implicative_shuffle_num": 242241, 
    "inf_sentences_id": 496583, 
    "line": "Tell me if it is n't so .", 
    "linenum": 496563, 
    "matchl": "Tell me if it is n't so .", 
    "out-dataset_counterfactual_shuffle_num": 190, 
    "out-dataset_implicative_shuffle_num": 490182, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 723841
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If)<mid>(was|were|had|<past>|<ppart>)<mid?>(<futr>) .+", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 20470, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1184-0.txt", 
    "implicative_pattern": "attack", 
    "in-dataset_counterfactual_shuffle_num": 47, 
    "in-dataset_implicative_shuffle_num": 45171, 
    "inf_sentences_id": 726370, 
    "line": "It might be expected that the attack , if indeed an attack was projected , would be made from the staircase of the ground floor , and not from a window ; in Monte Cristo 's opinion , the villains sought his life , not his money .", 
    "linenum": 18947, 
    "matchl": "It might be expected that the attack , if indeed an attack was projected , would be made from the staircase of the ground floor , and not from a window ; in Monte Cristo 's opinion , the villains sought his life , not his money .", 
    "out-dataset_counterfactual_shuffle_num": 191, 
    "out-dataset_implicative_shuffle_num": 96043, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 953950
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1330, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/24", 
    "implicative_pattern": "said", 
    "in-dataset_counterfactual_shuffle_num": 48, 
    "in-dataset_implicative_shuffle_num": 761, 
    "inf_sentences_id": 688626, 
    "line": "`` If yields return to normal , 1989-90 production of barley , oats and sorghum also is likely to rebound , '' he said .", 
    "linenum": 17, 
    "matchl": "`` If yields return to normal , 1989-90 production of barley , oats and sorghum also is likely to rebound , '' he said .", 
    "out-dataset_counterfactual_shuffle_num": 192, 
    "out-dataset_implicative_shuffle_num": 3044, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 916206
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 13506, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "in-dataset_counterfactual_shuffle_num": 48, 
    "in-dataset_question_shuffle_num": 9287, 
    "inf_sentences_id": 703954, 
    "line": "What are the chances of pregnacy if the penis does not penetrate the vagina ?", 
    "linenum": 3506, 
    "matchl": "What are the chances of pregnacy if the penis does not penetrate the vagina ?", 
    "out-dataset_counterfactual_shuffle_num": 193, 
    "out-dataset_question_shuffle_num": 27908, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question"
    ], 
    "ulf_sentences_id": 931534
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": ".+ (<wish>) .+", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 245484, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_counterfactual_shuffle_num": 48, 
    "inf_sentences_id": 245502, 
    "line": "I wish I could eat steak more often .", 
    "linenum": 245484, 
    "matchl": "I wish I could eat steak more often .", 
    "out-dataset_counterfactual_shuffle_num": 194, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 472762
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>if<mid>(was|were|had|<past>|<ppart>) .+", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 331602, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/3296.txt.utf-8", 
    "implicative_pattern": "delighted", 
    "in-dataset_counterfactual_shuffle_num": 48, 
    "in-dataset_implicative_shuffle_num": 159152, 
    "inf_sentences_id": 1037505, 
    "line": "For when a Greek hears it in Latin , he is not delighted , not knowing what is spoken ; but we Latins are delighted , as would he too , if he heard it in Greek ; because the thing itself is neither Greek nor Latin , which Greeks and Latins , and men of all other tongues , long for so earnestly .", 
    "linenum": 2174, 
    "matchl": "For when a Greek hears it in Latin , he is not delighted , not knowing what is spoken ; but we Latins are delighted , as would he too , if he heard it in Greek ; because the thing itself is neither Greek nor Latin , which Greeks and Latins , and men of all other tongues , long for so earnestly .", 
    "out-dataset_counterfactual_shuffle_num": 195, 
    "out-dataset_implicative_shuffle_num": 324005, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 1265085
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2428, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/72", 
    "implicative_pattern": "come", 
    "in-dataset_counterfactual_shuffle_num": 49, 
    "in-dataset_implicative_shuffle_num": 1572, 
    "inf_sentences_id": 689724, 
    "line": "Budget deadlines set by law come and go with no real consequences if they are missed .", 
    "linenum": 13, 
    "matchl": "Budget deadlines set by law come and go with no real consequences if they are missed .", 
    "out-dataset_counterfactual_shuffle_num": 196, 
    "out-dataset_implicative_shuffle_num": 6288, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 917304
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 5039, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "implicative_pattern": "find", 
    "in-dataset_counterfactual_shuffle_num": 49, 
    "in-dataset_implicative_shuffle_num": 2738, 
    "in-dataset_question_shuffle_num": 3163, 
    "inf_sentences_id": 695487, 
    "line": "How do I find a city if I have the area code ?", 
    "linenum": 2039, 
    "matchl": "How do I find a city if I have the area code ?", 
    "out-dataset_counterfactual_shuffle_num": 197, 
    "out-dataset_implicative_shuffle_num": 10203, 
    "out-dataset_question_shuffle_num": 9536, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 923067
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": ".+ (<wish>) .+", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 594308, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "implicative_pattern": "drive", 
    "in-dataset_counterfactual_shuffle_num": 49, 
    "in-dataset_implicative_shuffle_num": 262576, 
    "inf_sentences_id": 594329, 
    "line": "I wish you would n't drive so fast .", 
    "linenum": 594308, 
    "matchl": "I wish you would n't drive so fast .", 
    "out-dataset_counterfactual_shuffle_num": 198, 
    "out-dataset_implicative_shuffle_num": 528922, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 821586
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>(were|had) .+", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 27656, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/120.txt.utf-8", 
    "implicative_pattern": "attacked", 
    "in-dataset_counterfactual_shuffle_num": 49, 
    "in-dataset_implicative_shuffle_num": 82296, 
    "inf_sentences_id": 733556, 
    "line": "All they would do was to give me a loaded pistol lest we were attacked , and to promise to have horses ready saddled in case we were pursued on our return , while one lad was to ride forward to the doctor 's in search of armed assistance .", 
    "linenum": 381, 
    "matchl": "All they would do was to give me a loaded pistol lest we were attacked , and to promise to have horses ready saddled in case we were pursued on our return , while one lad was to ride forward to the doctor 's in search of armed assistance .", 
    "out-dataset_counterfactual_shuffle_num": 199, 
    "out-dataset_implicative_shuffle_num": 170293, 
    "sampled": [
      "counterfactual", 
      "implicative"
    ], 
    "ulf_sentences_id": 961136
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(<futr>)<mid>if<mid>(was|were|had|<past>|<ppart>) .+", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 676, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/120", 
    "in-dataset_counterfactual_shuffle_num": 50, 
    "inf_sentences_id": 687972, 
    "line": "Early in William J. Bennett 's tenure as secretary of education , when he was still on speaking terms with the National Education Association , the teacher union asked Bennett what he would do if he had a magic wand to wave over American s chools .", 
    "linenum": 0, 
    "matchl": "Early in William J. Bennett 's tenure as secretary of education , when he was still on speaking terms with the National Education Association , the teacher union asked Bennett what he would do if he had a magic wand to wave over American s chools .", 
    "out-dataset_counterfactual_shuffle_num": 200, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 915552
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 5657, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "in-dataset_counterfactual_shuffle_num": 50, 
    "in-dataset_question_shuffle_num": 4181, 
    "inf_sentences_id": 696105, 
    "line": "What have you not let a tennis ball do if you volley ?", 
    "linenum": 2657, 
    "matchl": "What have you not let a tennis ball do if you volley ?", 
    "out-dataset_counterfactual_shuffle_num": 201, 
    "out-dataset_question_shuffle_num": 12590, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question"
    ], 
    "ulf_sentences_id": 923685
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If)<mid>(was|were|had|<past>|<ppart>)<mid?>(<futr>) .+", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 132761, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_counterfactual_shuffle_num": 50, 
    "in-dataset_question_shuffle_num": 10076, 
    "in-dataset_request_shuffle_num": 3554, 
    "inf_sentences_id": 132778, 
    "line": "If you were to quit your job , what would you do ?", 
    "linenum": 132761, 
    "matchl": "If you were to quit your job , what would you do ?", 
    "out-dataset_counterfactual_shuffle_num": 202, 
    "out-dataset_question_shuffle_num": 30276, 
    "out-dataset_request_shuffle_num": 6895, 
    "question_pattern": "^.*\\?.*$", 
    "request_pattern": "<begin?>(<reqmodal>) you<mid?>(<pres>)<end?>", 
    "sampled": [
      "counterfactual", 
      "request", 
      "question"
    ], 
    "ulf_sentences_id": 360039
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 79465, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/135-0.txt", 
    "in-dataset_counterfactual_shuffle_num": 50, 
    "inf_sentences_id": 785365, 
    "line": "But if his vigor was dead , his energy was not .", 
    "linenum": 31038, 
    "matchl": "But if his vigor was dead , his energy was not .", 
    "out-dataset_counterfactual_shuffle_num": 203, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 1012945
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": ".+ (<wish>) .+", 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 699, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/120", 
    "in-dataset_counterfactual_shuffle_num": 51, 
    "inf_sentences_id": 687995, 
    "line": "`` I wish we had done more in the area of drugs .", 
    "linenum": 23, 
    "matchl": "`` I wish we had done more in the area of drugs .", 
    "out-dataset_counterfactual_shuffle_num": 204, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 915575
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 7579, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "implicative_pattern": "tell", 
    "in-dataset_counterfactual_shuffle_num": 51, 
    "in-dataset_implicative_shuffle_num": 1227, 
    "in-dataset_question_shuffle_num": 6952, 
    "inf_sentences_id": 698027, 
    "line": "How can anyone tell if a female had sexual intercourse ?", 
    "linenum": 1579, 
    "matchl": "How can anyone tell if a female had sexual intercourse ?", 
    "out-dataset_counterfactual_shuffle_num": 205, 
    "out-dataset_implicative_shuffle_num": 4909, 
    "out-dataset_question_shuffle_num": 20903, 
    "question_pattern": "(^|<sentconn>|<discpre>)(<wh>)<end?>$", 
    "sampled": [
      "counterfactual", 
      "question", 
      "implicative"
    ], 
    "ulf_sentences_id": 925607
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "counterfactual_pattern": "<begin?>(if|If) .*", 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 156710, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "in-dataset_counterfactual_shuffle_num": 51, 
    "inf_sentences_id": 156727, 
    "line": "If it must be that way , so be it .", 
    "linenum": 156710, 
    "matchl": "If it must be that way , so be it .", 
    "out-dataset_counterfactual_shuffle_num": 206, 
    "sampled": [
      "counterfactual"
    ], 
    "ulf_sentences_id": 383988
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1270, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/22", 
    "inf_sentences_id": 688566, 
    "line": "Because tritium decays at a rate of 5.5 percent a year , it needs to be regularly replenished to keep warheads at peak explosive power .", 
    "linenum": 11, 
    "matchl": "Because tritium decays at a rate of 5.5 percent a year , it needs to be regularly replenished to keep warheads at peak explosive power .", 
    "sampled": [], 
    "ulf_sentences_id": 916146
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 2177, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "inf_sentences_id": 692625, 
    "line": "Name a Gaelic language .", 
    "linenum": 1177, 
    "matchl": "Name a Gaelic language .", 
    "sampled": [], 
    "ulf_sentences_id": 920205
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 6699, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "inf_sentences_id": 697147, 
    "line": "Name the disposable razor that `` costs about 19 cents . ''", 
    "linenum": 699, 
    "matchl": "Name the disposable razor that `` costs about 19 cents . ''", 
    "sampled": [], 
    "ulf_sentences_id": 924727
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 623598, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 623620, 
    "line": "The first seven games were drawn .", 
    "linenum": 623598, 
    "matchl": "The first seven games were drawn .", 
    "sampled": [], 
    "ulf_sentences_id": 850876
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 266535, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2701-0.txt", 
    "inf_sentences_id": 972437, 
    "line": "That captain was Ahab .", 
    "linenum": 3522, 
    "matchl": "That captain was Ahab .", 
    "sampled": [], 
    "ulf_sentences_id": 1200017
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 7799, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "inf_sentences_id": 698247, 
    "line": "Name a band which was famous in the 1960 's .", 
    "linenum": 1799, 
    "matchl": "Name a band which was famous in the 1960 's .", 
    "sampled": [], 
    "ulf_sentences_id": 925827
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 4875, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "inf_sentences_id": 695323, 
    "line": "Name Randy Craft 's lawyer .", 
    "linenum": 1875, 
    "matchl": "Name Randy Craft 's lawyer .", 
    "sampled": [], 
    "ulf_sentences_id": 922903
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 13716, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "inf_sentences_id": 704164, 
    "line": "Name the fast food chain with the golden arches .", 
    "linenum": 3716, 
    "matchl": "Name the fast food chain with the golden arches .", 
    "sampled": [], 
    "ulf_sentences_id": 931744
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 4177, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "inf_sentences_id": 694625, 
    "line": "Name a Gaelic language .", 
    "linenum": 1177, 
    "matchl": "Name a Gaelic language .", 
    "sampled": [], 
    "ulf_sentences_id": 922205
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 43995, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 44011, 
    "line": "Here is your key .", 
    "linenum": 43995, 
    "matchl": "Here is your key .", 
    "sampled": [], 
    "ulf_sentences_id": 271273
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 356316, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/3600-0.txt", 
    "inf_sentences_id": 1062219, 
    "line": "OF THE BATTLE OF DREUX", 
    "linenum": 4117, 
    "matchl": "OF THE BATTLE OF DREUX", 
    "sampled": [], 
    "ulf_sentences_id": 1289799
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 51952, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/135-0.txt", 
    "inf_sentences_id": 757852, 
    "line": "She received the name as she received the water from the clouds upon her brow when it rained .", 
    "linenum": 3525, 
    "matchl": "She received the name as she received the water from the clouds upon her brow when it rained .", 
    "sampled": [], 
    "ulf_sentences_id": 985432
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 888, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/129", 
    "inf_sentences_id": 688184, 
    "line": "Maybe we need a CIA version of the Miranda warning: You have the right to conceal your coup intentions , because we may rat on you .", 
    "linenum": 15, 
    "matchl": "Maybe we need a CIA version of the Miranda warning: You have the right to conceal your coup intentions , because we may rat on you .", 
    "sampled": [], 
    "ulf_sentences_id": 915764
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 893, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/129", 
    "inf_sentences_id": 688189, 
    "line": "In other words , Congress wo n't let the CIA do much of anything anymore , and that 's fine with the CIA .", 
    "linenum": 20, 
    "matchl": "In other words , Congress wo n't let the CIA do much of anything anymore , and that 's fine with the CIA .", 
    "sampled": [], 
    "ulf_sentences_id": 915769
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2819, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/85", 
    "inf_sentences_id": 690115, 
    "line": "`` It 's a program we 've run a winning national campaign on , a program ratified in the light of intense national examination . ''", 
    "linenum": 20, 
    "matchl": "`` It 's a program we 've run a winning national campaign on , a program ratified in the light of intense national examination . ''", 
    "sampled": [], 
    "ulf_sentences_id": 917695
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 154290, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 154307, 
    "line": "He bailed on us just when we needed him .", 
    "linenum": 154290, 
    "matchl": "He bailed on us just when we needed him .", 
    "sampled": [], 
    "ulf_sentences_id": 381568
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 14181, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "inf_sentences_id": 704629, 
    "line": "Name one of King Henry VIII 's wives .", 
    "linenum": 4181, 
    "matchl": "Name one of King Henry VIII 's wives .", 
    "sampled": [], 
    "ulf_sentences_id": 932209
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 618744, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 618766, 
    "line": "Tom tiptoed into the bedroom to avoid waking up his wife .", 
    "linenum": 618744, 
    "matchl": "Tom tiptoed into the bedroom to avoid waking up his wife .", 
    "sampled": [], 
    "ulf_sentences_id": 846022
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 539, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/115", 
    "inf_sentences_id": 687835, 
    "line": "As a bearded ensign aboard the Finback , Edwards filmed Bush 's rescue with an 8mm Kodak movie camera .", 
    "linenum": 16, 
    "matchl": "As a bearded ensign aboard the Finback , Edwards filmed Bush 's rescue with an 8mm Kodak movie camera .", 
    "sampled": [], 
    "ulf_sentences_id": 915415
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1043, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/14", 
    "inf_sentences_id": 688339, 
    "line": "The cases in Lolotique and Piedra Luna , a village of a dozen households 90 miles east of San Salvador , are not unique .", 
    "linenum": 16, 
    "matchl": "The cases in Lolotique and Piedra Luna , a village of a dozen households 90 miles east of San Salvador , are not unique .", 
    "sampled": [], 
    "ulf_sentences_id": 915919
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 235, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/106", 
    "inf_sentences_id": 687531, 
    "line": "Its bottom rests 10 feet above an aquifer and its lip is 400 yards from Lake Marion , one of the Santee Cooper lakes created in World War II to provide hydroelectric power to underdeveloped areas and Charleston 's defense-related industries .", 
    "linenum": 19, 
    "matchl": "Its bottom rests 10 feet above an aquifer and its lip is 400 yards from Lake Marion , one of the Santee Cooper lakes created in World War II to provide hydroelectric power to underdeveloped areas and Charleston 's defense-related industries .", 
    "sampled": [], 
    "ulf_sentences_id": 915111
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2170, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/62", 
    "inf_sentences_id": 689466, 
    "line": "Mrs. Reagan was presented with a Lifetime Achievement Award by the Council of Fashion Designers of America at its eighth annual awards ceremony , held at the Metropolitan Museum of Art .", 
    "linenum": 1, 
    "matchl": "Mrs. Reagan was presented with a Lifetime Achievement Award by the Council of Fashion Designers of America at its eighth annual awards ceremony , held at the Metropolitan Museum of Art .", 
    "sampled": [], 
    "ulf_sentences_id": 917046
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 456683, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/768.txt.utf-8", 
    "inf_sentences_id": 1162587, 
    "line": "Next morning--bright and cheerful out of doors--stole softened in through the blinds of the silent room , and suffused the couch and its occupant with a mellow , tender glow .", 
    "linenum": 3110, 
    "matchl": "Next morning--bright and cheerful out of doors--stole softened in through the blinds of the silent room , and suffused the couch and its occupant with a mellow , tender glow .", 
    "sampled": [], 
    "ulf_sentences_id": 1390167
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 750, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/122", 
    "inf_sentences_id": 688046, 
    "line": "But the bank 's retail activities in Latin America are likely to be cut back .", 
    "linenum": 30, 
    "matchl": "But the bank 's retail activities in Latin America are likely to be cut back .", 
    "sampled": [], 
    "ulf_sentences_id": 915626
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 205194, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2500.txt.utf-8", 
    "inf_sentences_id": 911096, 
    "line": "Gotama taught the teachings of suffering , of the origin of suffering , of the way to relieve suffering .", 
    "linenum": 329, 
    "matchl": "Gotama taught the teachings of suffering , of the origin of suffering , of the way to relieve suffering .", 
    "sampled": [], 
    "ulf_sentences_id": 1138676
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1020, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/135", 
    "inf_sentences_id": 688316, 
    "line": "And , finally , there were the gloaters .", 
    "linenum": 42, 
    "matchl": "And , finally , there were the gloaters .", 
    "sampled": [], 
    "ulf_sentences_id": 915896
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2767, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/83", 
    "inf_sentences_id": 690063, 
    "line": "In Vienna , a deal was struck between Turkey and the Soviet Union .", 
    "linenum": 19, 
    "matchl": "In Vienna , a deal was struck between Turkey and the Soviet Union .", 
    "sampled": [], 
    "ulf_sentences_id": 917643
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 605377, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 605399, 
    "line": "She was the last guest .", 
    "linenum": 605377, 
    "matchl": "She was the last guest .", 
    "sampled": [], 
    "ulf_sentences_id": 832655
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 384, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/110", 
    "inf_sentences_id": 687680, 
    "line": "U.S. District Judge Gerhard Gesell is expected to act on Walsh 's request this week .", 
    "linenum": 4, 
    "matchl": "U.S. District Judge Gerhard Gesell is expected to act on Walsh 's request this week .", 
    "sampled": [], 
    "ulf_sentences_id": 915260
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 868, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/128", 
    "inf_sentences_id": 688164, 
    "line": "But so far , most potential participants have n't decided .", 
    "linenum": 14, 
    "matchl": "But so far , most potential participants have n't decided .", 
    "sampled": [], 
    "ulf_sentences_id": 915744
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1161, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/17", 
    "inf_sentences_id": 688457, 
    "line": "Some have been jailed since the first years after the 1959 revolution .", 
    "linenum": 10, 
    "matchl": "Some have been jailed since the first years after the 1959 revolution .", 
    "sampled": [], 
    "ulf_sentences_id": 916037
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 476, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/113", 
    "inf_sentences_id": 687772, 
    "line": "`` Now it 's different .", 
    "linenum": 43, 
    "matchl": "`` Now it 's different .", 
    "sampled": [], 
    "ulf_sentences_id": 915352
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 332, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/108", 
    "inf_sentences_id": 687628, 
    "line": "Whatever else it was , it was vintage Reagan .", 
    "linenum": 29, 
    "matchl": "Whatever else it was , it was vintage Reagan .", 
    "sampled": [], 
    "ulf_sentences_id": 915208
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 14397, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "inf_sentences_id": 704845, 
    "line": "Name Dick Tracy 's two children .", 
    "linenum": 4397, 
    "matchl": "Name Dick Tracy 's two children .", 
    "sampled": [], 
    "ulf_sentences_id": 932425
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 702, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/120", 
    "inf_sentences_id": 687998, 
    "line": "According to an account in the New Republic last May 23 , Bennett repeatedly urged the Pentagon and then-Attorney General Edwin Meese to unleash the U.S. military against foreign drug traffickers .", 
    "linenum": 26, 
    "matchl": "According to an account in the New Republic last May 23 , Bennett repeatedly urged the Pentagon and then-Attorney General Edwin Meese to unleash the U.S. military against foreign drug traffickers .", 
    "sampled": [], 
    "ulf_sentences_id": 915578
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 450741, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/76-0.txt", 
    "inf_sentences_id": 1156645, 
    "line": "He had suspicions of his father , the Duke of Wellington .", 
    "linenum": 3571, 
    "matchl": "He had suspicions of his father , the Duke of Wellington .", 
    "sampled": [], 
    "ulf_sentences_id": 1384225
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 268, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/107", 
    "inf_sentences_id": 687564, 
    "line": "In night clubs , theaters and galleries , artists of various kinds grapple with questions about the violence of occupation and the brutalizing effect on Israeli society of the army 's handling of the uprising .", 
    "linenum": 4, 
    "matchl": "In night clubs , theaters and galleries , artists of various kinds grapple with questions about the violence of occupation and the brutalizing effect on Israeli society of the army 's handling of the uprising .", 
    "sampled": [], 
    "ulf_sentences_id": 915144
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 11287, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "inf_sentences_id": 701735, 
    "line": "Name four famous cartoon cats .", 
    "linenum": 1287, 
    "matchl": "Name four famous cartoon cats .", 
    "sampled": [], 
    "ulf_sentences_id": 929315
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 5425, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "inf_sentences_id": 695873, 
    "line": "Name a Salt Lake City newspaper .", 
    "linenum": 2425, 
    "matchl": "Name a Salt Lake City newspaper .", 
    "sampled": [], 
    "ulf_sentences_id": 923453
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 471, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/113", 
    "inf_sentences_id": 687767, 
    "line": "Let 's just take that .", 
    "linenum": 38, 
    "matchl": "Let 's just take that .", 
    "sampled": [], 
    "ulf_sentences_id": 915347
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 36, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/1", 
    "inf_sentences_id": 687332, 
    "line": "An estimated $60,000 to $70,000 was earmarked in 1988 .", 
    "linenum": 36, 
    "matchl": "An estimated $60,000 to $70,000 was earmarked in 1988 .", 
    "sampled": [], 
    "ulf_sentences_id": 914912
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 1200, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "inf_sentences_id": 691648, 
    "line": "Name Alvin 's brothers", 
    "linenum": 200, 
    "matchl": "Name Alvin 's brothers", 
    "sampled": [], 
    "ulf_sentences_id": 919228
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 6009, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "inf_sentences_id": 696457, 
    "line": "Name the scar-faced bounty hunter of The Old West .", 
    "linenum": 9, 
    "matchl": "Name the scar-faced bounty hunter of The Old West .", 
    "sampled": [], 
    "ulf_sentences_id": 924037
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 11470, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "inf_sentences_id": 701918, 
    "line": "Name the creator of `` The Muppets '' .", 
    "linenum": 1470, 
    "matchl": "Name the creator of `` The Muppets '' .", 
    "sampled": [], 
    "ulf_sentences_id": 929498
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 57004, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 57020, 
    "line": "The dog traced the rabbit into the forest .", 
    "linenum": 57004, 
    "matchl": "The dog traced the rabbit into the forest .", 
    "sampled": [], 
    "ulf_sentences_id": 284282
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 73075, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/135-0.txt", 
    "inf_sentences_id": 778975, 
    "line": "The ventriloquist 's voice repeated his distich : --", 
    "linenum": 24648, 
    "matchl": "The ventriloquist 's voice repeated his distich : --", 
    "sampled": [], 
    "ulf_sentences_id": 1006555
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 383656, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 383675, 
    "line": "Write your surname on the fourth line .", 
    "linenum": 383656, 
    "matchl": "Write your surname on the fourth line .", 
    "sampled": [], 
    "ulf_sentences_id": 610934
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 14284, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "inf_sentences_id": 704732, 
    "line": "Name four comic strips about pilots .", 
    "linenum": 4284, 
    "matchl": "Name four comic strips about pilots .", 
    "sampled": [], 
    "ulf_sentences_id": 932312
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 5177, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "inf_sentences_id": 695625, 
    "line": "Name Pittsburgh 's baseball team .", 
    "linenum": 2177, 
    "matchl": "Name Pittsburgh 's baseball team .", 
    "sampled": [], 
    "ulf_sentences_id": 923205
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 258979, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 258997, 
    "line": "I ca n't just turn my back on Tom .", 
    "linenum": 258979, 
    "matchl": "I ca n't just turn my back on Tom .", 
    "sampled": [], 
    "ulf_sentences_id": 486257
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1621, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/37", 
    "inf_sentences_id": 688917, 
    "line": "The only nation that so far seems unaffected by the East European travel boom is Romania , whose 23 million citizens have scarce opportunity to journey abroad .", 
    "linenum": 28, 
    "matchl": "The only nation that so far seems unaffected by the East European travel boom is Romania , whose 23 million citizens have scarce opportunity to journey abroad .", 
    "sampled": [], 
    "ulf_sentences_id": 916497
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 602, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/117", 
    "inf_sentences_id": 687898, 
    "line": "`` NASA and interested external parties , domestic and international , must re-examine previous understandings , expectations , and commitments regarding flight opportunities . ''", 
    "linenum": 5, 
    "matchl": "`` NASA and interested external parties , domestic and international , must re-examine previous understandings , expectations , and commitments regarding flight opportunities . ''", 
    "sampled": [], 
    "ulf_sentences_id": 915478
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 484807, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/863-0.txt", 
    "inf_sentences_id": 1190711, 
    "line": "\" That was what you sealed up in the envelope . \"", 
    "linenum": 1059, 
    "matchl": "\" That was what you sealed up in the envelope . \"", 
    "sampled": [], 
    "ulf_sentences_id": 1418291
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 134610, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 134627, 
    "line": "Time for dinner .", 
    "linenum": 134610, 
    "matchl": "Time for dinner .", 
    "sampled": [], 
    "ulf_sentences_id": 361888
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 79055, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/135-0.txt", 
    "inf_sentences_id": 784955, 
    "line": "To follow to the slope is to arrive at the river .", 
    "linenum": 30628, 
    "matchl": "To follow to the slope is to arrive at the river .", 
    "sampled": [], 
    "ulf_sentences_id": 1012535
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 231850, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 231868, 
    "line": "They did not listen .", 
    "linenum": 231850, 
    "matchl": "They did not listen .", 
    "sampled": [], 
    "ulf_sentences_id": 459128
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2944, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/9", 
    "inf_sentences_id": 690240, 
    "line": "Revenue rose 42% to $133.7 million from $94 million .", 
    "linenum": 9, 
    "matchl": "Revenue rose 42% to $133.7 million from $94 million .", 
    "sampled": [], 
    "ulf_sentences_id": 917820
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2320, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/69", 
    "inf_sentences_id": 689616, 
    "line": "`` It 's really been quite a disaster . ''", 
    "linenum": 12, 
    "matchl": "`` It 's really been quite a disaster . ''", 
    "sampled": [], 
    "ulf_sentences_id": 917196
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2315, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/69", 
    "inf_sentences_id": 689611, 
    "line": "The only fire house in the rural community was destroyed and the only school was heavily damaged , according to Grounds .", 
    "linenum": 7, 
    "matchl": "The only fire house in the rural community was destroyed and the only school was heavily damaged , according to Grounds .", 
    "sampled": [], 
    "ulf_sentences_id": 917191
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 1022, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "inf_sentences_id": 691470, 
    "line": "Name 11 famous martyrs .", 
    "linenum": 22, 
    "matchl": "Name 11 famous martyrs .", 
    "sampled": [], 
    "ulf_sentences_id": 919050
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 271507, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 271525, 
    "line": "You look very beautiful tonight .", 
    "linenum": 271507, 
    "matchl": "You look very beautiful tonight .", 
    "sampled": [], 
    "ulf_sentences_id": 498785
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 136, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/103", 
    "inf_sentences_id": 687432, 
    "line": "Skiers and operators of fashionable resorts in the Alps and Dolomites are facing a severe dry spell that has left northern Italy snowless and caused sharp losses to the multimillion-dollar ski industry .", 
    "linenum": 0, 
    "matchl": "Skiers and operators of fashionable resorts in the Alps and Dolomites are facing a severe dry spell that has left northern Italy snowless and caused sharp losses to the multimillion-dollar ski industry .", 
    "sampled": [], 
    "ulf_sentences_id": 915012
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 432881, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/730.txt.utf-8", 
    "inf_sentences_id": 1138785, 
    "line": "' Well !", 
    "linenum": 797, 
    "matchl": "' Well !", 
    "sampled": [], 
    "ulf_sentences_id": 1366365
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 59289, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/135-0.txt", 
    "inf_sentences_id": 765189, 
    "line": "Nothing is so charming as the coloring reflection of happiness on a garret .", 
    "linenum": 10862, 
    "matchl": "Nothing is so charming as the coloring reflection of happiness on a garret .", 
    "sampled": [], 
    "ulf_sentences_id": 992769
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 527553, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 527574, 
    "line": "The Earth orbits around the Sun. It takes one year to go around the Sun one complete time .", 
    "linenum": 527553, 
    "matchl": "The Earth orbits around the Sun. It takes one year to go around the Sun one complete time .", 
    "sampled": [], 
    "ulf_sentences_id": 754831
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2858, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/86", 
    "inf_sentences_id": 690154, 
    "line": "Proposed outlays for total pensions are $4 billion , a $94 million increase over the estimated total for fiscal 1989 .", 
    "linenum": 28, 
    "matchl": "Proposed outlays for total pensions are $4 billion , a $94 million increase over the estimated total for fiscal 1989 .", 
    "sampled": [], 
    "ulf_sentences_id": 917734
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 56392, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/135-0.txt", 
    "inf_sentences_id": 762292, 
    "line": "The French , fired on from every point,--from behind the walls , from the summits of the garrets , from the depths of the cellars , through all the casements , through all the air-holes , through every crack in the stones,--fetched fagots and set fire to walls and men ; the reply to the grape-shot was a conflagration .", 
    "linenum": 7965, 
    "matchl": "The French , fired on from every point,--from behind the walls , from the summits of the garrets , from the depths of the cellars , through all the casements , through all the air-holes , through every crack in the stones,--fetched fagots and set fire to walls and men ; the reply to the grape-shot was a conflagration .", 
    "sampled": [], 
    "ulf_sentences_id": 989872
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 3602, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "inf_sentences_id": 694050, 
    "line": "Name the operating system that runs on IBM-compatible machines .", 
    "linenum": 602, 
    "matchl": "Name the operating system that runs on IBM-compatible machines .", 
    "sampled": [], 
    "ulf_sentences_id": 921630
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 565688, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 565709, 
    "line": "Mary chewed on her nails .", 
    "linenum": 565688, 
    "matchl": "Mary chewed on her nails .", 
    "sampled": [], 
    "ulf_sentences_id": 792966
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 568719, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 568740, 
    "line": "I could n't sleep on the plane .", 
    "linenum": 568719, 
    "matchl": "I could n't sleep on the plane .", 
    "sampled": [], 
    "ulf_sentences_id": 795997
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 70790, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 70806, 
    "line": "I could n't take in the lecture at all .", 
    "linenum": 70790, 
    "matchl": "I could n't take in the lecture at all .", 
    "sampled": [], 
    "ulf_sentences_id": 298068
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 257072, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2600-0.txt", 
    "inf_sentences_id": 962974, 
    "line": "One of the generals was reporting to him where the guns and prisoners had been captured .", 
    "linenum": 27951, 
    "matchl": "One of the generals was reporting to him where the guns and prisoners had been captured .", 
    "sampled": [], 
    "ulf_sentences_id": 1190554
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 148130, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1661.txt.utf-8", 
    "inf_sentences_id": 854031, 
    "line": "It was after five o'clock when Sherlock Holmes left me , but I had no time to be lonely , for within an hour there arrived a confectioner 's man with a very large flat box .", 
    "linenum": 5350, 
    "matchl": "It was after five o'clock when Sherlock Holmes left me , but I had no time to be lonely , for within an hour there arrived a confectioner 's man with a very large flat box .", 
    "sampled": [], 
    "ulf_sentences_id": 1081611
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 650282, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 650304, 
    "line": "I 'll just talk it over with Tom .", 
    "linenum": 650282, 
    "matchl": "I 'll just talk it over with Tom .", 
    "sampled": [], 
    "ulf_sentences_id": 877560
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 464727, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/786-0.txt", 
    "inf_sentences_id": 1170631, 
    "line": "' I 'd leefer not coom to ' t , sir ; but sin you put th ' question--an ' not want'n t ' be ill-manner'n--I 'll answer .", 
    "linenum": 3024, 
    "matchl": "' I 'd leefer not coom to ' t , sir ; but sin you put th ' question--an ' not want'n t ' be ill-manner'n--I 'll answer .", 
    "sampled": [], 
    "ulf_sentences_id": 1398211
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 7500, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "inf_sentences_id": 697948, 
    "line": "Name the two mystical ravens Odin has at his command .", 
    "linenum": 1500, 
    "matchl": "Name the two mystical ravens Odin has at his command .", 
    "sampled": [], 
    "ulf_sentences_id": 925528
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 13140, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "inf_sentences_id": 703588, 
    "line": "Name a movie that the actress , Sandra Bullock , had a role in .", 
    "linenum": 3140, 
    "matchl": "Name a movie that the actress , Sandra Bullock , had a role in .", 
    "sampled": [], 
    "ulf_sentences_id": 931168
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 3644, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "inf_sentences_id": 694092, 
    "line": "Name the organization that is presided by a Security Council .", 
    "linenum": 644, 
    "matchl": "Name the organization that is presided by a Security Council .", 
    "sampled": [], 
    "ulf_sentences_id": 921672
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 385288, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 385307, 
    "line": "I met my boyfriend there .", 
    "linenum": 385288, 
    "matchl": "I met my boyfriend there .", 
    "sampled": [], 
    "ulf_sentences_id": 612566
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 281874, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/28054-0.txt", 
    "inf_sentences_id": 987776, 
    "line": "He visits princes , though he is only a peasant corrupted .", 
    "linenum": 9449, 
    "matchl": "He visits princes , though he is only a peasant corrupted .", 
    "sampled": [], 
    "ulf_sentences_id": 1215356
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 11053, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "inf_sentences_id": 701501, 
    "line": "Name the various super-teams to which the Angel has belonged .", 
    "linenum": 1053, 
    "matchl": "Name the various super-teams to which the Angel has belonged .", 
    "sampled": [], 
    "ulf_sentences_id": 929081
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 12902, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "inf_sentences_id": 703350, 
    "line": "Name a female figure skater .", 
    "linenum": 2902, 
    "matchl": "Name a female figure skater .", 
    "sampled": [], 
    "ulf_sentences_id": 930930
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 10009, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "inf_sentences_id": 700457, 
    "line": "Name the scar-faced bounty hunter of The Old West .", 
    "linenum": 9, 
    "matchl": "Name the scar-faced bounty hunter of The Old West .", 
    "sampled": [], 
    "ulf_sentences_id": 928037
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 3017, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/93", 
    "inf_sentences_id": 690313, 
    "line": "Last month , Italy 's state television broadcast an interview with Contorno that was conducted at an undisclosed location in the United States .", 
    "linenum": 8, 
    "matchl": "Last month , Italy 's state television broadcast an interview with Contorno that was conducted at an undisclosed location in the United States .", 
    "sampled": [], 
    "ulf_sentences_id": 917893
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 704, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/120", 
    "inf_sentences_id": 688000, 
    "line": "Bennett is a Brooklyn-born son of a bank officer and a medical secretary who was raised in the Virginia suburbs of Washington after his parents divorced .", 
    "linenum": 28, 
    "matchl": "Bennett is a Brooklyn-born son of a bank officer and a medical secretary who was raised in the Virginia suburbs of Washington after his parents divorced .", 
    "sampled": [], 
    "ulf_sentences_id": 915580
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1696, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/40", 
    "inf_sentences_id": 688992, 
    "line": "They include nine Americans , among them Associated Press chief Middle East correspondent Terry Anderson , who was abducted on March 16 , 1985 .", 
    "linenum": 11, 
    "matchl": "They include nine Americans , among them Associated Press chief Middle East correspondent Terry Anderson , who was abducted on March 16 , 1985 .", 
    "sampled": [], 
    "ulf_sentences_id": 916572
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1485, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/31", 
    "inf_sentences_id": 688781, 
    "line": "On Wednesday , two American F-14s shot down two Libyan jet fighters .", 
    "linenum": 21, 
    "matchl": "On Wednesday , two American F-14s shot down two Libyan jet fighters .", 
    "sampled": [], 
    "ulf_sentences_id": 916361
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2535, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/75", 
    "inf_sentences_id": 689831, 
    "line": "Both parties operate unofficially in Hong Kong .", 
    "linenum": 12, 
    "matchl": "Both parties operate unofficially in Hong Kong .", 
    "sampled": [], 
    "ulf_sentences_id": 917411
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 487927, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 487947, 
    "line": "There are more of those in the drawer .", 
    "linenum": 487927, 
    "matchl": "There are more of those in the drawer .", 
    "sampled": [], 
    "ulf_sentences_id": 715205
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1944, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/50", 
    "inf_sentences_id": 689240, 
    "line": "--Federal money for educating handicapped children now covers only 8 percent of per-pupil expenditures as opposed to 12.5 percent in 1979 .", 
    "linenum": 24, 
    "matchl": "--Federal money for educating handicapped children now covers only 8 percent of per-pupil expenditures as opposed to 12.5 percent in 1979 .", 
    "sampled": [], 
    "ulf_sentences_id": 916820
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 304929, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/30254-0.txt", 
    "inf_sentences_id": 1010832, 
    "line": "At last she spoke again --", 
    "linenum": 377, 
    "matchl": "At last she spoke again --", 
    "sampled": [], 
    "ulf_sentences_id": 1238412
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 7407, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "inf_sentences_id": 697855, 
    "line": "Name the food company that traveled to Soviet Georgia to film a series of ads .", 
    "linenum": 1407, 
    "matchl": "Name the food company that traveled to Soviet Georgia to film a series of ads .", 
    "sampled": [], 
    "ulf_sentences_id": 925435
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 448543, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/76-0.txt", 
    "inf_sentences_id": 1154447, 
    "line": "De cow up ' n ' died on my han 's . \"", 
    "linenum": 1373, 
    "matchl": "De cow up ' n ' died on my han 's . \"", 
    "sampled": [], 
    "ulf_sentences_id": 1382027
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 109038, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 109055, 
    "line": "He has been writing poems since this morning .", 
    "linenum": 109038, 
    "matchl": "He has been writing poems since this morning .", 
    "sampled": [], 
    "ulf_sentences_id": 336316
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 54425, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/135-0.txt", 
    "inf_sentences_id": 760325, 
    "line": "There is a spectacle more grand than the sea ; it is heaven : there is a spectacle more grand than heaven ; it is the inmost recesses of the soul .", 
    "linenum": 5998, 
    "matchl": "There is a spectacle more grand than the sea ; it is heaven : there is a spectacle more grand than heaven ; it is the inmost recesses of the soul .", 
    "sampled": [], 
    "ulf_sentences_id": 987905
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2121, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/60", 
    "inf_sentences_id": 689417, 
    "line": "She did not have details of the inmates ' injuries .", 
    "linenum": 6, 
    "matchl": "She did not have details of the inmates ' injuries .", 
    "sampled": [], 
    "ulf_sentences_id": 916997
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 6602, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "inf_sentences_id": 697050, 
    "line": "Name the operating system that runs on IBM-compatible machines .", 
    "linenum": 602, 
    "matchl": "Name the operating system that runs on IBM-compatible machines .", 
    "sampled": [], 
    "ulf_sentences_id": 924630
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 560380, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 560401, 
    "line": "I updated my software .", 
    "linenum": 560380, 
    "matchl": "I updated my software .", 
    "sampled": [], 
    "ulf_sentences_id": 787658
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 551658, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 551679, 
    "line": "Tom was very jealous .", 
    "linenum": 551658, 
    "matchl": "Tom was very jealous .", 
    "sampled": [], 
    "ulf_sentences_id": 778936
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1299, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/23", 
    "inf_sentences_id": 688595, 
    "line": "According to Radio Moscow , enterprises that account for 60 percent of Soviet industrial output have been on `` self-accounting '' since January 1988 .", 
    "linenum": 14, 
    "matchl": "According to Radio Moscow , enterprises that account for 60 percent of Soviet industrial output have been on `` self-accounting '' since January 1988 .", 
    "sampled": [], 
    "ulf_sentences_id": 916175
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 27546, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 27562, 
    "line": "The peak rises above the clouds .", 
    "linenum": 27546, 
    "matchl": "The peak rises above the clouds .", 
    "sampled": [], 
    "ulf_sentences_id": 254824
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 467083, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 467103, 
    "line": "Tom is pretty good at singing .", 
    "linenum": 467083, 
    "matchl": "Tom is pretty good at singing .", 
    "sampled": [], 
    "ulf_sentences_id": 694361
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 304912, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/30254-0.txt", 
    "inf_sentences_id": 1010815, 
    "line": "Returning to the chair , and drawing well up her dress , petticoats and chemise , she exposed all her person up to the middle of her belly ; and sat down stretching herself backwards , and opening her thighs well .", 
    "linenum": 360, 
    "matchl": "Returning to the chair , and drawing well up her dress , petticoats and chemise , she exposed all her person up to the middle of her belly ; and sat down stretching herself backwards , and opening her thighs well .", 
    "sampled": [], 
    "ulf_sentences_id": 1238395
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 329790, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/3296.txt.utf-8", 
    "inf_sentences_id": 1035693, 
    "line": "To Thy grace I ascribe it , and to Thy mercy , that Thou hast melted away my sins as it were ice .", 
    "linenum": 362, 
    "matchl": "To Thy grace I ascribe it , and to Thy mercy , that Thou hast melted away my sins as it were ice .", 
    "sampled": [], 
    "ulf_sentences_id": 1263273
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 649176, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 649198, 
    "line": "Tom insulted me .", 
    "linenum": 649176, 
    "matchl": "Tom insulted me .", 
    "sampled": [], 
    "ulf_sentences_id": 876454
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 618254, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 618276, 
    "line": "You are level-headed .", 
    "linenum": 618254, 
    "matchl": "You are level-headed .", 
    "sampled": [], 
    "ulf_sentences_id": 845532
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 431122, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/55.txt.utf-8", 
    "inf_sentences_id": 1137026, 
    "line": "\" That is proof that he is sharp , \" remarked the Lion .", 
    "linenum": 1674, 
    "matchl": "\" That is proof that he is sharp , \" remarked the Lion .", 
    "sampled": [], 
    "ulf_sentences_id": 1364606
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 484699, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 484719, 
    "line": "Even Tom grinned .", 
    "linenum": 484699, 
    "matchl": "Even Tom grinned .", 
    "sampled": [], 
    "ulf_sentences_id": 711977
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 106483, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 106500, 
    "line": "He must have studied English hard .", 
    "linenum": 106483, 
    "matchl": "He must have studied English hard .", 
    "sampled": [], 
    "ulf_sentences_id": 333761
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 2369, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "inf_sentences_id": 692817, 
    "line": "Name the university of which Woodrow Wilson was president .", 
    "linenum": 1369, 
    "matchl": "Name the university of which Woodrow Wilson was president .", 
    "sampled": [], 
    "ulf_sentences_id": 920397
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 32086, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 32102, 
    "line": "The rule holds good in this case .", 
    "linenum": 32086, 
    "matchl": "The rule holds good in this case .", 
    "sampled": [], 
    "ulf_sentences_id": 259364
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 98543, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1400-0.txt", 
    "inf_sentences_id": 804443, 
    "line": "\" So you did .", 
    "linenum": 7893, 
    "matchl": "\" So you did .", 
    "sampled": [], 
    "ulf_sentences_id": 1032023
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 145407, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 145424, 
    "line": "I 've lost about 80 cents .", 
    "linenum": 145407, 
    "matchl": "I 've lost about 80 cents .", 
    "sampled": [], 
    "ulf_sentences_id": 372685
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 81346, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 81362, 
    "line": "The class being over , the students left quickly .", 
    "linenum": 81346, 
    "matchl": "The class being over , the students left quickly .", 
    "sampled": [], 
    "ulf_sentences_id": 308624
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 914, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/13", 
    "inf_sentences_id": 688210, 
    "line": "Once its ownership is finalized , the new company will open talks with state-appointed receivers to buy or lease Waertsilae Marine 's shipyard facilities .", 
    "linenum": 4, 
    "matchl": "Once its ownership is finalized , the new company will open talks with state-appointed receivers to buy or lease Waertsilae Marine 's shipyard facilities .", 
    "sampled": [], 
    "ulf_sentences_id": 915790
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 53427, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/135-0.txt", 
    "inf_sentences_id": 759327, 
    "line": "Fantine returned home .", 
    "linenum": 5000, 
    "matchl": "Fantine returned home .", 
    "sampled": [], 
    "ulf_sentences_id": 986907
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 267914, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2701-0.txt", 
    "inf_sentences_id": 973816, 
    "line": "\" Stern all ! \"", 
    "linenum": 4901, 
    "matchl": "\" Stern all ! \"", 
    "sampled": [], 
    "ulf_sentences_id": 1201396
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 3200, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "inf_sentences_id": 693648, 
    "line": "Name Alvin 's brothers", 
    "linenum": 200, 
    "matchl": "Name Alvin 's brothers", 
    "sampled": [], 
    "ulf_sentences_id": 921228
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 141597, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 141614, 
    "line": "I 'm photographing the woman .", 
    "linenum": 141597, 
    "matchl": "I 'm photographing the woman .", 
    "sampled": [], 
    "ulf_sentences_id": 368875
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 7287, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "inf_sentences_id": 697735, 
    "line": "Name four famous cartoon cats .", 
    "linenum": 1287, 
    "matchl": "Name four famous cartoon cats .", 
    "sampled": [], 
    "ulf_sentences_id": 925315
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 607095, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 607117, 
    "line": "The man stole my purse .", 
    "linenum": 607095, 
    "matchl": "The man stole my purse .", 
    "sampled": [], 
    "ulf_sentences_id": 834373
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 64601, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 64617, 
    "line": "Our hens laid a lot of eggs yesterday .", 
    "linenum": 64601, 
    "matchl": "Our hens laid a lot of eggs yesterday .", 
    "sampled": [], 
    "ulf_sentences_id": 291879
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2478, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/74", 
    "inf_sentences_id": 689774, 
    "line": "Police in the county of Derbyshire reported several bodies scattered on each side of the highway .", 
    "linenum": 10, 
    "matchl": "Police in the county of Derbyshire reported several bodies scattered on each side of the highway .", 
    "sampled": [], 
    "ulf_sentences_id": 917354
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 627960, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 627982, 
    "line": "No one ever seizes power with the intention of relinquishing it .", 
    "linenum": 627960, 
    "matchl": "No one ever seizes power with the intention of relinquishing it .", 
    "sampled": [], 
    "ulf_sentences_id": 855238
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 113892, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1497.txt.utf-8", 
    "inf_sentences_id": 819793, 
    "line": "Neither must we sing to them of", 
    "linenum": 4608, 
    "matchl": "Neither must we sing to them of", 
    "sampled": [], 
    "ulf_sentences_id": 1047373
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 293458, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/28054-0.txt", 
    "inf_sentences_id": 999360, 
    "line": "My idea seemed silly to me at the time , but he was perhaps pointing then to that little bag in which he had fifteen hundred roubles ! \"", 
    "linenum": 21033, 
    "matchl": "My idea seemed silly to me at the time , but he was perhaps pointing then to that little bag in which he had fifteen hundred roubles ! \"", 
    "sampled": [], 
    "ulf_sentences_id": 1226940
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 358285, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 358304, 
    "line": "He had bought a dog .", 
    "linenum": 358285, 
    "matchl": "He had bought a dog .", 
    "sampled": [], 
    "ulf_sentences_id": 585563
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 679211, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 679233, 
    "line": "We are all sinners .", 
    "linenum": 679211, 
    "matchl": "We are all sinners .", 
    "sampled": [], 
    "ulf_sentences_id": 906489
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 15395, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "inf_sentences_id": 705843, 
    "line": "Describe the Long March .", 
    "linenum": 5395, 
    "matchl": "Describe the Long March .", 
    "sampled": [], 
    "ulf_sentences_id": 933423
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 8519, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "inf_sentences_id": 698967, 
    "line": "Name a civil war battlefield .", 
    "linenum": 2519, 
    "matchl": "Name a civil war battlefield .", 
    "sampled": [], 
    "ulf_sentences_id": 926547
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 108955, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/148.txt.utf-8", 
    "inf_sentences_id": 814856, 
    "line": "During his absence the French and savages had taken Fort George , on the frontier of that province , and the savages had massacred many of the garrison after capitulation .", 
    "linenum": 1857, 
    "matchl": "During his absence the French and savages had taken Fort George , on the frontier of that province , and the savages had massacred many of the garrison after capitulation .", 
    "sampled": [], 
    "ulf_sentences_id": 1042436
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 9066, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "inf_sentences_id": 699514, 
    "line": "Name the three races unleashed by the Celestials in Marvel comics .", 
    "linenum": 3066, 
    "matchl": "Name the three races unleashed by the Celestials in Marvel comics .", 
    "sampled": [], 
    "ulf_sentences_id": 927094
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 84546, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/140-0.txt", 
    "inf_sentences_id": 790446, 
    "line": "There was Elzbieta Lukoszaite , Teta , or Aunt , as they called her , Ona 's stepmother , and there were her six children , of all ages .", 
    "linenum": 364, 
    "matchl": "There was Elzbieta Lukoszaite , Teta , or Aunt , as they called her , Ona 's stepmother , and there were her six children , of all ages .", 
    "sampled": [], 
    "ulf_sentences_id": 1018026
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 918, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_1000.raw", 
    "inf_sentences_id": 691366, 
    "line": "Name the largest country in South America .", 
    "linenum": 918, 
    "matchl": "Name the largest country in South America .", 
    "sampled": [], 
    "ulf_sentences_id": 918946
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 10579, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "inf_sentences_id": 701027, 
    "line": "Name the soft drink that is `` number one in the sun . ''", 
    "linenum": 579, 
    "matchl": "Name the soft drink that is `` number one in the sun . ''", 
    "sampled": [], 
    "ulf_sentences_id": 928607
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 638989, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 639011, 
    "line": "It must 've been destiny .", 
    "linenum": 638989, 
    "matchl": "It must 've been destiny .", 
    "sampled": [], 
    "ulf_sentences_id": 866267
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 291993, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 292011, 
    "line": "It is n't locked .", 
    "linenum": 291993, 
    "matchl": "It is n't locked .", 
    "sampled": [], 
    "ulf_sentences_id": 519271
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 9723, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1184-0.txt", 
    "inf_sentences_id": 715623, 
    "line": "he asked of Franz .", 
    "linenum": 8200, 
    "matchl": "he asked of Franz .", 
    "sampled": [], 
    "ulf_sentences_id": 943203
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1681, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/4", 
    "inf_sentences_id": 688977, 
    "line": "Typically , money-fund yields beat comparable short-term investments because portfolio managers can vary maturities and go after the highest rates .", 
    "linenum": 11, 
    "matchl": "Typically , money-fund yields beat comparable short-term investments because portfolio managers can vary maturities and go after the highest rates .", 
    "sampled": [], 
    "ulf_sentences_id": 916557
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 92340, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 92356, 
    "line": "We heard glass shattering in our street .", 
    "linenum": 92340, 
    "matchl": "We heard glass shattering in our street .", 
    "sampled": [], 
    "ulf_sentences_id": 319618
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 10200, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "inf_sentences_id": 700648, 
    "line": "Name Alvin 's brothers", 
    "linenum": 200, 
    "matchl": "Name Alvin 's brothers", 
    "sampled": [], 
    "ulf_sentences_id": 928228
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 10970, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "inf_sentences_id": 701418, 
    "line": "Name the only extant trilogy of classical Greek plays .", 
    "linenum": 970, 
    "matchl": "Name the only extant trilogy of classical Greek plays .", 
    "sampled": [], 
    "ulf_sentences_id": 928998
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 6970, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "inf_sentences_id": 697418, 
    "line": "Name the only extant trilogy of classical Greek plays .", 
    "linenum": 970, 
    "matchl": "Name the only extant trilogy of classical Greek plays .", 
    "sampled": [], 
    "ulf_sentences_id": 924998
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 149, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/103", 
    "inf_sentences_id": 687445, 
    "line": "The few resorts with favorable ski conditions because of their shady positions were invaded by thousands of Chrismas holiday skiers -- quickly spoiling their slopes .", 
    "linenum": 13, 
    "matchl": "The few resorts with favorable ski conditions because of their shady positions were invaded by thousands of Chrismas holiday skiers -- quickly spoiling their slopes .", 
    "sampled": [], 
    "ulf_sentences_id": 915025
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 68414, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/135-0.txt", 
    "inf_sentences_id": 774314, 
    "line": "The devil ! \"", 
    "linenum": 19987, 
    "matchl": "The devil ! \"", 
    "sampled": [], 
    "ulf_sentences_id": 1001894
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 208716, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 208734, 
    "line": "You do n't worry .", 
    "linenum": 208716, 
    "matchl": "You do n't worry .", 
    "sampled": [], 
    "ulf_sentences_id": 435994
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1429, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/3", 
    "inf_sentences_id": 688725, 
    "line": "In 1988 , 371 persons had been killed in the nation 's capital as of Dec. 30 , far surpassing the previous high total of 287 , set in 1969 .", 
    "linenum": 3, 
    "matchl": "In 1988 , 371 persons had been killed in the nation 's capital as of Dec. 30 , far surpassing the previous high total of 287 , set in 1969 .", 
    "sampled": [], 
    "ulf_sentences_id": 916305
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 61523, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 61539, 
    "line": "My wife is subject to moods .", 
    "linenum": 61523, 
    "matchl": "My wife is subject to moods .", 
    "sampled": [], 
    "ulf_sentences_id": 288801
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 1882, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "inf_sentences_id": 692330, 
    "line": "Name the various costumed personas of Dr. Henry Pym .", 
    "linenum": 882, 
    "matchl": "Name the various costumed personas of Dr. Henry Pym .", 
    "sampled": [], 
    "ulf_sentences_id": 919910
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 10540, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "inf_sentences_id": 700988, 
    "line": "Name a movie about the Sioux Indians starring Kevin Costner .", 
    "linenum": 540, 
    "matchl": "Name a movie about the Sioux Indians starring Kevin Costner .", 
    "sampled": [], 
    "ulf_sentences_id": 928568
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 264153, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 264171, 
    "line": "This is my last review .", 
    "linenum": 264153, 
    "matchl": "This is my last review .", 
    "sampled": [], 
    "ulf_sentences_id": 491431
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 170596, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/20228.txt.utf-8", 
    "inf_sentences_id": 876497, 
    "line": "Bucod sa rito'y ang m~ga bagay na sasabihin co'y lubhang napacamahalaga upang maipagpaubaya o sabihin caya sa cahulihulihan ; ito ang dahil at ibig co sanang magpauna n~g pananalita , at n~g maibigay ang dapat na cauculan .", 
    "linenum": 2376, 
    "matchl": "Bucod sa rito'y ang m~ga bagay na sasabihin co'y lubhang napacamahalaga upang maipagpaubaya o sabihin caya sa cahulihulihan ; ito ang dahil at ibig co sanang magpauna n~g pananalita , at n~g maibigay ang dapat na cauculan .", 
    "sampled": [], 
    "ulf_sentences_id": 1104077
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 66124, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/135-0.txt", 
    "inf_sentences_id": 772024, 
    "line": "CHAPTER I --", 
    "linenum": 17697, 
    "matchl": "CHAPTER I --", 
    "sampled": [], 
    "ulf_sentences_id": 999604
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 375965, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/42.txt.utf-8", 
    "inf_sentences_id": 1081868, 
    "line": "They were both pale ; and there was an answering horror in their eyes .", 
    "linenum": 641, 
    "matchl": "They were both pale ; and there was an answering horror in their eyes .", 
    "sampled": [], 
    "ulf_sentences_id": 1309448
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 294089, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/28054-0.txt", 
    "inf_sentences_id": 999991, 
    "line": "She became prudent and saved money .", 
    "linenum": 21664, 
    "matchl": "She became prudent and saved money .", 
    "sampled": [], 
    "ulf_sentences_id": 1227571
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 80532, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/135-0.txt", 
    "inf_sentences_id": 786432, 
    "line": "He seized Basque by the collar , and shouted full in his face in fury:--\"By the hundred thousand Javottes of the devil , those ruffians did assassinate him ! \"", 
    "linenum": 32105, 
    "matchl": "He seized Basque by the collar , and shouted full in his face in fury:--\"By the hundred thousand Javottes of the devil , those ruffians did assassinate him ! \"", 
    "sampled": [], 
    "ulf_sentences_id": 1014012
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 182, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/104", 
    "inf_sentences_id": 687478, 
    "line": "The set for this first staged presentation was a cutaway two-story house by Michael Anania .", 
    "linenum": 23, 
    "matchl": "The set for this first staged presentation was a cutaway two-story house by Michael Anania .", 
    "sampled": [], 
    "ulf_sentences_id": 915058
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 32086, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1232.txt.utf-8", 
    "inf_sentences_id": 737986, 
    "line": "Castruccio was received in great honour by Frederick , and many privileges were conferred upon him , and he was appointed the emperor 's lieutenant in Tuscany .", 
    "linenum": 1125, 
    "matchl": "Castruccio was received in great honour by Frederick , and many privileges were conferred upon him , and he was appointed the emperor 's lieutenant in Tuscany .", 
    "sampled": [], 
    "ulf_sentences_id": 965566
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 7379, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "inf_sentences_id": 697827, 
    "line": "Name the five positions who are in the line of succession to the presidency .", 
    "linenum": 1379, 
    "matchl": "Name the five positions who are in the line of succession to the presidency .", 
    "sampled": [], 
    "ulf_sentences_id": 925407
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 546, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/115", 
    "inf_sentences_id": 687842, 
    "line": "Bush bailed out over the water but his two crew members were lost .", 
    "linenum": 23, 
    "matchl": "Bush bailed out over the water but his two crew members were lost .", 
    "sampled": [], 
    "ulf_sentences_id": 915422
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 9716, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "inf_sentences_id": 700164, 
    "line": "Name the fast food chain with the golden arches .", 
    "linenum": 3716, 
    "matchl": "Name the fast food chain with the golden arches .", 
    "sampled": [], 
    "ulf_sentences_id": 927744
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 100110, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1404.txt.utf-8", 
    "inf_sentences_id": 806011, 
    "line": "Ambition , avarice , personal animosity , party opposition , and many other motives not more laudable than these , are apt to operate as well upon those who support as those who oppose the right side of a question .", 
    "linenum": 24, 
    "matchl": "Ambition , avarice , personal animosity , party opposition , and many other motives not more laudable than these , are apt to operate as well upon those who support as those who oppose the right side of a question .", 
    "sampled": [], 
    "ulf_sentences_id": 1033591
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 373229, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 373248, 
    "line": "Tom does n't have any close friends .", 
    "linenum": 373229, 
    "matchl": "Tom does n't have any close friends .", 
    "sampled": [], 
    "ulf_sentences_id": 600507
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 2470, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "inf_sentences_id": 692918, 
    "line": "Name the creator of `` The Muppets '' .", 
    "linenum": 1470, 
    "matchl": "Name the creator of `` The Muppets '' .", 
    "sampled": [], 
    "ulf_sentences_id": 920498
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 675989, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 676011, 
    "line": "The air in this city is very polluted .", 
    "linenum": 675989, 
    "matchl": "The air in this city is very polluted .", 
    "sampled": [], 
    "ulf_sentences_id": 903267
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 449286, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/76-0.txt", 
    "inf_sentences_id": 1155190, 
    "line": "\" Po ' little chap . \"", 
    "linenum": 2116, 
    "matchl": "\" Po ' little chap . \"", 
    "sampled": [], 
    "ulf_sentences_id": 1382770
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 402, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/111", 
    "inf_sentences_id": 687698, 
    "line": "`` The enthusiasm was just overwhelming .", 
    "linenum": 11, 
    "matchl": "`` The enthusiasm was just overwhelming .", 
    "sampled": [], 
    "ulf_sentences_id": 915278
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 604393, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 604415, 
    "line": "Tom probably is n't hungry .", 
    "linenum": 604393, 
    "matchl": "Tom probably is n't hungry .", 
    "sampled": [], 
    "ulf_sentences_id": 831671
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 190130, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/2148-0.txt", 
    "inf_sentences_id": 896031, 
    "line": "VALDEMAR", 
    "linenum": 1021, 
    "matchl": "VALDEMAR", 
    "sampled": [], 
    "ulf_sentences_id": 1123611
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 4407, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "inf_sentences_id": 694855, 
    "line": "Name the food company that traveled to Soviet Georgia to film a series of ads .", 
    "linenum": 1407, 
    "matchl": "Name the food company that traveled to Soviet Georgia to film a series of ads .", 
    "sampled": [], 
    "ulf_sentences_id": 922435
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 1644, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_2000.raw", 
    "inf_sentences_id": 692092, 
    "line": "Name the organization that is presided by a Security Council .", 
    "linenum": 644, 
    "matchl": "Name the organization that is presided by a Security Council .", 
    "sampled": [], 
    "ulf_sentences_id": 919672
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 126777, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/158-0.txt", 
    "inf_sentences_id": 832678, 
    "line": "\" I shall not scold you .", 
    "linenum": 5930, 
    "matchl": "\" I shall not scold you .", 
    "sampled": [], 
    "ulf_sentences_id": 1060258
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 11295, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "inf_sentences_id": 701743, 
    "line": "Define cosmology .", 
    "linenum": 1295, 
    "matchl": "Define cosmology .", 
    "sampled": [], 
    "ulf_sentences_id": 929323
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 55552, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 55568, 
    "line": "The train was crowded with people .", 
    "linenum": 55552, 
    "matchl": "The train was crowded with people .", 
    "sampled": [], 
    "ulf_sentences_id": 282830
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1929, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/50", 
    "inf_sentences_id": 689225, 
    "line": "He is expected to rework the lame-duck budget Reagan will be sending to Congress on Monday .", 
    "linenum": 9, 
    "matchl": "He is expected to rework the lame-duck budget Reagan will be sending to Congress on Monday .", 
    "sampled": [], 
    "ulf_sentences_id": 916805
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 970, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_1000.raw", 
    "inf_sentences_id": 691418, 
    "line": "Name the only extant trilogy of classical Greek plays .", 
    "linenum": 970, 
    "matchl": "Name the only extant trilogy of classical Greek plays .", 
    "sampled": [], 
    "ulf_sentences_id": 918998
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 11359, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "inf_sentences_id": 701807, 
    "line": "Name an art gallery in New York .", 
    "linenum": 1359, 
    "matchl": "Name an art gallery in New York .", 
    "sampled": [], 
    "ulf_sentences_id": 929387
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 2083, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/59", 
    "inf_sentences_id": 689379, 
    "line": "The proposed directive is the result of increasing concern about cracking on older commercial jetliners .", 
    "linenum": 3, 
    "matchl": "The proposed directive is the result of increasing concern about cracking on older commercial jetliners .", 
    "sampled": [], 
    "ulf_sentences_id": 916959
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1505, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/33", 
    "inf_sentences_id": 688801, 
    "line": "Mrs. Ryder was the widow of Melvin Ryder , who in 1940 founded the Army Times , and she had been in the management of the company from its inception .", 
    "linenum": 2, 
    "matchl": "Mrs. Ryder was the widow of Melvin Ryder , who in 1940 founded the Army Times , and she had been in the management of the company from its inception .", 
    "sampled": [], 
    "ulf_sentences_id": 916381
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 135863, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/160-0.txt", 
    "inf_sentences_id": 841764, 
    "line": "\" But not well enough to keep you there .", 
    "linenum": 2981, 
    "matchl": "\" But not well enough to keep you there .", 
    "sampled": [], 
    "ulf_sentences_id": 1069344
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 411434, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 411454, 
    "line": "We ate at a restaurant just outside Boston .", 
    "linenum": 411434, 
    "matchl": "We ate at a restaurant just outside Boston .", 
    "sampled": [], 
    "ulf_sentences_id": 638712
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 8233, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "inf_sentences_id": 698681, 
    "line": "Name the two blob members of the animated Herculoids .", 
    "linenum": 2233, 
    "matchl": "Name the two blob members of the animated Herculoids .", 
    "sampled": [], 
    "ulf_sentences_id": 926261
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 570370, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 570391, 
    "line": "Tom deserves a raise .", 
    "linenum": 570370, 
    "matchl": "Tom deserves a raise .", 
    "sampled": [], 
    "ulf_sentences_id": 797648
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 14981, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "inf_sentences_id": 705429, 
    "line": "Name the Islamic counterpart to the Red Cross .", 
    "linenum": 4981, 
    "matchl": "Name the Islamic counterpart to the Red Cross .", 
    "sampled": [], 
    "ulf_sentences_id": 933009
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 12425, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "inf_sentences_id": 702873, 
    "line": "Name a Salt Lake City newspaper .", 
    "linenum": 2425, 
    "matchl": "Name a Salt Lake City newspaper .", 
    "sampled": [], 
    "ulf_sentences_id": 930453
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 128978, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/158-0.txt", 
    "inf_sentences_id": 834879, 
    "line": "That was the act of a very , very young man , one too young to consider whether the inconvenience of it might not very much exceed the pleasure .", 
    "linenum": 8131, 
    "matchl": "That was the act of a very , very young man , one too young to consider whether the inconvenience of it might not very much exceed the pleasure .", 
    "sampled": [], 
    "ulf_sentences_id": 1062459
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 7422, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_4000.raw", 
    "inf_sentences_id": 697870, 
    "line": "Name Li 'l Abner 's favorite Indian drink .", 
    "linenum": 1422, 
    "matchl": "Name Li 'l Abner 's favorite Indian drink .", 
    "sampled": [], 
    "ulf_sentences_id": 925450
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 48755, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/135-0.txt", 
    "inf_sentences_id": 754655, 
    "line": "LITTLE GAVROCHE CHAPTER I --", 
    "linenum": 328, 
    "matchl": "LITTLE GAVROCHE CHAPTER I --", 
    "sampled": [], 
    "ulf_sentences_id": 982235
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 4500, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "inf_sentences_id": 694948, 
    "line": "Name the two mystical ravens Odin has at his command .", 
    "linenum": 1500, 
    "matchl": "Name the two mystical ravens Odin has at his command .", 
    "sampled": [], 
    "ulf_sentences_id": 922528
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 125749, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 125766, 
    "line": "She takes great pride in her appearance .", 
    "linenum": 125749, 
    "matchl": "She takes great pride in her appearance .", 
    "sampled": [], 
    "ulf_sentences_id": 353027
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 37453, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 37469, 
    "line": "A computer can calculate very rapidly .", 
    "linenum": 37453, 
    "matchl": "A computer can calculate very rapidly .", 
    "sampled": [], 
    "ulf_sentences_id": 264731
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 401991, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/4363.txt.utf-8", 
    "inf_sentences_id": 1107895, 
    "line": "Oh Europe !", 
    "linenum": 1381, 
    "matchl": "Oh Europe !", 
    "sampled": [], 
    "ulf_sentences_id": 1335475
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 205471, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 205489, 
    "line": "I 'm broken .", 
    "linenum": 205471, 
    "matchl": "I 'm broken .", 
    "sampled": [], 
    "ulf_sentences_id": 432749
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "pg", 
    "dataset_name": "Project Gutenberg", 
    "dataset_num": 47717, 
    "filepath": "datasets/project_gutenberg/normalized_top100-30day-2-26-2018/1342-0.txt", 
    "inf_sentences_id": 753617, 
    "line": "Mrs .", 
    "linenum": 5577, 
    "matchl": "Mrs .", 
    "sampled": [], 
    "ulf_sentences_id": 981197
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "dgb", 
    "dataset_name": "Discourse Graphbank", 
    "dataset_num": 1177, 
    "filepath": "datasets/discourse_graphbank/normalized_discourse_graphbank/18", 
    "inf_sentences_id": 688473, 
    "line": "The herbicide contains the highly toxic chemical dioxin .", 
    "linenum": 13, 
    "matchl": "The herbicide contains the highly toxic chemical dioxin .", 
    "sampled": [], 
    "ulf_sentences_id": 916053
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 4369, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "inf_sentences_id": 694817, 
    "line": "Name the university of which Woodrow Wilson was president .", 
    "linenum": 1369, 
    "matchl": "Name the university of which Woodrow Wilson was president .", 
    "sampled": [], 
    "ulf_sentences_id": 922397
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 14205, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "inf_sentences_id": 704653, 
    "line": "Name a flying mammal .", 
    "linenum": 4205, 
    "matchl": "Name a flying mammal .", 
    "sampled": [], 
    "ulf_sentences_id": 932233
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 15015, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_5500.raw", 
    "inf_sentences_id": 705463, 
    "line": "Name the Four Horsemen of the Apocalypse .", 
    "linenum": 5015, 
    "matchl": "Name the Four Horsemen of the Apocalypse .", 
    "sampled": [], 
    "ulf_sentences_id": 933043
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "tatoeba", 
    "dataset_name": "Tatoeba Translation Dataset", 
    "dataset_num": 643391, 
    "filepath": "datasets/tatoeba/normalized_tatoeba_sentences_raw.eng", 
    "inf_sentences_id": 643413, 
    "line": "It 's a lot to ask .", 
    "linenum": 643391, 
    "matchl": "It 's a lot to ask .", 
    "sampled": [], 
    "ulf_sentences_id": 870669
  }, 
  {
    "config_info": {
      "iyouknow": false, 
      "swmatch": false
    }, 
    "dataset_abbrev": "uiuc", 
    "dataset_name": "University of Illinois Urbana-Champaign Question Classification Dataset", 
    "dataset_num": 3661, 
    "filepath": "datasets/uiuc_qc/normalized_train/train_3000.raw", 
    "inf_sentences_id": 694109, 
    "line": "Name a tiger that is extinct .", 
    "linenum": 661, 
    "matchl": "Name a tiger that is extinct .", 
    "sampled": [], 
    "ulf_sentences_id": 921689
  }
]